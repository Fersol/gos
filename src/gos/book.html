<h2 id="последовательная-и-параллельная-сложность-алгоритмов-информационный-граф-и-ресурс-параллелизма-алгоритмов.">1. Последовательная и параллельная сложность алгоритмов, информационный граф и ресурс параллелизма алгоритмов.</h2>
<p><strong>Последовательная сложность</strong> (serial complexity) алгоритма - число операций, которые нужно выполнить при его последовательном исполнении.</p>
<p><strong>Параллельная сложность</strong> (parallel complexity) алгоритма - число шагов, за которое можно выполнить данный алгоритм в предположении доступности неограниченного числа необходимых процессоров (функциональных устройств, вычислительных узлов, ядер и т.п.). Параллельная сложность алгоритма понимается как высота канонической <a href="https://algowiki-project.org/ru/Глоссарий#.D0.AF.D1.80.D1.83.D1.81.D0.BD.D0.BE-.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D1.8C.D0.BD.D0.B0.D1.8F_.D1.84.D0.BE.D1.80.D0.BC.D0.B0_.D0.B3.D1.80.D0.B0.D1.84.D0.B0_.D0.B0.D0.BB.D0.B3.D0.BE.D1.80.D0.B8.D1.82.D0.BC.D0.B0">ярусно-параллельной формы</a>.</p>
<p><strong>Ярусно-параллельная форма (ЯПФ)</strong> (parallel form) - это представление графа алгоритма, в котором:</p>
<p>- все вершины разбиты на перенумерованные подмножества ярусов;</p>
<p>- начальная вершина каждой дуги расположена на ярусе с номером меньшим, чем номер яруса конечной вершины;</p>
<p>- между вершинами, расположенными на одном ярусе, не может быть дуг.</p>
<p><em>Высота</em> ЯПФ - это число ярусов. Ширина яруса - число вершин, расположенных на ярусе. <em>Ширина</em> ЯПФ - это максимальная ширина ярусов в ЯПФ.</p>
<p><strong>Канонической ярусно-параллельной формой</strong> называется ЯПФ, высота которой на единицу больше длины критического пути, а все входные вершины расположены на первом ярусе. Для заданного графа его каноническая ЯПФ единственна.</p>
<p><strong>Граф алгоритма</strong> (algorithm graph, информационный граф) - это ориентированный ациклический мультиграф, вершины которого соответствуют операциям алгоритма, а дуги - передаче данных между ними. Вершины графа алгоритма могут соединяться несколькими дугами, в частности когда в качестве разных аргументов одной и той же операции используется одна и та же величина. Граф алгоритма почти всегда является параметризованным графом. В частности, его вид часто зависит от входных данных.</p>
<p><img src="img\aaaaaa.png" /></p>
<p>Информационная структура одного из вариантов алгоритма решения систем линейных алгебраических уравнений с блочно-двухдиагональной матрицей</p>
<p>Граф алгоритма используется как удобное представление алгоритма при исследовании его структуры, ресурса параллелизма, а также других свойств. Его можно рассматривать как параметризованную информационную историю. Он сохраняет её информативность, при этом обладая компактностью за счёт параметризации. Разработана методика построения графа алгоритма по исходному тексту программ.</p>
<p><em>Граф алгоритма</em>:</p>
<p>- почти всегда является параметризованным графом. В частности, его вид часто зависит от входных данных.</p>
<p>- используется как удобное представление алгоритма при исследовании его структуры, ресурса параллелизма, а также других свойств.</p>
<p>- показывает как устроена параллельная структура алгоритма. Много информации несут разного рода проекции информационного графа, выделяя его регулярные составляющие и одновременно скрывая несущественные детали.</p>
<p>- потенциально бесконечный граф, число вершин и дуг которого определяется значениями внешних переменных.</p>
<p>- потенциально многомерный объект. Наиболее естественная система координат для размещения вершин и дуг информационного графа опирается на структуру вложенности циклов в реализации алгоритма.</p>
<p>Для описания <strong>ресурса параллелизма</strong> алгоритма (ресурса параллелизма информационного графа) необходимо указать ключевые параллельные ветви в терминах <a href="http://algowiki-project.org/ru/Глоссарий#.D0.9A.D0.BE.D0.BD.D0.B5.D1.87.D0.BD.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC"><em>конечного</em></a> и <a href="http://algowiki-project.org/ru/Глоссарий#.D0.9C.D0.B0.D1.81.D1.81.D0.BE.D0.B2.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC"><em>массового</em></a> параллелизма. Далеко не всегда ресурс параллелизма выражается просто, например, через <a href="http://algowiki-project.org/ru/Глоссарий#.D0.9A.D0.BE.D0.BE.D0.BE.D0.B4.D0.B8.D0.BD.D0.B0.D1.82.D0.BD.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC"><em>координатный параллелизм</em></a> или, что то же самое, через независимость итераций некоторых циклов (да-да-да, циклы - это понятие, возникающее лишь на этапе реализации, но здесь все так связано… В данном случае, координатный параллелизм означает, что информационно независимые вершины лежат на гиперплоскостях, перпендикулярных одной из координатных осей). С этой точки зрения, не менее важен и ресурс <a href="http://algowiki-project.org/ru/Глоссарий#.D0.A1.D0.BA.D0.BE.D1.88.D0.B5.D0.BD.D0.BD.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC"><em>скошенного параллелизма</em></a>. В отличие от координатного параллелизма, скошенный параллелизм намного сложнее использовать на практике, но знать о нем необходимо, поскольку иногда других вариантов и не остается: нужно оценить потенциал алгоритма, и лишь после этого, взвесив все альтернативы, принимать решение о конкретной параллельной реализации. Хорошей иллюстрацией может служить алгоритм, структура которого показана на рис.2: координатного параллелизма нет, но есть параллелизм скошенный, использование которого снижает сложность алгоритма с в последовательном случае до в параллельном варианте.</p>
<p><strong>Конечный параллелизм (finite parallelism)</strong> - параллелизм, определяемый информационной независимостью некоторых фрагментов в тексте программы.</p>
<p><strong>Массовый параллелизм (mass parallelism)</strong> - параллелизм, определяемый информационной независимостью итераций циклов программы.</p>
<p><strong>Координатный параллелизм (coordinate parallelism)</strong> - частный yслучай скошенного параллелизма, определяемый циклами ParDO, при котором информационно независимые вершины лежат на гипер-плоскостях, перпендикулярных одной из координатных осей.</p>
<p><strong>Скошенный параллелизм (skewed parallelism)</strong> - параллелизм в пространстве итераций, определяемый поверхностями уровней разверток. Ряд исследователей этим термином пользуется только для случая, когда параллелизм не является координатным.</p>
<p>Все можно найти на алговики – https://goo.gl/0AtOj7</p>
<p>Про граф алгоритма (инфо граф) – <a href="https://ru.wikipedia.org/wiki/Граф_алгоритма">https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D1%84_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0</a> ## 2. Архитектурные особенности графических процессоров, направленные на массивно параллельные вычисления. Методы эффективной организации параллельных вычислений на графических процессорах.</p>
<p>https://www.iis.nsk.su/files/articles/sbor_kas_16_poletaev.pdf</p>
<p>https://vk.com/<span class="citation" data-cites="physics_math-graficheskii-processor-ili-gpu">@physics_math-graficheskii-processor-ili-gpu</span></p>
<p>http://hpc-education.unn.ru/files/schools/hpc-2014/gpu/Lecture1_IntroToGPGPU.pdf</p>
<p>http://elar.urfu.ru/bitstream/10995/40616/1/978-5-7996-1722-6_2016.pdf</p>
<p>http://www2.rsuh.ru/binary/2632507_99.1424349071.26912.pdf</p>
<h4 id="архитектурные-особенности">Архитектурные особенности</h4>
<p>GPU (Graphics Processing Unit) предназначен для вычислений:</p>
<ul>
<li><p>параллельных по данным: одна и та же операция выполняется над многими данными параллельно,</p></li>
<li><p>в которых отношение вычислительных операций к числу операций по доступу к памяти велико.</p>
<p><img src="img\gpuarch.PNG" /></p></li>
</ul>
<p>Высокая вычислительная мощность GPU объясняется особенностями архитектуры. Современные CPU содержат несколько ядер, тогда как графический процессор изначально создавался как многопоточная структура с множеством ядер. Если архитектура CPU предполагает последовательную обработку информации, то GPU исторически предназначался для обработки компьютерной графики, поэтому рассчитан на массивно параллельные вычисления.</p>
<p>CPU лучше работает с последовательными задачами. При большом объёме обрабатываемой информации очевидное преимущество имеет GPU. Условие только одно — в задаче должен наблюдаться параллелизм.</p>
<p>Графический процессор может выполнить лишь часть операций, которые может выполнить центральный процессор, но он делает это с невероятной скоростью. GPU будет использовать сотни ядер, но для достижения высоких скоростей GPU должен выполнять однообразные операции.</p>
<p>Выбор концепции SIMD для графических процессоров обусловлен тем, что она обеспечивает параллельное использование большого количества «вычислителей» без явного управления ими: распределения задач, синхронизации вычислений и коммуникации между параллельными расчетами.</p>
<p>Тем не менее, центральные процессоры более гибкие, чем графические. Центральные процессоры имеют больший набор инструкций, поэтому они могут выполнять более широкий диапазон функций. Также CPU работают на более высоких максимальных тактовых частотах и имеют возможность управлять вводом и выводом компонентов компьютера в отличии от GPU.</p>
<p>Есть множество различий и в поддержке многопоточности. CPU исполняет 1-2 потока вычислений на одно процессорное ядро, а видеочипы могут поддерживать до 1024 потоков на каждый мультипроцессор, которых в чипе несколько штук. И если переключение с одного потока на другой для CPU стоит сотни тактов, то GPU переключает несколько потоков за один такт.</p>
<p>Различен и принцип работы с памятью у GPU и CPU. Так, все современные GPU имеют несколько контроллеров памяти, да и сама графическая память более быстрая, поэтому графические процессоры имеют гораздо б<em>о</em>льшую пропускную способность памяти, по сравнению с универсальными процессорами, что также весьма важно для параллельных расчетов, оперирующих огромными потоками данных.</p>
<p><img src="img\cpu_gpu.PNG" /></p>
<p>В универсальных процессорах б<em>о</em>льшую часть площади кристалла занимают различные буферы команд и данных, блоки декодирования, блоки аппаратного предсказания ветвления, блоки переупорядочения команд и кэш­память первого, второго и третьего уровней. Все эти аппаратные блоки нужны для ускорения исполнения немногочисленных потоков команд за счет их распараллеливания на уровне ядра процессора. Сами же исполнительные блоки занимают в универсальном процессоре относительно немного места.</p>
<p>В графическом процессоре, наоборот, основную площадь занимают именно многочисленные исполнительные блоки, что позволяет ему одновременно обрабатывать несколько тысяч потоков команд.</p>
<h4 id="методы-эффективной-организации-параллельных-вычислений-на-графических-процессорах">Методы эффективной организации параллельных вычислений на графических процессорах</h4>
<p>GPGPU – технология использования графического процессора для выполнения расчетов в приложениях общих вычислений. Это стало возможным благодаря добавлению программируемых шейдерных блоков и более высокой арифметической точности растровых контейнеров, что позволяет использовать потоковые процессоры для неграфических вычислений.</p>
<p>На сегодняшний день технология GPGPU реализована несколькими производителями:</p>
<ul>
<li><p>Khronos Group: OpenCL – язык программирования задач общего назначения, связанных с вычислениями на различных графических и центральных процессорах.</p></li>
<li><p>Компания nVidia: CUDA – технология GPGPU, позволяющая реализовывать на языке Си(или других языках программирования)вычислительные алгоритмы, выполняемые только на устройствах компании nVidia.</p></li>
</ul>
<p>Особо значимое ускорение в GPGPU можно получить, если одни и те же инструкции применяются к огромным массивам данных.</p>
<p>Следующим требованием можно назвать отсутствие взаимодействий между обрабатываемыми потоками или «слабое» взаимодействие.</p>
<p>Потоковая обработка данных особенно эффективна для алгоритмов, обладающих следующими свойствами, характерными для задач физического и математического моделирования:</p>
<ul>
<li><p>большая плотность вычислений — велико число арифметических операций, приходящихся на одну операцию ввода‑вывода (например, обращение к памяти). Во многих современных приложениях обработки сигналов она достигает 50:1, причем со сложностью алгоритмов увеличивается;</p></li>
<li><p>отсутствие в алгоритмах множественного ветвления;</p></li>
<li><p>локальность данных по времени — каждый элемент загружается и обрабатывается за время, малое по отношению к общему времени обработки, после чего он больше не нужен. В результате в памяти потокового процессора для каждого «вычислителя можно хранить только данные, необходимые для обработки одного элемента, в отличие от центральных процессоров с моделью произвольно зависимых данных.</p></li>
<li><p>одна и та же последовательность вычислений, применяемая к разным данным</p></li>
<li><p>могут быть разбиты на подзадачи одинаковой сложности (подзадача будет решаться блоком нитей)</p></li>
<li><p>каждая подзадача может быть выполнена независимо от всех остальных, нет потребности в глобальной синхронизации</p></li>
</ul>
<p>Возможные случаи параллелизма:</p>
<ul>
<li>Параллельные копирование и выполнение кода на GPU</li>
<li>Параллельное выполнение кода на GPU</li>
</ul>
<p>Если отсутствует возможность параллельного копирования памяти в обе стороны, то неправильный порядок отправки команд может привести к простою.</p>
<p>MPI + OpenMP + CUDA - хорошо гармонируют, так как MPI - ускорение экстенсивным путём, между процессорами, OpenMP - простое ускорение экстенсивным путём внутри процессора, а CUDA - ускорение интенсивным путём однотиповых вычислений.</p>
<p>Один CPU поток может управлять несколькими GPU, для этого нужно лишь переключать контексты. # 3. Основные принципы организации оптических и беспроводных систем передачи данных.</p>
<h3 id="оптические-системы">Оптические системы</h3>
<p><strong>Волоко́нно-опти́ческая связь</strong> — способ передачи информации, использующий в качестве носителя информационного сигнала электромагнитное излучение оптического (ближнего инфракрасного) диапазона, а в качестве направляющих систем — волоконно-оптические кабели. Благодаря высокой несущей частоте и широким возможностям мультиплексирования пропускная способность волоконно-оптических линий многократно превышает пропускную способность всех других систем связи и может измеряться Терабитами в секунду. Малое затухание света в оптическом волокне позволяет применять волоконно-оптическую связь на значительных расстояниях без использования усилителей. Волоконно-оптическая связь свободна от электромагнитных помех и труднодоступна для несанкционированного использования: незаметно перехватить сигнал, передаваемый по оптическому кабелю, технически крайне сложно.</p>
<p><strong>OTN</strong> – основная технология построения магистральных волоконно-оптических сетей связи на сегодняшний день, сменившая SDH/SONET (Synchronous Optical NETwork). Аббревиатура OTN расшифровывается как Optical Transport Network («оптическая транспортная сеть»). OTN - это оптическая транспортная сеть, которая обеспечивает передачу и мультиплексирование цифровых данных по волновым каналам DWDM (Dense Wavelength Division Multiplexing, плотное мультиплексирование с разделением по длине волны, обеспечивает передачу по волокну оптических сигналов на разных длинах волн). Технология OTN стандартизирована сектором телекоммуникаций Международного союза электросвязи (ITU-T) в декабре 2009 года, см. «ITU-T Recommendation G.709 «Interfaces for the Optical Transport Network (OTN)»».</p>
<p><strong>Принцип действия</strong> технологии OTN заключается в том, что сигналы различных форматов упаковываются в стандартные контейнеры, которые затем передаются по волоконно-оптической сети. Таким образом, обеспечивается возможность передачи по транспортной сети любых необходимых типов клиентских сигналов (STM, ATM, IP, Fibre Channel, InfiniBand и др.), а также эффективное использование пропускной способности за счет плотной упаковки разнородного трафика.</p>
<p>В заголовки контейнеров может добавляться служебная информация, которая позволяет контролировать прохождение трафика по сети и обнаруживать ошибки работы, а также избыточное кодирование, которое позволяет восстанавливать повреждённый трафик без необходимости его повторной передачи. Технология коррекции ошибок FEC, применяемая в сетях OTN, позволяет успешно восстанавливать переданный сигнал даже после существенных искажений и затуханий, что даёт возможность строить оптоволоконные магистрали OTN протяжённостью сотни и тысячи километров.</p>
<p><strong>Структура контейнера OTN</strong></p>
<p>Контейнер OTN строится путём добавления к исходным клиентским данным нескольких заголовков, каждый из которых выполняет свою функцию.</p>
<ul>
<li>Во-первых, клиентский трафик разбивается на части нужного размера, после чего к каждой из них добавляется заголовок, описывающий тип трафика. Получившийся блок информации называется OPU – Optical Payload Unit, «оптический блок нагрузки». Блок OPU передаётся в неизменном виде из конца в конец сети – т.е. от точки приёма клиентских данных до точки выдачи этих данных клиенту.</li>
<li>Во-вторых, к блоку OPU добавляется служебная информация, необходимая для мониторинга прохождения сигнала по сети и управления процессом передачи сигнала. Получившийся блок информации называется ODU – Optical Data Unit, «оптический блок данных». Блок ODU также передаётся в неизменном виде из конца в конец сети – т.е. от точки приёма клиентских данных до точки выдачи этих данных клиенту.</li>
<li>В-третьих, к блоку ODU добавляется избыточное кодирование (FEC, Forward Error Correction) и дополнительная служебная информация – для мониторинга, контроля и восстановления трафика на отдельном сегменте сети между двумя транспондерами. Получившийся блок информации называется OTU – Optical Transport Unit, «оптический транспортный блок». Блок OTU передаётся в неизменном виде в пределах участка сети, ограниченного транспондерами (т.е. пунктами, где сигнал преобразуется в электронный вид для <a href="https://ru.wikipedia.org/wiki/Оптический_регенератор">3R-регенерации</a>).</li>
</ul>
<p>Таким образом, по сети OTN передаются контейнеры OTU, каждый из которых представляет собой «матрёшку», где под несколькими слоями служебных данных скрывается исходный клиентский сигнал. Можно сказать, что клиентский сигнал «завёрнут» в несколько слоёв служебных данных – поэтому технологию OTN называют также «digital wrapper technology», или «optical channel wrapper» (англ. wrapper – обёртка).</p>
<p>G.709 определяет 6 уровней OTN потока</p>
<ul>
<li><p>OPU</p></li>
<li><p>ODU</p></li>
<li><p>OTU</p></li>
<li><p>OCh: Optical Channel. Представляет собой end-to-end оптический путь. Передается на несущей определенного “цвета”.</p></li>
<li><p>OMS: Optical Multiplex Section. Секция мультиплексирования. Работает между OADMs (Optical Add Drop Multiplexer). Используется для мониторинга оптического соединения и обнаружения проблем в OTN.</p></li>
<li><p>OTS: Optical Transport Section. Секция передачи. Работает в пределах участка сети, ограниченного двумя сетевыми элементами. Выполняет задачи контроля и обслуживания сети между сетевыми элементами (мультиплексоры, демультиплексоры, оптические коммутаторы и тд.).</p>
<p>Первые три - electrical domain, вторые три - optical domain.</p></li>
</ul>
<figure>
<img src="./otn_levels.png" alt="" /><figcaption>otn levels</figcaption>
</figure>
<figure>
<img src="./otn_structure.png" alt="" /><figcaption>otn structure</figcaption>
</figure>
<p><strong>FEC</strong></p>
<p>В процедуре прямой коррекции ошибок (FEC) используются коды Рида-Соломона RS(255, 239). В этом самокорректирующемся коде данные кодируются блоками по 255 байт, из которых 239 байт являются пользовательскими, а 16 байт представляют собой корректирующий код. Коды Рида-Соломона позволяют исправлять до 8 ошибочных байтов в блоке из 255 байт. Применение кода Рида-Соломона позволяет улучшить отношение мощности сигнала к мощности шума на 5дБ при уменьшении уровня битовых ошибок с 10−3(без применения FEC) до 10−2(после применения FEC). Этот эффект дает возможность увеличить расстояние между генераторами сети на 20 км или использовать менее мощные передатчики сигнала.</p>
<p><strong>Интерфейсы</strong></p>
<p>В рекомендации ITU-T G.872 описаны два типа интерфейсов для OTN: IrDI (Inter-Domain Interface) и IaDI (Intra-Domain Interface). Внешний интерфейс IrDI встречается при присоединении сети одного оператора к сети другого оператора, на внутренних стыках различных подсетей одного оператора и на стыках однотипного оборудования внутри одной подсети. Внутренний интерфейс IaDI встречается только на стыках однотипного оборудования одной подсети.</p>
<figure>
<img src="./otn_interfaces.png" alt="" /><figcaption>OTN interfaces</figcaption>
</figure>
<p><a href="https://asvk.cs.msu.su/~bahmurov/course_advanced_networks/2018//%D0%A7%D1%82%D0%BE%20%D1%82%D0%B0%D0%BA%D0%BE%D0%B5%20OTN.PDF">Подробно про структуру заголовков OTN можно прочитать тут</a></p>
<h3 id="беспроводные-системы">Беспроводные системы</h3>
<p><strong>Беспроводная вычислительная сеть</strong> — вычислительная сеть, основанная на беспроводном (без использования кабельной проводки) принципе, полностью соответствующая стандартам для обычных проводных сетей (например, Ethernet). В качестве носителя информации в таких сетях могут выступать радиоволны СВЧ-диапазона.</p>
<p><strong>ALOHAnet</strong> — первая компьютерная сеть передачи данных с пакетной коммутацией, использовавшая в качестве среды доступа к ней беспроводную технологию. Была разработана и введена в эксплуатацию в 1968—1970-х годах группой учёных Гавайского университета под руководством Нормана Абрамсона в рамках исследовательского проекта THE ALOHA SYSTEM, основной целью которого было изучение возможностей использования радиопередачи как альтернативы проводным коммуникациям. В чистой ALOHA вещание, как и в радио, может начаться в любой момент, все устройства слушают и передают на одной частоте -&gt; могут возникать коллизии.</p>
<p>Поэтому придумали <strong>Carrier Sense Multiple Access With Collision Avoidance</strong> (<strong>CSMA/CA</strong>, множественный доступ с контролем несущей и избеганием коллизий) — это сетевой протокол, в котором:</p>
<ul>
<li>используется схема прослушивания несущей волны</li>
<li>станция, которая собирается начать передачу, посылает jam signal (сигнал затора) (RTS в WiFi);</li>
<li>после продолжительного ожидания всех станций, которые могут послать jam signal (RTS), станция начинает передачу фрейма</li>
<li>если во время передачи станция обнаруживает jam signal (RTS) от другой станции, она останавливает передачу на отрезок времени случайной длины и затем повторяет попытку</li>
</ul>
<p>Беспроводные сети делятся на два типа: локальные (WLAN) и мобильные сотовые сети.</p>
<p>Примеры WLAN: WiFi, WiMAX (сейчас практически нигде не используется)</p>
<p>Сотовые сети: AMPS, GSM, CDMA2000, LTE, etc</p>
<p><strong>Технологии, использующиеся в беспроводных сетях для увеличения скорости:</strong></p>
<ul>
<li><p>MIMO</p></li>
<li><p>OFDM (orthogonal frequency division multiplexing)</p></li>
<li><p>Увеличение ширины канала</p></li>
</ul>
<p><strong>Сотовая связь</strong> – один из видов мобильной радиосвязи, в основе которого лежит сотовая сеть. Зона покрытия сети делится на ячейки (соты), определяющиеся зонами покрытия отдельных базовых станций. Основной идеей, на которой базируется принцип сотовой связи, является повторное использование частот в несмежных сотах. Каждая из ячеек обслуживается своим передатчиком с невысокой выходной мощностью и ограниченным числом каналов связи. Это позволяет без помех использовать повторно частоты каналов этого передатчика в другой, удаленной на значительное расстояние, ячейке. Это хорошо иллюстрируется раскраской сот, использующих один диапазон частот, в одинаковый цвет и сот, использующих разные диапазоны, в разные цвета. Таким образом сеть делится минимум на 3 кластера.</p>
<p><img src="./mobile_cells.png" alt="mobile cells" style="zoom:40%;" /></p>
<p><strong>Основные принципы сотовых сетей</strong></p>
<ul>
<li>Использование лицензируемого спектра радиочастот (в России выделяется ГКРЧ): для сетей 4G диапазон 900 MГц – 3500 MГц</li>
<li>Централизованное управление: все передачи пользовательских устройств управляются сетью (базовыми станциями)</li>
</ul>
<p><strong>Wi-Fi</strong> — технология беспроводной локальной сети с устройствами на основе стандартов IEEE 802.11. Работает в диапазоне 2.4 ГГц и 5 ГГц. В 802.11ay - 60 ГГц (миллиметровый WiFi). Может работать по двум схемам: с точкой доступа и в режиме ad-hoc. Основной протокол для доступа к среде передачи данных - DCF. DCF использует метод CSMA/CA вместе с алгоритмом двоичной экспоненциальной отсрочки.</p>
<p><strong>DCF</strong></p>
<p>Пока канал занят, станция ничего не передает. После освобождения канала станция ждёт дополнительно интервал времени <em>DIFS</em>. В сетях с большим числом станций передача нескольких станций сразу по окончании интервала DIFS может привести к коллизиям, поэтому каждая станция генерирует счётчиком отсрочки (англ. backoff). backoff - это случайное число в интервале (0, CWmin], где CWmin - это конкурентное окно (англ. contention window). Станция слушает канал время <span class="math inline"><em>σ</em></span>, определённое в стандарте как время пустого слота, и, если канал был свободен, уменьшает счётчик отсрочки на единицу. Если канал был занят, то станция замораживает свой счётчик отсрочки и ждёт пока канал освободится, далее ждёт интервал DIFS и размораживает счётчик отсрочки. Когда счётчик отсрочки достигает нуля, станция передаёт кадр данных.</p>
<p>DCF включает в себя необходимость подтверждения успешного приёма кадра данных, таким образом если станция после отправки своего кадра не получила кадр подтверждения (англ. acknowledgment, ACK), она считает передачу неуспешной.</p>
<p>Если передача была неуспешной (из-за коллизии станций или помех), станция вновь генерирует backoff из интервала (0, 2CWmin]. Конкурентное окно увеличивается вдвое каждый раз после неудачной попытки передачи кадра данных пока не достигнет значения CWmax. Если конкурентное окно достигло максимума, станция его не меняет до тех пор пока не будет достигнут предел количества попыток передач (англ. retry limit) кадра данных.</p>
<p>По достижении предельного числа попыток передач кадра данных станция сбрасывает кадр данных и начинает пытаться передавать следующий кадр данных из очереди FIFO. Если это был <em>первый</em> сброшенный кадр данных, станция сбрасывает конкурентное окно до значения (0, CWmin] и вновь его экспоненциально наращивает. Если же станция сбросила два кадра данных подряд, то все последующие кадры данных передаются на максимальном конкурентном окне до тех пор, пока хотя бы один кадр данных не будет передан успешно. Если кадр данных был передан успешно, то для следующего кадра данных используется минимальное конкурентное окно (0, CWmin].</p>
<p>Дополнительно станции могут использовать механизм RTS/CTS, который заключается в предварительной отправке кадров Request-to-Send (англ. Запрос на передачу) передающей станцией и Clear-to-Send (англ. Разрешение передачи) принимающей станцией. Кадр RTS короткий, и попадание в коллизию двух кадров RTS менее болезненно, чем попадание в коллизию двух длинных кадров данных. Если кадр данных слишком короткий, использование RTS/CTS может быть неэффективно — в таком случае используется RTS порог (англ. RTS Threshold), который определяет максимальную длину кадра данных, который будет передан без использования механизма RTS/CTS. В кадрах RTS/CTS дополнительно устанавливается TXOP (англ. transmission opportunity, рус. возможность передачи) — интервал виртуальной занятости канала, в течение которого другие станции должны воздерживаться от начала своей передачи. RTS/CTS позволяет частично (но не полностью) решить проблемы скрытых и засвеченных станций.</p>
<p><strong>4 Сети хранения данных – архитектура и основные сервисы.</strong></p>
<p><strong>Сеть хранения данных</strong> (СХД, англ. Storage Area Network, SAN) — представляет собой архитектурное решение для подключения внешних устройств хранения данных, таких как дисковые массивы, ленточные библиотеки, оптические приводы к серверам таким образом, чтобы операционная система распознала подключенные ресурсы как локальные. Большинство сетей хранения данных использует протокол SCSI для связи между серверами и устройствами хранения данных на уровне шинной топологии. Так как протокол SCSI не предназначен для формирования сетевых пакетов, в сетях хранения данных используются низкоуровневые <strong>протоколы</strong>:</p>
<ul>
<li>Fibre Channel Protocol (FCP), транспорт SCSI через Fibre Channel. Наиболее часто используемый на данный момент протокол. Существует в вариантах 1 Gbit/s, 2 Gbit/s, 4 Gbit/s, 8 Gbit/s, 10 Gbit/s, 16 Gbit/s, 20 Gbit/s.</li>
<li>iSCSI, транспорт SCSI через TCP/IP.</li>
<li>iSER, транспорт iSCSI через InfiniBand / RDMA.</li>
<li>SRP, транспорт SCSI через InfiniBand / RDMA</li>
<li>FCoE, транспортировка FCP/SCSI поверх «чистого» Ethernet.</li>
<li>FCIP и iFCP, инкапсуляция и передача FCP/SCSI в пакетах IP.</li>
<li>HyperSCSI, транспорт SCSI через Ethernet.</li>
<li>FICON транспорт через Fibre Channel (используется только мейнфреймами).</li>
<li>ATA over Ethernet, транспорт ATA через Ethernet.</li>
</ul>
<p><strong>Технологически SAN состоит из следующих компонентов:</strong></p>
<ul>
<li>Узлы, ноды (nodes)
<ul>
<li>Дисковые массивы (системы хранения данных) — хранилища (таргеты [targets])</li>
<li>Серверы — потребители дисковых ресурсов (инициаторы [initiators]).</li>
</ul></li>
<li>Сетевая инфраструктура
<ul>
<li>Коммутаторы (и маршрутизаторы в сложных и распределённых системах)</li>
<li>Кабели</li>
</ul></li>
</ul>
<p>Для SAN ключевыми параметрами являются не только производительность, но и надёжность. Ведь если у сервера БД пропадёт сеть на пару секунд (или даже минут) — ну неприятно будет, но пережить можно. А если на это же время отвалится жёсткий диск с базой или с ОС, эффект будет куда более серьёзным. Поэтому все компоненты SAN обычно дублируются — порты в устройствах хранения и серверах, коммутаторы, линки между коммутаторами и, ключевая особенность SAN, по сравнению с LAN — дублирование на уровне всей инфраструктуры сетевых устройств — фабрики.<strong>Фабрика</strong> (fabric — что вообще-то в переводе с английского ткань, т.к. термин символизирует переплетённую схему подключения сетевых и конечных устройств, но термин уже устоялся) — совокупность коммутаторов, соединённых между собой межкоммутаторными линками (ISL — InterSwitch Link). Высоконадёжные SAN обязательно включают две (а иногда и более) фабрики, поскольку фабрика сама по себе — единая точка отказа. Фабрики могут иметь идентичную (зеркальную) топологию или различаться. Например одна фабрика может состоять из четырёх коммутаторов, а другая — из одного, и к ней могут быть подключены только высококритичные узлы.</p>
<p><strong>Различают следующие виды топологий фабрики:</strong></p>
<ul>
<li><strong>Каскад</strong> — коммутаторы соединяются последовательно. Если их больше двух, то ненадёжно и непроизводительно.</li>
<li><strong>Кольцо</strong> — замкнутый каскад. Надёжнее просто каскада, хотя при большом количестве участников (больше 4) производительность будет страдать. А единичный сбой ISL или одного из коммутаторов превращает схему в каскад со всеми вытекающими.</li>
<li><strong>Сетка (mesh)</strong>. Бывает <strong>Full Mesh</strong> — когда каждый коммутатор соединяется с каждым. Характерно высокой надежностью, производительностью и ценой. Количество портов, требуемое под межкоммутаторные связи, с добавлением каждого нового коммутатора в схему растет экспоненциально. При определённой конфигурации просто не останется портов под узлы — все будут заняты под ISL. <strong>Partial Mesh</strong> — любое хаотическое объединение коммутаторов.</li>
<li><strong>Центр/периферия</strong> (Core/Edge) — близкая к классической топологии LAN, но без уровня распределения. Нередко хранилища подключаются к Core-коммутаторам, а серверы — к Edge. Хотя для хранилищ может быть выделен дополнительный слой (tier) Edge-коммутаторов. Также и хранилища и серверы могут быть подключены в один коммутатор для повышения производительности и снижения времени отклика (это называется локализацией). Такая топология характеризуется хорошей масштабируемостью и управляемостью.</li>
</ul>
<p><strong>Архитектура дисковой подсистемы (ДПС)</strong> Все порты ДПС подключаются к контроллеру. Контроллер управляет дисками и кешем. Часть дисков используется для резервирования, поэтому объем памяти, предоставляемый пользователям обычно меньше реального объема. В ДПС может использоваться дублирование каналов связи, для повышения надежности. При выходе из строя одной линии связи, можно переключиться на вторую для доступа к диску. При нормальной работе каналы, по которым происходит доступ к дискам, могут быть фиксированы (запросы к одному диску всегда идут по одному каналу) или выбираться динамически (решение, по какому каналу отправлять запрос принимает контроллер в каждом отдельном случае). См. рисунок ниже.</p>
<figure>
<img src="https://lh3.googleusercontent.com/QqsTzcm0nsGdyTmDQGB-vdTIlHFejR4IdyIIB_S2DV6nXTyUjLJPLPadAMZQHSTqNNpAiWjK8ua0do4YK5M4AFU3YwTv3n9TVfE64rb7K4n-3VJqUTlcV6Dn49MYlxA_fFYN1IHu" alt="" /><figcaption>img</figcaption>
</figure>
<p><strong>Для резервирования данных используются:</strong></p>
<ul>
<li>Горячий дисковый резерв - все диски дублируются, используется активное резервирование</li>
<li>RAID массивы - избыточный массив независимых дисков.</li>
</ul>
<p><strong>Для обеспечения устойчивости работоспособности ДПС используются разные техники:</strong></p>
<ul>
<li>Данные распределяют по нескольким дискам с помощью механизмов RAID и снабжают избыточными данными (блоки четности).</li>
<li>На каждом физическом диске данные закодированы кодом Хемминга. Кроме этого диск оснащен подсистемой самодиагностики, которая контролирует частоту ошибок, вибрацию шпинделя и т.д. Это позволяет проактивно прогнозировать отказы диска.</li>
<li>Каждый диск подсоединен к контроллеру хотя бы через две внутренние шины.</li>
<li>Контроллер дисковой подсистемы может быть продублирован. Выход одного экземпляра, автоматически будет активизировать следующий экземпляр. Схема Active-Standby.</li>
<li>Используют периодическое мгновенное копирование для защиты от логических ошибок. Например, создание мгновенной копии данных через каждый час. Тогда в случае сбоя и уничтожения какой-то таблицы, она может быть восстановлена.</li>
<li>Удаленное зеркалирование (копирование всех данных в удаленную сеть хранения данных) используют от физического уничтожения или повреждения оборудования (катастрофоустойчивость). В сочетании с мгновенным копированием эти сервисы гарантируют сохранение и консистентность данных даже для нескольких виртуальных дисков или дисковых подсистем.</li>
<li>LUN (Logical Unit Number) маскирование защищает от несанкционированного доступа, упрощает работу системного администратора, защищает от случайных сбоев в работе приложений серверов и их оборудования.</li>
</ul>
<p><strong>LUN (Logical Unit Number) маскирование</strong></p>
<p>LUN не означает отдельный жесткий диск, скорее он определяет виртуальный раздел в RAID-массиве. При этом один и тот же виртуальный раздел массива может иметь разные значения LUN для разных хостов, которым этот LUN назначен. Также возможно наличие на одном хосте одинаковых LUN, принадлежащих разным системам хранения (разным SCSI Target ID).</p>
<p>Таким образом, полный адрес диска (физического раздела жёсткого диска) на SCSI-устройстве складывается из SCSI Target ID (уникального для хоста и определяемого драйвером) и LUN, уникального в пределах SCSI-устройства и назначаемого ему в настройках или автоматически по порядку.</p>
<p><strong>Преимущества</strong> Совместное использование систем хранения, как правило, упрощает администрирование и добавляет изрядную гибкость, поскольку кабели и дисковые массивы не нужно физически транспортировать и перекоммутировать от одного сервера к другому.</p>
<p>Другим преимуществом является возможность загружать сервера прямо из сети хранения. При такой конфигурации можно быстро и легко заменить сбойный сервер, переконфигурировав SAN таким образом, что сервер-замена будет загружаться с LUN’а (LUN, Logical Unit Number - адрес дискового устройства в SAN) сбойного сервера. Эта процедура может занять, например, полчаса. Идея относительно новая, но уже используется в новейших датацентрах.</p>
<p>Дополнительным преимуществом является возможность на хосте собрать RAID-зеркало из LUNов, которые презентованы хосту с двух разных дисковых массивов. В таком случае полный отказ одного из массивов не навредит хосту.</p>
<p>Также сети хранения помогают более эффективно восстанавливать работоспособность после сбоя. В SAN может входить удаленный участок со вторичным устройством хранения. В таком случае можно использовать репликацию — реализованную на уровне контроллеров массивов, либо при помощи специальных аппаратных устройств. # 5. Принципы организации и основные достоинства MPLS технологии.</p>
<p>Проблема: протоколам маршрутизации для передачи пакета на следующий хоп нужно смотреть заголовок пакета и локальную таблицу маршрутизации, причем это происходит на каждом хопе. Таким образом на каждом маршрутизаторе по сути нужно иметь полную таблицу маршрутизации и делать лукап по адресу назначения на каждом хопе.</p>
<p>Решение: MPLS — уменьшает оверхед на непосредственно маршрутизацию, может маршрутизировать не только IP.</p>
<p>BTW</p>
<p>На самом деле сейчас стала широко доступна аппаратная IP маршрутизация, поэтому лучше сказать, что MPLS решает проблему универсальности доставки — совершенно неважно, что находится под меткой — IP, Ethernet, ATM, Frame Relay. В основном сейчас MPLS применяется для VPN и TE. Еще один плюс применения чистого MPLS — возможность сделать так, чтобы не нужно было настраивать BGP на каждом роутере для IBGP, достаточно раутить по меткам.</p>
<h2 id="mpls-control-plane">MPLS Control Plane</h2>
<p><img src="img/Screenshot 2020-05-26 at 20.26.35.png" alt="Screenshot 2020-05-26 at 20.26.35" style="zoom: 33%;" /></p>
<p>Заполняется новая таблица с метками, метками обмениваются как и IP адресами, заполняется соответствующая таблица.</p>
<h2 id="mpls-data-plane">MPLS Data Plane</h2>
<p><img src="img/Screenshot 2020-05-26 at 20.26.53.png" alt="Screenshot 2020-05-26 at 20.26.53" style="zoom:33%;" /></p>
<p>Маршрутизация может проводится на основе обоих таблиц.</p>
<h2 id="mpls-устройства">MPLS устройства</h2>
<p><strong>LSR</strong> — маршрутизатор в домене MPLS. Передает и принимает только пакеты с метками. Может менять метки при передаче пакета.</p>
<p><strong>Edge LSR</strong> — стоит на границе MPLS домена. Производит установку первой метки при входе в MPLS домен и снятия последней при выходе из домена.</p>
<p>LSR, которые не Edge будем называть <strong>core LSR</strong>.</p>
<p>Сами Edge по понятному принципу делятся на <strong>Ingress Edge LSR</strong> и <strong>Egress Edge LSR</strong> (вход и выход из MPLS домена соотвественно)</p>
<p>Таким образом исходный лукап в таблицу маршрутизации происходит только на Edge LSR. Остальные LSR делают лукап по меткам только в Label Forwarding Table.</p>
<h2 id="mpls-метки">MPLS метки</h2>
<ul>
<li>Определяют FEC (forwarding equivalence class) — класс эквивалентности маршрутизации — по сути это IP + маска на egress.</li>
<li>Имеют локальную значимость. Каждый lsr сам выбирает метку и FEC и передает эту информацию другим LSR.</li>
</ul>
<p>По сути FEC — это группа пакетов, которые передаются по одному пути. MPLS маршрутизация состоит из назначения пакета на FEC, определения следующего хода для FEC.</p>
<p>MPLS метка имеет размер 32 бита из которых:</p>
<ul>
<li>Первые 20 — сама метка</li>
<li>3 бита — TC (Traffic class) — очередной QoS</li>
<li>Индикатор S — 1 бит — указывает последняя ли это метка перед IP пакетом (нужно для парсинга)</li>
<li>8 бит TTL — копируется из IP пакета</li>
</ul>
<p>Сами метку называются между 2 и 3 уровнями ISO/OSI. То есть IP пакет сначала заворачиваем в MPLS, а затем уже в L2 фрейм.</p>
<p>В лекции выделяют:</p>
<ul>
<li>Frame-mode MPLS. Именно то, что описано выше, кладем информацию между 2 и 3 уровнями.</li>
<li>Cell-mode MPLS is MPLS over ATM. Есть такой L2 протокол ATM. Там есть куда куда впихнуть метки в самом протоколе, дополнительные сущности таким образом не нужны.</li>
</ul>
<p>Для задач маршрутизации обычно достаточно одной метки, но с помощью MPLS можно организовывать всякие сложные вещи, увеличивая количество меток:</p>
<ul>
<li>MPLS VPNs (2 метки): Одна метка для маршрутизации, другая для указания VPN (туннеля).</li>
<li>MPLS TE (2 и больше меток): Тут подразумевается, например, балансировка нагрузки, одна из меток позволяет указать класс (туннель) TE.</li>
<li>Все вместе: много меток</li>
</ul>
<p>Последняя метка всегда используется для маршрутизации.</p>
<p>Парить все это просто. Для L2 пакетов есть EtherType, указывающий, что пакет начинается с метки <em>0x8847</em> (на самом деле тут еще указано, что это юникаст), дальше снимаем по 32 бита и смотрим на индикатор S.</p>
<h2 id="операции-над-mpls-метками">Операции над MPLS метками</h2>
<p>Ранее говорилось, что LSR может менять метки при передаче пакета. Что это, зачем это.</p>
<p>LSR может сделать 3 вещи:</p>
<ul>
<li><p>Вставить одну или несколько меток (Ingress Edge LSR)</p></li>
<li><p>Поменять одну или несколько меток (core LSR)</p></li>
<li><p>Удалить метку (pop) (Egress Edge LSR)</p></li>
</ul>
<p>Пример:</p>
<p><img src="img/Screenshot 2020-05-26 at 21.01.59.png" alt="Screenshot 2020-05-26 at 21.01.59" style="zoom: 50%;" /></p>
<h2 id="практическое-применение-mpls">Практическое применение MPLS</h2>
<p>Применение:</p>
<ul>
<li><p>Unicast IP routing</p></li>
<li><p>Multicast IP routing</p></li>
<li><p>MPLS TE</p></li>
<li><p>QoS</p></li>
<li><p>MPLS VPNs (на этом кстати фокусировался по хорошему наш курс)</p></li>
<li><p>AToM (раньше про это не было, это возможность завернуть любой L2 в MPLS и другой L2)</p></li>
</ul>
<p>Более подробно будем рассматривать только Unicast IP routing (база) и MPLS VPNs (слишком много про них было).</p>
<p>Для начала нужно разобраться как обнаруживать соседей и передавать метки, мы же все таки маршрутизацией занимаемся.</p>
<h2 id="присваивание-и-распространение-меток">Присваивание и распространение меток</h2>
<h3 id="обнаружение-соседей">Обнаружение соседей</h3>
<p>Метки распространяются благодаря алгоритму LDP (Label Distribution Protocol).</p>
<p>Установление сессии:</p>
<ol type="1">
<li>Рассылка Hello сообщений (UDP multicast на адреса в той же подсети с TTL 1) на интерфейсы, с MPLS enabled</li>
<li>Ответ на Hello сообщение — попытка установить сессию (на самом деле инициатором установки соединения будет тот LSR у которого IP больше)</li>
</ol>
<p>Сама сессия устанавливается по TCP.</p>
<p>После этого происходит обмен инициализационными сообщениями и начинают посылаться keepalive сообщения.</p>
<p>Несмежные соседи могут соединяться схожим образом, только вместо multicast — unicast, это называется tLDP, иногда это нужно.</p>
<h3 id="распространение-меток">Распространение меток</h3>
<p><img src="img/Screenshot 2020-05-27 at 05.08.49.png" alt="Screenshot 2020-05-27 at 05.08.49" style="zoom:50%;" /></p>
<p>Подробного описания нет, но все достаточно очевидно — посылаем соседям те метки и IP адреса, которые у нас есть — при получении заполняем LIB, FIB и LFIB. Отметим, что без отработавшего OSPF это все работать не будет.</p>
<p>Но откуда вообще взять метки? Для этого нужен LSP.</p>
<h3 id="label-switched-path-и-построение-пути">Label-Switched Path и построение пути</h3>
<p>LSP — последовательность LSR, передающих помеченные пакеты определенного FEC.</p>
<p>Таким образом:</p>
<ul>
<li>Строятся LSP исходя из IP маршрутизации (например OSPF)</li>
<li>LDP распространяет метки на отдельные сегменты LSP.</li>
</ul>
<p>Все происходит примерно так:</p>
<ul>
<li>Egress роутер обнаруживает изменение в таблице маршрутизации</li>
<li>Выбирает какой нибудь FEC (ip+маска из dst таблицы маршрутизации) и выбирает для нее метку (любую) (так происходит для всех dest)</li>
<li>Эту информацию он через LDP передает своим соседям</li>
<li>Соседи генерируют свою метку, заполняют LIB, FIB и LFIB и передают своим соседям</li>
<li>В итоге построен LSP путь</li>
<li>Если найдено несколько путей используется лучший по некоторой метрике (как и в других алгоритмах маршрутизации)</li>
<li>Гифка из СДСМ: https://gblobscdn.gitbook.com/assets%2F-LIgRTPaaN7wUujKIWEz%2F-LXhL-JzPMdG-IAZwDzA%2F-LXhLLisFxolb93jgcCx%2Fb1371acab49e47c9bab46aa0af23123b.gif</li>
<li>RFC: https://tools.ietf.org/html/rfc5036</li>
</ul>
<h3 id="php">PHP</h3>
<p><strong>Penultimate Hop Popping</strong> — оптимизация от бога, удаляем все метки на предпоследнем маршрутизаторе, чтобы не делать лишних лукапов в последнем.</p>
<p>Гифка: https://gblobscdn.gitbook.com/assets%2F-LIgRTPaaN7wUujKIWEz%2F-LfxxzdGb7gGgdgvPhmC%2F-Lfxzrl0AYwgGNeu29Rs%2F2c74499985d7463da7e67beac679038f-1.gif</p>
<h3 id="про-сходимость">Про сходимость</h3>
<p>Все сходится неплохо, но медленнее чем IGP, поэтому предлагается использовать MPLS TE (видимо резервные пути), чтобы избежать проблем при падении линка.</p>
<h2 id="vpn">VPN</h2>
<p>С помощью MPLS можно сформировать провайдерский VPN.</p>
<p>Основные понятия для VPN:</p>
<p><strong>CE — Customer Edge router</strong> — граничный маршрутизатор клиента, который подключен в сеть провайдера.</p>
<p><strong>PE — Provider Edge router</strong> — граничный маршрутизатор провайдера. Собственно к нему и подключаются CE. На PE зарождается VPN, на нём они и кончаются. Именно на нём расположены интерфейсы, привязанные к VPN. Именно PE назначает и снимает сервисные метки. Именно PE являются Ingress LSR и Egress LSR. PE должны знать таблицы маршрутизации каждого VPN, ведь это они принимают решение о том, куда посылать пакет, как в пределах провайдерской сети, так и в плане клиентских интерфейсов.</p>
<p><strong>P — Provider router</strong> — транзитный маршрутизатор, который не является точкой подключения — пакеты VPN проходят через него без каких-либо дополнительных обработок, иными словами просто коммутируются по транспортной метке. P нет нужды знать таблицы маршрутизации VPN или сервисные метки. На P нет интерфейсов привязанных к VPN.</p>
<p>Основные понятия для MPLS:</p>
<p>Центральное понятие здесь <strong>VRF</strong> — Virtual Routing and Forwarding instance — нужна как гарантия чтобы ограничивать раутинг, если разные клиенты используют одни и те же частные сети. VRF — он строго локален для маршрутизатора — за его пределами VRF не существует. Соответственно VRF на одном маршрутизаторе никак не связан с VRF на другом.</p>
<p>MPLS VPN VRF создаются только на тех маршрутизаторах к которым подключены клиенты. Далее принадлежность к конкретному VPN определяется MPLS меткой. Остаётся вопрос, как найти выходной маршрутизатор.</p>
<figure>
<img src="img/0_107085_688266c0_L.png" alt="" /><figcaption>img</figcaption>
</figure>
<p>Все верно используем две метки — одну для раутинга на внутренних LSR, вторую для обозначения принадлежности к VPN, она будет использоваться только на Ingress и Egress. Заметим, что в качестве FEC в данной случае будет использоваться адрес последнего LSR в MPLS сети.</p>
<p>Конечно нужно как то выбрать одну метку для одного VPN на Ingress и Egress — для этого используется протокол MP-BGP.</p>
<p>Итого все вместе:</p>
<p>Маршрутизатор PE навешивает на клиентский трафик две метки — внутреннюю сервисную, которая не меняется до самого конца путешествия и по ней последний PE понимает, какому VRF принадлежит пакет, и внешнюю транспортную, по которой пакет передаётся через сеть провайдера — эта метка меняется на каждом P-маршрутизаторе и снимается на последнем PE или предпоследнем P. Благодаря наличию сервисной метки и VRF трафик различных VPN изолирован друг от друга как в пределах маршрутизаторов, так и в каналах.</p>
<h2 id="ps">PS</h2>
<p>Если хочется разобраться можно почитать слайды и СДСМ.</p>
<h1 id="программно-конфигурируемые-сети-sdn.-основные-принципы-архитектура-и-преимущества.-протокол-openflow.-структура-openflow-контроллера-и-коммутатора.-примеры-применения.">6. Программно-конфигурируемые сети (SDN). Основные принципы, архитектура и преимущества. Протокол OpenFlow. Структура OpenFlow контроллера и коммутатора. Примеры применения.</h1>
<h2 id="основные-принципы">Основные принципы</h2>
<p>Программно-Конфигурируемые Сети (Software Defined Networking/SDN) — это разделение плоскости передачи и управления данными, позволяющее осуществлять программное управление плоскостью передачи, которое может быть физически или логически отделено от аппаратных коммутаторов и маршрутизаторов.</p>
<ol type="1">
<li>Физически разделить уровень управления сетевым оборудованием от уровня управления передачей данных.</li>
<li>Перейти от управления отдельными экземплярами сетевого оборудования к управлению сетью в целом – логически централизованное управление.</li>
<li>Создать открытый программно-управляемый интерфейс между сетевыми приложениями и транспортной сетью.</li>
</ol>
<h2 id="архитектура">Архитектура</h2>
<p><img src="img/Screenshot 2020-05-27 at 06.25.58.png" alt="Screenshot 2020-05-27 at 06.25.58" style="zoom:25%;" /></p>
<p><img src="img/Screenshot 2020-05-27 at 06.53.19.png" alt="Screenshot 2020-05-27 at 06.53.19" style="zoom: 33%;" /></p>
<h2 id="преимущества">Преимущества</h2>
<ul>
<li>Удешевление оборудования</li>
<li>Облегчение управления сетью</li>
<li>Программируемость, открытость, инновации</li>
</ul>
<h2 id="openflow">OpenFlow</h2>
<p><img src="img/Screenshot 2020-05-27 at 06.27.49.png" alt="Screenshot 2020-05-27 at 06.27.49" style="zoom: 33%;" /></p>
<p>Поддерживается три типа сообщений:</p>
<ul>
<li>Сообщения контроллер-коммутатор
<ul>
<li>Конфигурирование коммутатора</li>
<li>Управление и контроль состояния</li>
<li>Управление таблицами потоков</li>
<li>Features, Configuration, Modify-State (flow-mod), Read-State (multipart request), Packet-out, Barrier, Role-Request</li>
</ul></li>
<li>Симметричные сообщения
<ul>
<li>Отправкавобоихнаправлениях</li>
<li>Обнаружение проблем соединения контроллера с коммутатором – Hello,Echo</li>
</ul></li>
<li>Ассиметричные сообщения
<ul>
<li>Отправка от коммутатора к контроллеру</li>
<li>Объявляют об изменении состояния сети, состояния коммутаторов</li>
<li>Packet-in, flow-removed, port-status, error</li>
</ul></li>
</ul>
<h3 id="версии-openflow-это-можно-отнести-к-структуре-коммутатора">Версии OpenFlow (это можно отнести к структуре коммутатора)</h3>
<p>В 1.0 была только одна таблица потоков, что приводило к большому росту числа правил. В 1.1 таблиц стало несколько.</p>
<p>Также появились групповые таблицы позволяющие задать ряд действий и выбирать:</p>
<ul>
<li>Использование всех</li>
<li>Одного случайного</li>
<li>Одного определенного</li>
<li>Первого живого</li>
</ul>
<p>Также появилась Meter Table для учета количества трафика.</p>
<p>В версии 1.2 появились сценарии отказоустойчивости для контроллеров — Master / Slave.</p>
<p>Для быстрого матчинга в коммутаторах используется TCAM (Ternary Content Addressable Memory). Это когда у бита целых три значения — 0, 1 и ?, выдается адрес первой подходящей строки. Эта штука работает за константное время.</p>
<h3 id="структура-openflow-контроллера">Структура OpenFlow контроллера</h3>
<ul>
<li>Программа,TCP/IPсервер,ожидающий подключения коммутаторов</li>
<li>Отвечает за обеспечение взаимодействие приложения-коммутатор.</li>
<li>Предоставляет важные сервисы(например, построение топологии, мониторинг хостов)</li>
<li>API сетевой ОС или контроллер предоставляет возможность создавать приложения на основе централизованной модели программирования.</li>
</ul>
<figure>
<img src="img/image-20200527063455691.png" alt="" /><figcaption>image-20200527063455691</figcaption>
</figure>
<h3 id="схема-работы-openflow">Схема работы OpenFlow</h3>
<ul>
<li>Реактивный режим</li>
<li>Проактивный режим</li>
</ul>
<p>Топология строится с помощью LLDP. Суть в том, что посылается Packet-Out на один из свитчей (на определенный порт), потом анализируется откуда пришел Packet-In и таким образом строится линк.</p>
<h2 id="варианты-применения-sdnopenflow">Варианты применения SDN/OpenFlow</h2>
<p>Области применения:</p>
<ul>
<li>Компании</li>
<li>Телеком операторы и сервис провайдеры</li>
<li>ЦОД и облака</li>
</ul>
<p>Один из примеров применения:</p>
<p>Интеллектуальный Traffic Engineering:</p>
<ul>
<li>Выбор оптимального пути</li>
<li>Реакция на отказ канала</li>
<li>Резервирование пропускной способности</li>
</ul>
<p>И так можно придумать еще кучу всего. <strong>7. Виртуализация сетевых сервисов (NFV). Основные принципы, этапы развития, архитектура, преимущества. Примеры применения.</strong></p>
<p>Виртуализация сетевых функций (NFV) - это способ виртуализации сетевых служб, таких как маршрутизаторы, брандмауэры и балансировщики нагрузки, которые традиционно выполнялись на проприетарном оборудовании. Эти сервисы упаковываются в виртуальные машины, которые выполняются на обычном оборудовании, что позволяет поставщикам услуг запускать свою сеть на стандартных серверах вместо проприетарных. Таким образом оператор сети перестает зависеть от одного поставщика сетевого оборудования.</p>
<p>С NFV оператору сети не нужно иметь выделенное оборудование для каждой сетевой функции. NFV повышает масштабируемость и гибкость, позволяя поставщикам услуг предоставлять новые сетевые сервисы и приложения по требованию, не требуя дополнительных аппаратных ресурсов.</p>
<p><strong>Основные принципы</strong> Виртуализация сетевых функций (NFV, Network Function Virtualization) это технология, которая виртуализирует функциональность физических сетевых устройств, позволяя перенести ее на архитектуру ЦОД (вычислительные сервера, сервера хранения + коммутаторы). NFV программно реализует функции сетевых устройств, которые в дальнейшем запускаются на виртуальной инфраструктуре облака. NFV отделяет реализацию сетевых функций от непосредственного сетевого оборудования.</p>
<p>В NFV это делается при помощи виртуальных функций сети VNF (Virtualized network function). Виртуальная сетевая функция (Virtualized NF, VNF) - программная реализация сетевой функции, которая может быть установлена в виртуальной инфраструктуре. Примеры сетевых функций: DHCP, Firewall, NAT, VPN.</p>
<p>В архитектуре NFV становится возможным осуществлять надежное предоставление сервисов за счет распределенного резервирования ресурсов такой архитектуры, а также сбор данных для индикаторов производительности KPI (Key Performance Indicator) от аппаратных и программных компонентов NFV. Отношения к ПКС</p>
<ul>
<li>NFV дружественная к SDN технология, так как NFV позволяет создавать инфраструктуру, к которой применима ПКС архитектура.</li>
<li>NFV и ПКС взаимовыгодны друг другу, но не зависят друг от друга.</li>
<li>Сетевые функции могут быть виртуализованы без ПКС, также как и ПКС может быть запущен без NFV.</li>
</ul>
<p><strong>Этапы развития NFV</strong></p>
<ol type="1">
<li>Software implementation of network - программная имплементация сетевых функций: переход от быстрых аппаратных реализаций к программным реализациям</li>
<li>Network function modules - модули сетевых функций: разделение на функциональные модули, например DHCP, NAT, Rate limiting</li>
<li>Implementation in virtual machines - решения для виртуальных машин: переход к использованию виртуальных машин, отсюда появляются все преимущества виртуализации: быстрая доставка новых приложений, масштабируемость, мобильность и другие. Есть гипервизор и много виртуалок.</li>
<li>Standard API’s between modules - стандартные API для взаимодействия модулей</li>
</ol>
<p><strong>Архитектура</strong></p>
<figure>
<img src="https://lh3.googleusercontent.com/KPc4YrztPx0vRnHvSc2K-I6b9EVyoB6Xjg_VI1PjO-CGipRUqYW9ms2xp7xRbEnnC8xUABpoLvQxZrCNHzv5hzd-ZFVWzVzUMsjBELdbz2tuQCC__c55Lg4bqKAPCTwhnNDWfo9V" alt="" /><figcaption>img</figcaption>
</figure>
<p>Ключевыми элементами NFV архитектуры являются:</p>
<ul>
<li>Виртуальная Сетевая Функция (VNF): VNF программная реализация сетевой функции, которая может запуститься на NFV инфраструктуре (NFVI).</li>
<li>NFV Инфраструктура (NFVI): NFVI включает вычислительные, сетевые ресурсы, а также ресурсы хранения, которые могут быть виртуализованы.</li>
<li>Управление и Оркестрация (MANO) NFV: NFV MANO фокусируется на всех задачах связанных с виртуализацией, которые возникают на всех стадия жизненного цикла VNF.</li>
</ul>
<p><strong>Преимущества</strong> NFV - перенос сетевых функций на виртуальные машины:</p>
<ul>
<li>Автоматизация установки и настройки как софта, так и железа</li>
<li>Поддержка нескольких поставщиков инфраструктуры</li>
<li>Уменьшение стоимости за счет использования стандартных серверов</li>
<li>Объединение сервисов в группы</li>
<li>Целостность облачных приложений</li>
<li>Восстановление после сбоев</li>
</ul>
<p><strong>Варианты применения</strong> Облака:</p>
<ul>
<li>NFVI as a service подобно IaaS (infrastructure as a service)</li>
<li>VNF as a service</li>
<li>Цепочки сервисов (VNF forwarding graphs)</li>
<li>Платформа виртуальной сети as a service</li>
</ul>
<p>Мобильные сети:</p>
<ul>
<li>Виртуализация ядра мобильной сети и IMS (не знаю что это)</li>
<li>Виртуализация базовой мобильной станции</li>
</ul>
<p>ЦОД:</p>
<ul>
<li>Виртуализация CDN</li>
</ul>
<p>Доступ:</p>
<ul>
<li>Виртуализация домашней сети</li>
<li>NFV фиксированного доступа</li>
</ul>
<p><strong>Примеры</strong></p>
<p>BRAS</p>
<ul>
<li>Терминация пользовательских сессий</li>
<li>Интересует выгода на одного пользователя ~ 1Mbps</li>
<li>Стоимость существующего решений примерно 10к за 10Gbps =&gt; Одно подключение = 1</li>
<li>С NFV: один сервер может обрабатывать 50Gbps. Стоимость 5k =&gt; Одно подключение = 0.1.</li>
</ul>
<p>CG-NAT</p>
<ul>
<li>Трансляция адресов</li>
<li>Высокая стоимость существующих решений.</li>
<li>Экономия: 16 -&gt; 4 -&gt; 2 на подключение</li>
</ul>
<h1 id="качество-сервиса-в-компьютерных-сетях-модели-распределения-ресурсов-сети-и-методы-борьбы-с-перегрузками.">8. Качество сервиса в компьютерных сетях: модели распределения ресурсов сети и методы борьбы с перегрузками.</h1>
<p><strong>Качество сервиса</strong></p>
<ul>
<li>Нет четкого определения</li>
<li>Методы позволяющие обслуживать разные потоки данных с разным качеством</li>
<li>Методы распределения ресурсов сети между разными потоками данных</li>
<li>Методы обеспечения предсказуемого и согласованного поведения сети в условиях постоянно изменяющейся конфигурации</li>
<li>Методы повышения эффективности работы и утилизации оборудования сети</li>
</ul>
<p><strong>Метрики качества сервиса </strong></p>
<ul>
<li>Уровень потерь (packet loss) – Доля пакетов, которые были отправлены, но не были доставлены получателю [проценты]</li>
<li>Пропускная способность (bandwidth) – Количество данных, которые могут быть переданы в единицу времени [байты]</li>
<li>Задержка (delay) – Время передачи единицы данных по направлению от отправителя к получателю [секунды]</li>
<li>Вариация задержки, дрожание (jitter) – Разница между минимальной и максимальной задержками [секунды]</li>
</ul>
<p><strong>Что такое управление качеством сервиса? </strong></p>
<ul>
<li>Методы позволяющие обслуживать разные потоки данных с разным качеством</li>
<li>Методы распределения ресурсов сети между разными потоками данных</li>
<li>Методы обеспечения предсказуемого и согласованного поведения сети в условиях постоянно изменяющейся конфигурации</li>
<li>Методы повышения эффективности работы и утилизации оборудования сети</li>
</ul>
<h3 id="перегрузка">Перегрузка</h3>
<p><strong>Перегрузка сети</strong> в компьютерных сетях и теории очередей — состояние сети, при котором основные показатели качества обслуживания существенно ухудшаются. Возникает, когда на сетевой узел (например, коммутатор) поступает больше данных, чем он может обрабатывать/передавать. Типичные эффекты включают задержку в очереди, потерю пакетов или блокировку новых соединений. Перегрузки могут возникать как на отдельных участках сети (локальные перегрузки), так и распространяться на всю сеть (глобальные перегрузки).</p>
<p><strong>Методы борьбы с перегрузкой:</strong></p>
<ul>
<li>Буферизация (не уверена, что это тут нужно)
<ul>
<li>На входе: Нет необходимости в сверх-быстрой памяти. Если пакеты из нескольких входных портов начинают конкурировать за один и тот же вход коммутационной фабрики, возникает блокировка пакетов, находящихся за ними – Head Of Line (HOL) Blocking. При равномерном распределении маршрутов передачи пакетов производительность коммутатора равна менее 59% показателя коммутатора с буферизацией на выходе.</li>
<li>На выходе</li>
<li>На самом деле на сегодняшний день наиболее распространены модели Combined Input Output Queuing (CIOQ)</li>
</ul></li>
<li>управление перегрузкой</li>
</ul>
<p><strong>Управление перегрузкой TCP: задачи</strong></p>
<ul>
<li>Соединения должны адаптироваться к качеству предоставленной линии связи и стремиться использовать предоставленные ресурсы максимально эффективно</li>
<li>Соединения должны автоматически распределять пропускную способность разделяемой ими линии связи справедливым образом</li>
</ul>
<p><strong>Управления перегрузкой TCP: принципы работы</strong></p>
<ul>
<li>Взаимодействующие с сетью – Сетевые устройства сигнализируют о возникновении перегрузки (TCP/ECN)</li>
<li>Без взаимодействия с коммутаторами – Перегрузка определяется косвенно (по потере пакета, увеличению задержки и т.д.)</li>
<li>Реактивные (как правило, loss based) – Детектируют возникновение перегрузок по факту</li>
<li>Проактивные (как правило, delay based) – Ограничивают пропускную способность соединения, предчувствуя скорую перегрузку</li>
</ul>
<p>При отсутствии дополнительных сервисных пакетов отправитель получает информацию из ACK-сообщений, поступающих к нему спустя один Round Trip Time (RTT), следовательно отправитель способен адаптироваться к состоянию сети не быстрее, чем за RTT.</p>
<p><strong>Примеры</strong></p>
<ul>
<li>TCP Tahoe
<ul>
<li>медленный старт: начинаем с cwnd=1, потом *2, до порога slow-start threshold, ssthresh.</li>
<li>предотвращение перегрузки (congestion-avoidance): +1</li>
<li>таймаут или 3 dupACK: cwnd=1, медленный старт, ssthresh=ssthresh/2</li>
</ul></li>
<li>TCP Reno</li>
<li>Cubic</li>
<li>Data Center TCP</li>
<li>etc</li>
</ul>
<h3 id="модели-распределения-ресурсов">Модели распределения ресурсов</h3>
<p><strong>Проблема эффективного распределения ресурсов</strong></p>
<p>Проблема обеспечения качества связана с проблемой распределения сетевых ресурсов между потоками данных</p>
<ul>
<li>Проблему распределения ресурсов можно формализовать как задачу оптимизации</li>
<li>Чем больше ресурсов вовлечено в обслуживание потока, тем выше качество его соединения</li>
<li>Чем большее количество ресурсов позволяет задействовать модель распределения, тем выше эффективность сети, и тем больший уровень утилизации достигается. Чем выше уровень утилизации, тем лучше отношение производительности сети к стоимости сетевой инфраструктуры</li>
</ul>
<p><strong>Модель Интегрированных Сервисов (IntServ)</strong></p>
<p>Мультимедийный трафик в сети:</p>
<ul>
<li><p>Как оградить TCP трафик от мультимедийных данных, передающихся через UDP?</p></li>
<li><p>Как обеспечить качество соединения?</p></li>
<li><p>Гарантированный уровень качества можно обеспечить лишь с помощью резервирования ресурсов – закрепления части ресурсов сети за конкретным потоком данных. Основная идея – прокладывание маршрутов с заданным качеством путём предварительного резервирования ресурсов на оборудовании</p></li>
<li><p>Модель лишь расширяет архитектуру Интернета, сохраняется совместимость с best-effort</p></li>
<li><p>Модель особенно эффективна при многоадресной передаче данных</p></li>
<li><p>Допускаются накладные расходы на предварительное прокладывание маршрута</p></li>
<li><p>всё или ничего – модель или гарантирует соединение нужного качества, или отказывается предоставить какое-либо соединение.</p>
<p><strong>Основные компоненты модели IntServ</strong></p></li>
<li><p>Классификатор (classifier) – Разделение пакетов на классы обслуживания</p></li>
<li><p>Планировщик (scheduler) – Обеспечение выполнения требований QoS</p></li>
<li><p>Контроль доступа (admission control) – Оценка возможности добавления потоков</p></li>
<li><p>Протокол резервирования ресурсов – Резервирование ресурсов вдоль маршрута</p></li>
</ul>
<p><strong>Расчёт и обеспечение качества соединений</strong></p>
<ul>
<li>Распределение по очередям на входящих и исходящих интерфейсах коммутатора</li>
<li>Использование policing &amp; shaping для формирования нужного профиля потоков</li>
<li>Установка надлежащих дисциплин сброса пакетов при их постановке в очереди и выборки пакетов из очередей</li>
<li>Настройка алгоритмов планирования коммутационной матрицы</li>
</ul>
<p>Пример IntServ протокола: RSVP</p>
<p><strong>Модель Дифференцированных Сервисов (DiffServ)</strong></p>
<ul>
<li><p>Каждый маршрутизатор имеет несколько предопределённых классов обслуживания</p></li>
<li><p>Пограничные маршрутизаторы определяют класс потока, маркируют его пакеты dscp метками и проводят traffic conditioning – используют инструменты policing &amp; shaping для установки нужного профиля трафика</p></li>
<li><p>На внутренних маршрутизаторах пакеты с более высоким приоритетом получают большую долю ресурсов, и наоборот</p>
<p><strong>Стандартные классы обслуживания DiffServ</strong></p></li>
<li><p>Default Forwarding (DF) – Обычно обслуживается по best-effort</p></li>
<li><p>Expedient Forwarding (EF) – Идёт через очередь с высшим приоритетом, маленькие delay, jitter &amp; loss</p></li>
<li><p>Assured Forwarding (AF) – Идёт через менее приоритетную очередь, охватывает несколько классов с разной политикой сброса при заполнении очереди</p></li>
<li><p>Преимущества</p>
<ul>
<li>Отсутствие внутренней фрагментации</li>
<li>Высокая степень утилизации оборудования</li>
<li>Простота реализации в аппаратуре</li>
<li>Хорошая масштабируемость</li>
</ul></li>
<li><p>Недостатки</p>
<ul>
<li>Не предоставляет гарантий качества</li>
<li>Метрики качества не рассчитываются явно</li>
<li>Ограниченное количество классов качества</li>
</ul></li>
</ul>
<p><strong>9. Основные подходы математического моделирования КС. Прототипирование КС: преимущества, недостатки, ограничения применимости.</strong></p>
<p>Модель – сущность/объект, который отображает процессы, протекающие в реальных системах с помощью математических или натурных средств. Отражение процессов осуществляется на основе оценки характеристик (зависимостей) или параметров процессов моделируемых систем. Основные условия выбора метода моделирования</p>
<ul>
<li>Постановка задачи</li>
<li>Составом, характером и объемом исходных данных</li>
<li>Временем на решение исследовательской задачи</li>
</ul>
<p>Методы моделирования:</p>
<ul>
<li>Натурное или физическое</li>
<li>АналитическоеИмитационное</li>
<li>Комбинированные методы</li>
</ul>
<p><strong>Натурное моделирование</strong> Измерение характеристик осуществляется на исследуемых системах в реальном времени (проведение экспериментов). Данные исследователь получает ведя наблюдение за процессами в реальной системе.</p>
<p>Достоинства:</p>
<ul>
<li>Высокая адекватность модели реальной системе</li>
<li>Высокая точность результатов</li>
</ul>
<p>Недостатки:</p>
<ul>
<li>Высокая стоимость создания модели</li>
<li>Большие временные затраты</li>
<li>Необходимость доработки отдельных узлов реальной системы для проведения натурных экспериментов</li>
</ul>
<p><strong>Аналитическое моделирование</strong> Модель представляется совокупностью аналитических выражений, которые отражают функциональные зависимости между параметрами реальной системы в процессе ее работы. Аналитические модели применяются для относительно простых систем, для исследования характеристик которых не требуется высокая точность.</p>
<p>Достоинства</p>
<ul>
<li>Простота и низкая стоимость модели</li>
<li>Возможность быстро получить численные результаты</li>
</ul>
<p>Недостатки</p>
<ul>
<li>Большое число допущений и ограничений</li>
<li>Не высокая точность результатов</li>
<li>Соответствие результатов определенным условиям</li>
<li>Большая сложность аналитического описания функциональных зависимостей</li>
</ul>
<p><strong>Имитационное моделирование</strong> Метод исследования, при котором изучаемая система заменяется моделью с достаточной точностью описывающей реальную систему и с ней проводятся эксперименты с целью получения информации об этой системе. Экспериментирование с моделью называют имитацией (имитация - это постижение сути явления, не прибегая к экспериментам на реальном объекте). Это метод математического моделирования. Существует класс объектов, для которых по различным причинам не разработаны аналитические модели или аналитические методы решения полученной модели. В таких случаях математическая модель заменяется имитационной. Достоинства</p>
<ul>
<li>Высокая адекватность между физической сущностью описываемого процесса и его моделью</li>
<li>Возможность описать сложную систему на достаточно высоком уровне детализации</li>
<li>Значительно больший охват исследования, чем у аналитического моделирования</li>
<li>Отсутствие ограничений на зависимости между параметрами модели</li>
<li>Возможность оценки функционирования системы не только в стационарных состояниях, но и в переходных процессах (режимах)</li>
<li>Получение большого числа данных об исследуемом объекте</li>
<li>Наиболее рациональное отношение “результат-затраты” по отношению к аналитическому и физическому моделированию</li>
</ul>
<p>Недостатки</p>
<ul>
<li>Относительно большая сложность создания модели</li>
<li>Необходимость высокой квалификации исследователя для написания модели</li>
<li>Необходимость проведения верификации и валидации данных моделирования</li>
<li>Индивидуальность реализации. Для широкого применения модели необходимо сделать детальное описание ее построения</li>
</ul>
<p><strong>Комбинированные методы</strong> Модель представляется как комбинация методов моделирования. Наиболее широко применяются имитационно-аналитические модели. Степень применения методов моделирования определяет исследователь, исходя из поставленных задач, имеющихся ресурсов и времени на проведение исследовательской работы.</p>
<p><strong>Прототипирование</strong> Прототипирование КС - это моделирование КС с помощью “почти реальных” виртуальных машин/контейнеров и тд. В таком случае мы строим сеть из полноценных сетевых устройств, пусть даже с некоторым уровнем абстракции. Это может быть как ручками построенная сеть из виртуальных машин или контейнеров (lxc, docker), так и mininet/maxinet.</p>
<p>Linux LXC Контейнеры</p>
<p>LXC используют Cgroups для изоляции ресурсов. Cgroups - это механизмы виртуализации и изоляции, которые поддерживаются ядром Linux начиная с версии 2.6.24. Cgroups позволяют обеспечить сетевыми интерфейсами, таблицами маршрутизации и ARP-таблицами процессы в рамках одной операционной системы. Это один из видов виртуализации на уровне ОС, позволяющий запустить множество однотипных процессов в изолированном и ограниченном по ресурсам окружении.</p>
<p>Используемые операции с сетевым пространством имен:</p>
<ol type="1">
<li>Создание сетевого пространства имен</li>
<li>Ассоциирование интерфейса с сетевым пространством имен</li>
<li>Конфигурирование интерфейса в сетевом пространстве имен</li>
</ol>
<p>Mininet</p>
<p>Техники, подобные Cgroups, позволяют Mininet создавать в пространстве ядра или пользователя коммутаторы, OpenFlow-контроллеры и хосты, и взаимодействовать в рамках моделируемой сети. В качестве виртуальных коммутаторов используется адаптированная реализация Open vSwitch’a.Основная функциональность Mininet реализована на Python, за исключением некоторых утилит написанных на Си. Практически любая произвольная топология может быть описана с помощью специального синтаксиса на Python. В интернете можно найти множество интересных лабораторных работ на базе mininet, решающих различные задачи. Например реализация простого маршрутизатора.</p>
<p>Docker</p>
<p>Докер - это открытая платформа для разработки, доставки и эксплуатации приложений. Позволяет отделить ваше приложение от вашей инфраструктуры. Позволяет запускать практически любое приложение безопасно изолированное в контейнере.</p>
<p>Что использует:</p>
<ul>
<li>Пространство имен (namespaces)</li>
<li>Control groups (контрольные группы)</li>
<li>Union File System</li>
</ul>
<p><em>(Дальше придумывала сама, добавляйте свои пункты,если есть идеи)</em></p>
<p>Преимущества</p>
<ul>
<li>Высокий уровень детализации модели без использования физических устройств</li>
<li>Легкость создания модели</li>
</ul>
<p>Недостатки</p>
<ul>
<li>Сложность моделирования больших сетей (вроде по оценкам Антоненко mininet может создать ~1000 хостов максимум)</li>
<li>Можно исследовать только те характеристики, которые есть в используемых абстракциях сетевых устройств</li>
</ul>
<p>Ограничения применения</p>
<ul>
<li>Насколько я понимаю, нельзя устанавливать необходимые характеристики линков между сетевыми устройствами (например, пропускную способность)</li>
</ul>
<h5 id="динамическое-планирование-задач-в-иус-рв.-схемы-планирования-rate-monotonic-фиксированные-приоритеты-и-earliest-deadline-first-динамические-приоритеты.-оценка-времени-отклика-задач-для-схемы-rate-monotonic.">10. Динамическое планирование задач в ИУС РВ. Схемы планирования Rate Monotonic (фиксированные приоритеты) и Earliest Deadline First (динамические приоритеты). Оценка времени отклика задач для схемы Rate Monotonic.</h5>
<p><strong>Динамическое планирование задач в ИУС РВ</strong></p>
<p>В ИУС РВ есть два режима активации задач:</p>
<ul>
<li>Периодические задачи (time driven) – задача автоматически активируется ядром через регулярные интервалы времени;</li>
<li>Апериодические задачи (event driven) – задача активируется при наступлении какого-либо события (например, вызывается прерывание).</li>
</ul>
<p>Так как в ИУС РВ много периодических задач с разной скоростью вызова, а также много апериодических событий, в один и тот же момент времени для выполнения могут быть доступны несколько задач. Порядок выполнения таких задач определяет планировщик. Его работа оказывает влияние на:</p>
<ul>
<li>Время отклика задачи;</li>
<li>Задержку выполнения задач и jitter;</li>
<li>Время выполнения задачи (так как вытеснение задачи уничтожает кэш);</li>
<li>Преодоление перегрузки;</li>
<li>Оптимизацию использования ресурсов;</li>
<li>Сохранение энергии, затрачиваемой процессором.</li>
</ul>
<p>Для каждой задачи t<sub>i</sub> определены следующие характеристики: С<sub>i</sub> – время выполнения задачи в наихудшем случае (WCET); D<sub>i</sub> – относительный дедлайн задачи; T<sub>i</sub> – время между активациями задачи (период) (может быть просто минимальным временем между активациями, если период не фиксированный); в некоторых системах D<sub>i</sub>=T<sub>i</sub>.</p>
<p>Каждый экземпляр задачи (т.е. задача, выполнненная внутри своего экземпляра периода), называется работой;</p>
<p>r<sub>i,k</sub> - время активации k-ой работы задачи t<sub>i</sub>; d<sub>i,k</sub> - абсолютный дедлайн k-ой работы задачи t<sub>i</sub>; <span class="math inline"><em>r</em><sub><em>i</em>, <em>k</em></sub> = <em>Φ</em> <em>i</em>  + (<em>k</em> − 1) * <em>T</em> <em>i</em> </span>; <span class="math inline"><em>d</em><sub><em>i</em>, <em>k</em></sub> = <em>r</em><sub><em>i</em>, <em>k</em></sub> + <em>D</em> <em>i</em> </span></p>
<p><img src=".\img\10_1.PNG" alt="10_1" style="zoom: 50%;" /></p>
<p>Далее: набор задач спланирован ≡ построено расписание выполнения задач, при котором каждая из них завершается до своего дедлайна; необходимо проверить существование расписания до запуска в run-time.</p>
<p><strong>Rate Monotonic (фиксированные приоритеты)</strong></p>
<p>Суть схемы планироавния с фикс. приоритетами:</p>
<ul>
<li>каждая задача имеет фикс. (статический) приоритет, определнный до запуска системы (до run-time);</li>
<li>задачи выполняются в порядке, заданном их приоритетами (1 - самый отстойный приоритет);</li>
</ul>
<p>В Rate Monotonic приоритеты задач определяются след. образом: если дан набор задач с известными периодами, то каждой задаче ставится уникальный приоритет по следующему принципу: чем меньше период, тем выше приоритет <span class="math inline">(<em>T</em><sub><em>i</em></sub> &lt; <em>T</em><sub><em>J</em></sub> ⇒ <em>P</em><sub><em>i</em></sub> &gt; <em>P</em><sub><em>j</em></sub>)</span>.</p>
<p>Утверждение (на курсе не доказывалось): если какой-то набор задач может быть спланирован при помощи схемы планирования с фиксированным приоритетом (с вытеснением задач, т.е. выполнение низкоприоритетных задач может прерываться выполнением высокоприоритетных задач), то данный набор может быть спланирован и с Rate Monotonic.</p>
<p><strong>Earliest Deadline First (динамические приоритеты)</strong></p>
<p>Запущенные задачи выполняются в порядке, определяемом их абсолютными дедлайнами d<sub>i,k</sub>. Следующая задача для запуска имеет ближайший абсолютный дедлайн. Хотя относительные дедлайны (значение D<sub>i</sub>) известны заранее, абсолютный дедлайн считается во время выполнения задачи, поэтому эта схема описывается как динамическая.</p>
<p><strong>EDF vs FPS (Fixed Priority Scheduling)</strong></p>
<ul>
<li>FPS (а RM это подвид FPS) проще реализовать, так как приоритеты статичны.</li>
<li>EDF – динамический и требует более сложной системы, которая будет иметь больше накладных расходов на расчёты во время планирования.</li>
<li>В FPS проще добавить задачи без дедлайнов (просто назначить наименьший приоритет)</li>
<li>Проще учитывать другие факторы в отношении приоритетов, чем в отношении дедлайнов;</li>
<li>Во время перегрузки FPS более предсказуем (дедлайн могут пропустить низкоприоритетные задачи), а EDF непредсказуем (задачи могут начать пропускать дедлайн по принципу домино);</li>
<li>Но EDF лучше организует процессорное время.</li>
</ul>
<p><strong>Оценка времени отклика задач для схемы Rate Monotonic</strong></p>
<p>Для ответа на вопрос «является ли данный набор задач планируемым» для схемы Rate Monotonic используется анализ времени отклика. Анализ времени отклика задач состоит из следующих шагов:</p>
<ol type="1">
<li><p>Считается интерференция (I<sub>i</sub>) для задачи i от более высокоприоритетных задач <span class="math inline"><em>I</em><sub><em>i</em></sub> = ∑<sub><em>T</em><sub><em>k</em></sub> &lt; <em>T</em><sub><em>i</em></sub></sub><em>C</em><sub><em>k</em></sub></span></p></li>
<li><p>Вычисляется время отклика как <span class="math inline"><em>R</em><sub><em>i</em></sub> = <em>C</em><sub><em>i</em></sub> + <em>I</em><sub><em>i</em></sub></span></p></li>
<li><p>Проверяется, что <span class="math inline"><em>R</em><sub><em>i</em></sub> &lt;  = <em>D</em><sub><em>i</em></sub></span>; если верно для всех задач, то планируемо.</p></li>
</ol>
<p>Интерференция задачи k на задачу i на интервале времени <span class="math inline">$[0,R_i]: I_{i,k}=\lceil\frac{R_i}{T_k}\rceil*C_k$</span></p>
<p>Интерференция высокоприоритетных задач на задачу i: <span class="math inline">$I_i=\sum_{T_k&lt;T_i}\lceil\frac{R_i}{T_k}\rceil*C_k$</span></p>
<p>Тогда время отклика считается как , <span class="math inline">$R_i=C_i+ \sum_{j\in hp(i)}\lceil\frac{R_i}{T_j}\rceil*C_j$</span>, где hp(i) – набор задач с приоритетом выше, чем у задачи i.</p>
<p>Такое уравнение решается рекуррентным соотношением <span class="math inline">$w_{i}^{n+1}=C_i + \sum_{j\in hp(i)}\lceil\frac{w_{i}^{n}}{T_j}\rceil*C_j$</span></p>
<p>Набор значений <span class="math inline"><em>w</em><sub><em>i</em></sub><sup>0</sup>, <em>w</em><sub><em>i</em></sub><sup>1</sup>, ..., <em>w</em><sub><em>i</em></sub><sup><em>n</em></sup>, ...</span> монотонно не убывает. Когда <span class="math inline"><em>w</em><sub><em>i</em></sub><sup><em>n</em></sup> = <em>w</em><sub><em>i</em></sub><sup><em>n</em> + 1</sup></span> , решение найдено. <span class="math inline"><em>w</em><sub><em>i</em></sub><sup>0</sup></span> должно быть не больше, чем R<sub>i</sub>(например, 0 или C<sub>i</sub>). ##### 11. Понятие наихудшего времени выполнения программы (WCET). Факторы, влияющие на WCET. Фазы анализа WCET. Использование абстрактной интерпретации для выявления недопустимых путей. Анализ влияния конвейера на время выполнения программы.</p>
<p>Простейшая вычислительная задача:</p>
<ul>
<li>входные данные доступны в момент старта</li>
<li>выходные данные готовы в момент завершения</li>
<li>нет блокировок в процессе выполнения</li>
<li>нет синхронизации или обмена данными в процессе выполнения</li>
<li>время выполнения зависит только от: входных данных и состояния задачи в момент старта</li>
</ul>
<p><strong>Наихудшее время выполнения программного кода (WCET)</strong></p>
<p>– это максимальное время, которое требуется для выполнения данного фрагмента кода, в данном контексте (входные данные, состояние), на заданном аппаратном вычислителе. WCET используется в формуле оценки времени отклика задач для RM: C<sub>i</sub>.</p>
<p>(есть еще BCET – Best-case execution time - нижняя оценка времени выполнения)</p>
<p>Цель анализа WCET – оценить сверху время выполнения фрагмента кода. Оценка должна быть:</p>
<ul>
<li>Безопасной (недопустимо ошибаться в меньшую сторону)</li>
<li>Точной (завышенность приведёт к излишнему резервированию ресурсов системы)</li>
<li>Затраты на ее анализ д.б. разумными</li>
</ul>
<p><strong>WCET нельзя просто замерить, т.к.:</strong></p>
<ul>
<li>замер времени на ВСЕХ путях выполнения невозможен</li>
<li>при определении тестовой выборки могут быть упущены редкие сценарии</li>
<li>выбранные тестовые данные могут не породить самую длинную трассу</li>
<li>внутреннее состояние процессора на момент старта измерений может НЕ БЫТЬ наихудшим</li>
</ul>
<p><strong>Факторы, влияющие на WCET:</strong></p>
<ul>
<li>Возможные пути (последовательности действий) выполнения задачи, определяются:
<ul>
<li>Семантикой программного кода (спецификой реализации, в т.ч. аппаратно-зависимой семантикой)</li>
<li>Входными данными, возможными в данном контексте вызова программы</li>
</ul></li>
<li>Длительность выполнения каждого действия на каждом возможном пути выполнения, определяются
<ul>
<li>Аппаратной реализацией команд процессора</li>
<li>Состоянием аппаратных средств, влияющих на тайминги (кэш-память, конвейер и т.п.) (как связанные с самой задачей, так и связанные с внешними факторами (состояние на момент старта, вытеснение задачи))</li>
</ul></li>
</ul>
<p>Длительность выполнения пути:</p>
<ul>
<li>В простом случае - длительность каждого действия константа.</li>
<li>В реалистическом случае – длительности варьируются (конвейер, кэш-память, параллелизм процессора).</li>
</ul>
<p><strong>Фазы анализа WCET:</strong></p>
<ol type="1">
<li>Анализ потоков: ограничить (сверху) число выполнений различных фрагментов программы (в основном, анализ программной составляющей) (даёт верхнюю оценку, которая корректна для всех возможных трасс) <em>Примеры предоставляемой информации</em>: ограничение на число итераций цикла, ограничение на глубину рекурсии, недопустимые пути выполнения. <em>Источники информации</em>: статический анализ программы и ручные аннотации кода.</li>
<li>Низкоуровневый анализ: ограничить (сверху) время выполнения различных фрагментов программы (сочетание анализа программной и аппаратной составляющих), большая часть исследований по WCET посвящена этой фазе. <em>Использует</em>: модель целевой аппаратуры (не требуется моделирование всех подробностей, при этом необходимо безопасно сверху оценить все задержки при работе аппаратуры) <em>Применяется:</em> к скомпанованому двоичному коду (исполняемой программе)</li>
<li>Вычисление: объединить результаты анализа потоков и низкоуровневого анализа, чтобы получить верхнюю оценку WCET <em>Примеры подходов</em>: расчёт по синтаксическому дереву (дерево обходится снизу-вверх), расчёт по путям выполнения, неявный перебор путей (IPET).</li>
</ol>
<p><strong>Использование абстрактной интерпретации для выявления недопустимых путей</strong> (фаза анализа – Анализ потоков)</p>
<p><em>Анализируется граф потока управления, множество путей программного выполнения имеет вложенную структуру: все фактически возможные пути <span class="math inline">≤</span> статически допустимые (например, if(x&lt;23){}) <span class="math inline">≤</span>базовая ограниченность (например, число итераций цикла &lt; 100) <span class="math inline">≤</span>структурно допустимые пути (бесконечно много); Требование базовой ограниченности: для каждого цикла должно быть известно (вычислено или задано) ограничение на число итераций. Недопустимые пути (например, найденные на основе if) исключаются из множества статически допустимых путей.</em></p>
<p><img src=".\img\11_0.PNG" alt="11_0" style="zoom: 25%;" /></p>
<p><strong>Абстрактная интерпретация (АИ):</strong></p>
<ol type="1">
<li>Ограничивает число итераций циклов и выявляет недопустимые пути
<ul>
<li>Вычисляет безопасную (расширенную) оценку множества значений каждой переменной для различных точек выполнения программы</li>
<li>В ходе АИ, переменной сопоставляется не конкретное значение, а множество значений («абстрактное» значение)</li>
</ul></li>
<li>Программа «выполняется» с использованием абстрактных значений переменных</li>
<li>Результат выполнения: безопасная (расширенная) оценка множества допустимых путей выполнения
<ul>
<li>Все фактически допустимые пути входят в полученное множество</li>
<li>Также в него могут входить некоторые фактически НЕ допустимые пути</li>
<li>Пути, не вошедшие в полученное множество, гарантированно не допустимы</li>
</ul></li>
</ol>
<p><img src=".\img\11_1.PNG" alt="11_1" style="zoom: 67%;" /></p>
<p><strong>Анализ влияния конвейера на время выполнения программы</strong> (фаза анализа – Низкоуровневый анализ) Простой конвейер: <em>Instruction fetch (выборка команды) -&gt; instruction decode (декодирование команды) -&gt; execution -&gt; memory access (загрузить / сохранить значения в/из памяти) -&gt; write back (запись результата)</em></p>
<ul>
<li>В идеале: коэффициент ускорения равен числу ступеней конвейера</li>
<li>Фактически: между командами есть зависимости по данным; «слом» конвейера при неверном предсказании ветвления; ожидание данных из памяти</li>
</ul>
<p>Виды конвейеров: отсутствует / скалярный (один конвейер) / VLIW (несколько конвейеров, статическое планирование из загрузки на уровне компилятора) / Суперскалярный (несколько конвейеров, внеочередное выполнение команд (процессор может на ходу переставить порядок команд))</p>
<p>Чтобы учесть задержки в случае простого конвейера – в графе потока управления ребрам присваиваются отрицательные веса:</p>
<p><img src=".\img\11_2.PNG" alt="11_2" style="zoom: 25%;" /></p>
<p><strong>Учет совместного влияния кэша и конвейера:</strong> Анализ влияния конвейера должен брать на вход результаты анализа влияния кэш-памяти</p>
<ul>
<li>Команды помечаются попаданием/промахом в кэш</li>
<li>Попадания/промахи влияют на задержки в конвейере</li>
</ul>
<ol start="12" type="1">
<li><h5 id="архитектура-интегрированной-модульной-авионики-има-её-основные-преимущества-примеры-типов-модулей-шина-vme.-статико-динамическая-схема-планирования-вычислений-в-системах-има.">Архитектура интегрированной модульной авионики (ИМА), её основные преимущества, примеры типов модулей (шина VME). Статико-динамическая схема планирования вычислений в системах ИМА.</h5></li>
</ol>
<p>Федеративная ИУС РВ (более старое поколение):</p>
<ul>
<li>специализированные блоки (по назначению/ по архитектуре)</li>
<li>ПО различных подсистем на разных блоках (изоляция по памяти, нет конкуренции за выч. ресурсы)</li>
</ul>
<p><em>Недостатки</em>:</p>
<ul>
<li>система неоднородна (блоки сильно различаются)/</li>
<li>модули одного блока тесно интегрированы друг с другом</li>
<li>модули разных блоков слишком изолированы</li>
<li>низкая переносимость и повторная используемость ПО</li>
<li>низкая отказоустойчивость и реконфигурируемость (блок выходит из строя целиком)</li>
</ul>
<p><strong>Архитектура ИМА и ее основные преимущества:</strong></p>
<ul>
<li>логически единый распределённый вычислитель (единая архитектура, унифицированные модули, унифицированные программные интерфейсы)</li>
<li>разделение вычислительных ресурсов между ПО различных подсистем.</li>
</ul>
<p><em>Проблемы</em>: конкуренция за процессорное время; изоляция по памяти.</p>
<p><em>Решение</em>: каждой подсистеме - раздел.</p>
<p>Для ИМА характерно:</p>
<ul>
<li>Стандартное API со стороны ОС.</li>
<li>Статическое разделение времени, памяти и ресурсов.</li>
<li>Унификация: вычислительные модули, сетевое оборудование и протоколы</li>
<li>Интеграция: программное обеспечение, потоки данных</li>
<li>Виртуализация: процессоры, память, сеть</li>
</ul>
<p><em>Преимущества</em>: надёжность, переносимость, возможность повторного использования, модульность, упрощение верификации и сертификации.</p>
<p>описание ИМА:</p>
<ul>
<li>Модули всех блоков равноправно подключены к среде обмена данными =&gt; система – «облако» модулей</li>
<li>Сервисная шина – последовательная, относительно медленная (помехоустойчивость), может объединять все модули системы ИМА
<ul>
<li>CAN bus - Controller Area Network – сеть контроллеров</li>
</ul></li>
<li>Трафик по сервисной шине минимален (низкоуровневые данные о состоянии, простейшие команды вроде вкл/выкл модуля)</li>
<li>Высокая отказоустойчивость и реконфигурируемость
<ul>
<li>модуль вышел из строя =&gt; заменить его может модуль из другого блока</li>
<li>поддержка виртуальных каналов =&gt; возможность миграции вычислительных задач</li>
</ul></li>
</ul>
<p><strong>Примеры модулей (это без привязки к VME):</strong></p>
<ol type="1">
<li>Модуль процессора данных - функциональный модуль общего назначения. Задачи: обработка данных, выполнение вычислительных задач, принятие управленческих решений.</li>
<li>Модуль ввода-вывода - функциональный модуль специального назначения. Задачи: прием/выдача сигналов по «унаследованным» бортовым интерфейсам, преобразование унаследованных форматов сообщений в стандартный формат ARINC 653.</li>
<li>Модуль графического контроллера - функциональный модуль специального назначения. Задачи: построение изображений на основе данных, полученных от вычислительных задач, обработка входных видеоизображений,прием/выдача изображений по оптическим видеоканалам.</li>
<li>Модуль коммутатора FC - предназначен для обеспечения взаимодействия в сети Fibre Channel</li>
<li>Модуль источника питания - вспомогательный модуль, обеспечивающий вторичное питание модулей с требуемыми характеристиками.</li>
</ol>
<p><strong>Шина VME:</strong></p>
<ul>
<li>Параллельная шина с арбитражем</li>
<li>Реализует прямой доступ к памяти модулей</li>
<li>Объединяет модули в блок (крейт)</li>
<li>Разрядность шины данных: 32 или 64 бита</li>
<li>Пропускная способность:</li>
<li>40 Мбайт/с (VME32)</li>
<li>80 Мбайт/с (VME64)</li>
<li>до 320 Мбайт/с (VME64 в блочном режиме, на одну передачу адреса – несколько передач данных)</li>
</ul>
<p>VME - Адресная шина данных с арбитражем и прерываниями (напр., использовалась как процессорная шина Motorola 68000);</p>
<p>Структура шины VME:</p>
<ul>
<li>адресная шина</li>
<li>шина данных</li>
<li>шина арбитража</li>
<li>шина прерываний</li>
</ul>
<p><strong>Роли модулей на шине VME:</strong></p>
<ul>
<li><em>Ведущий</em> (Master) - может инициировать передачу данных</li>
<li><em>Подчинённый</em> (Slave) - отвечает на запросы от ведущего</li>
<li><em>Источник прерывания</em> (Interrupter) - модуль, способный формировать прерывание (обычно – подчинённый)</li>
<li><em>Обработчик прерывания</em> (Interrupt handler) - модуль, способный обрабатывать прерывания (как правило, одноплатный компьютер)</li>
<li><em>Арбитр</em> (Arbiter) - модуль, управляющий доступом к шине и осуществляющий мониторинг обмена по шине. Устанавливается в слот №1</li>
</ul>
<p><strong>Процедура передачи данных на VME:</strong></p>
<ol type="1">
<li>Ведущий устанавливает запрос на передачу данных на шине арбитража (Ш.А.) – при этом ведущий устанавливает на Ш.А. «свою» линию запроса в активное состояние (логический 0)</li>
<li>Шина освобождается от текущей передачи данных =&gt;</li>
</ol>
<ul>
<li>арбитр определяет, какие линии запроса активны на Ш.А.</li>
<li>арбитр выбирает ведущего, которому отдать шину, и устанавливает в активное состояние линию Ш.А. «доступ дан» для этого ведущего</li>
</ul>
<ol start="3" type="1">
<li>Получив доступ к шине, ведущий устанавливает:
<ul>
<li>на шине данных: значения передаваемых данных (в случае отправки); разрядность данных – не больше разрядности шины данных</li>
<li>на шине адреса: номер подчинённого устройства, адрес в памяти подчинённого устройства, разрядность передаваемых данных (8, 16, 32 бита; также 64 бита для VME64), признак «чтение» или «запись»</li>
</ul></li>
<li>Подчинённое устройство:
<ul>
<li>на Ш.А. признак «чтение» =&gt; устанавливает на шине данных значения данных заданной разрядности с заданного адреса своей памяти</li>
<li>на Ш.А. признак «запись» =&gt; записывает по заданному адресу своей памяти данные заданной разрядности с шины данных</li>
</ul></li>
</ol>
<p><strong>Прерывания VME:</strong></p>
<ul>
<li>Прерывание – способ для подчинённого устройства оповестить какое-либо из ведущих устройств о необходимости обмена данными</li>
<li>Запрос прерывания выставляется на одной из 7 линий шины прерывания</li>
<li>Ведущие устройства сами разбираются, кому адресован запрос</li>
</ul>
<p>Блочная передача данных:</p>
<ul>
<li>Поддерживается в VME64</li>
<li>В начале обмена задаётся адрес и число передаваемых блоков данных</li>
<li>Выполняется передача заданного числа блоков данных (каждый блок - не шире шины данных) =&gt; значительная экономия времени на задании адреса</li>
</ul>
<p><strong>Недостатки VME:</strong></p>
<ul>
<li><p>Медленная шина (по современным меркам)</p></li>
<li><p>Параллельная шина (много линий на материнской плате, сложность повышения частоты работы)</p></li>
<li><p>Невозможно одновременное выполнение нескольких обменов данными</p></li>
</ul>
<p><strong>Статико-динамическая схема планирования</strong> <em>Статико</em> – stands for статическое расписание окон. Границы окон одинаковы для всех ядер одного модуля. В одном окне могут выполняться задачи только одного раздела, между окнами для разных разделов происходит переключение контекста; <em>Динамическое</em> – stands for планирование работы в конкретном окне. При этом учитываются: очередь выполнения, приоритеты, вытеснение, ожидание входных данных.</p>
<p><strong>Сквозное планирование вычислений и информационного обмена</strong>: <em>Дано</em>:</p>
<ul>
<li>Описание вычислительной системы с архитектурой ИМА
<ul>
<li>вычислительные средства (модули, процессоры в их составе)</li>
<li>сеть передачи данных (структура сети, транспортный протокол)</li>
</ul></li>
<li>Описание рабочей нагрузки
<ul>
<li>на вычислители: задачи (сгруппированы в разделы)</li>
<li>на сеть: сообщения, передаваемые между задачами</li>
</ul></li>
</ul>
<p><em>Требуется:</em></p>
<ol type="1">
<li>Распределить вычислительную нагрузку (привязать разделы к процессорным ядрам)</li>
<li>Построить конфигурацию сети (виртуальные каналы, их маршруты и характеристики)</li>
<li>Построить расписание окон для каждого ядра</li>
</ol>
<p><strong>Вычислительные ресурсы и рабочая нагрузка на них</strong>:</p>
<ul>
<li>Вычислительные ресурсы
<ul>
<li>набор модулей</li>
<li>модуль -&gt; набор и типы процессорных ядер</li>
<li>ядро -&gt; верхняя граница загрузки</li>
</ul></li>
<li>Рабочая нагрузка на вычислительные ресурсы (вычислительная нагрузка)
<ul>
<li>набор задач</li>
<li>набор разделов</li>
<li>задача -&gt; период, приоритет, WCET (для типа процессора), принадлежность к разделу</li>
<li>раздел -&gt; допустимые ядра</li>
</ul></li>
</ul>
<p><strong>Сеть передачи данных и рабочая нагрузка на нее</strong></p>
<ul>
<li>Сеть передачи данных
<ul>
<li>набор коммутаторов</li>
<li>структура каналов (коммутатор-модуль, коммутатор-коммутатор)</li>
<li>пропускные способности каналов</li>
<li>транспортный протокол + соответствующая ему схема оценки задержек и джиттера передачи сообщений через сеть</li>
</ul></li>
<li>Рабочая нагрузка на сеть
<ul>
<li>набор сообщений</li>
<li>сообщение -&gt; задача-отправитель, задача-получатель, размер</li>
<li>период передачи сообщения определяется периодом задачи-отправителя</li>
<li>Длительность передачи сообщения через сеть зависит от конфигурации сети (=&gt; заранее не известна, может быть оценена снизу)</li>
</ul></li>
</ul>
<p><strong>Распределение вычислительной нагрузки</strong> <em>Дано</em>: Описание вычислительной системы;Описание рабочей нагрузки <em>Требуется:</em> Построить привязку разделов к процессорным ядрам <em>Оптимизируемый критерий:</em> Трафик между модулями -&gt; min <em>Ограничения:</em> Каждый раздел привязан к одному ядру, допустимому для него; Загрузка каждого ядра не превышает максимально допустимой</p>
<p><strong>Построение конфигурации сети</strong> <em>Дано:</em> Описание вычислительной системы; Описание рабочей нагрузки; Распределение вычислительной нагрузки (=&gt; модуль-отправитель и модуль-получатель для каждого сообщения); <em>Опционально:</em> максимально допустимые длительности и джиттеры передачи сообщений через сеть (индивидуально по сообщениям) <em>Требуется:</em> Построить систему виртуальных каналов; <em>Оптимизируемый критерий</em>: нет <em>Ограничения:</em> Непревышение пропускной способности каналов; Непревышение максимально допустимых длительностей и джиттеров</p>
<p><strong>Построение расписания окон</strong> <em>Дано:</em> Описание вычислительной системы; Описание рабочей нагрузки; Распределение вычислительной нагрузки; Длительности передачи сообщений через сеть; Минимально и максимально допустимые длительности окон; <em>Требуется:</em> Построить расписание окон для каждого ядра (Ядро -&gt; набор окон; Окно -&gt;время начала, время завершения, раздел) <em>Оптимизируемый критерий:</em> нет <em>Ограничения:</em> окна для каждого ядра не перекрываются; к каждому окну привязан единственный раздел; длительность каждого окна не меньше минимально допустимой и не больше максимально допустимой; границы окон для всех ядер одного модуля должны совпадать; все работы выполняются в рамках директивных сроков, задаваемых периодами (при длительностях, равных WCET);</p>
<p><strong><em>Соблюдение директивных сроков проверяется имитационным моделированием работы динамического планировщика</em></strong></p>
<h6 id="v-образный-жизненный-цикл-жц-программного-обеспечения.-основные-виды-инструментальных-средств-поддержки-жц-их-отнесение-к-фазам-жц.-структура-комплекса-стендов-для-поэтапной-интеграции-по-и-аппаратуры-иус-рв-на-восходящей-фазе-жц.">13 V-образный жизненный цикл (ЖЦ) программного обеспечения. Основные виды инструментальных средств поддержки ЖЦ, их отнесение к фазам ЖЦ. Структура комплекса стендов для поэтапной интеграции ПО и аппаратуры ИУС РВ на восходящей фазе ЖЦ.</h6>
<p>*<strong>Информационно-управляющая система (ИУС)*</strong> – вычислительная система верхнего уровня, обеспечивающая:</p>
<ul>
<li>функциональную и информационную интеграцию составных частей управляемого объекта</li>
<li>взаимодействие между объектом и оператором</li>
</ul>
<p><strong>V-образный ЖЦ на рисунке:</strong></p>
<p><img src=".\img\13_1.PNG" alt="13_1" style="zoom: 50%;" /></p>
<p><strong>Фазы ЖЦ на V-цикле</strong> (про вехи не спрашивают в билете).</p>
<p><img src=".\img\13_2.PNG" alt="13_2" style="zoom: 33%;" /></p>
<p><strong>Основные виды инструментальных средств поддержки ЖЦ, их отнесение к фазам ЖЦ</strong></p>
<blockquote>
<p>на мой взгляд, достаточно знать сам вид и фазу + мб примеры. Остальное добавила - просто для понимания</p>
</blockquote>
<p><strong><em>Средства поддержки разработки требований</em></strong> <em>Фазы:</em> разработка требований <em>Необходимая функциональность</em>:</p>
<ul>
<li>создание и хранение требований, отслеживание истории</li>
<li>связывание требований с версиями документов и ПО</li>
<li>прослеживаемость требований на: Низкоуровневые требования; Формальные спецификации; Код;Тесты</li>
</ul>
<p><em>Примеры средств:</em> IBM DOORS, Borland CaliberRM, SyBase PowerDesigner</p>
<p><strong><em>Средства версионного/ конфигурационного контроля</em></strong> <em>Фазы:</em> проектирования; кодирования; <em>Версия</em> = вся совокупность документов: Требования, спецификации, код, тесты,…;Часть конфигурации борта <em>Необходимая функциональность</em>:</p>
<ul>
<li>Версионирование совокупности документов (в т.ч. атомарность изменений)</li>
<li>Поддержка ветвей истории</li>
<li>Поддержка групповой разработки, в т.ч. разграничения доступа</li>
<li>Обновление документов в реальном времени</li>
</ul>
<p><em>Примеры:</em> CVS, Subversion, git, IBM ClearCase</p>
<p><strong><em>Средства отслеживания проблем и изменений</em></strong> <em>Фазы:</em> формальная верификация (и как следствие исправление баг на остальных фазах)+ фазы, где идет в параллель свое тестирование (проектирование, кодирование, интеграция и тд) <em>Необходимая функциональность</em>:</p>
<ul>
<li>Поддержка структуры продукта и процесса</li>
<li>Настраиваемый формат сообщения о проблеме</li>
<li>Настраиваемый ЖЦ сообщения, поддержка согласования</li>
<li>Поддержка групповой разработки, втч разграничения доступа</li>
<li>Интеграция со средствами управления версиями</li>
</ul>
<p><em>Примеры:</em> Bugzilla, Trac, IBM ClearQuest</p>
<p><strong><em>Средства поддержки сопряжения подсистем ПО</em></strong> <em>Фазы:</em> кодирование, интеграция; проектирования</p>
<ul>
<li>Средства автоматизации проектирования бортовых интерфейсов: Балансировка загрузки каналов; Формирование набора сообщений; Построение расписаний обмена (канал с централизованным управлением); Построение системы виртуальных каналов (сеть на основе коммутаторов);</li>
<li>Средства автоматизации интеграции ПО: Использование унифицированных структурных компонентов ПО;</li>
</ul>
<p><strong><em>Средства автоматизации проектирования индикационных форматов</em></strong> <em>Фазы:</em> кодирование; проектирования Индикационный формат = набор графических элементов + правила поведения <em>Необходимая функциональность:</em></p>
<ul>
<li>Редактирование в графической форме, WYSIWYG</li>
<li>Поддержка библиотеки элементов</li>
<li>Поддержка автономного тестирования</li>
<li>Генерация кода в формате для целевого устройства</li>
</ul>
<p><em>Примеры:</em> SCADE Display, VAPS, САПР ИФ</p>
<p><strong><em>Средства проектирования алгоритмов</em></strong> <em>Фазы:</em> кодирование; проектирования; формальной верификации <em>Необходимая функциональность</em>:</p>
<ul>
<li>Поддержка обоих видов формального представления (потоковая обработка данных, конечный автомат)</li>
<li>Графическое описание</li>
<li>Тестирование и пошаговая отладка на уровне модели</li>
<li>Верификация на основе формальных методов</li>
<li>Сертифицированный кодогенератор</li>
</ul>
<p><em>Примеры:</em> Telelogic Rhapsody, SCADE Suite, Simulink</p>
<p><strong><em>Средства поддержки верификации и тестирования бортового ПО</em></strong> <em>Фазы:</em> формальной верификации</p>
<ul>
<li>Тестирование на целевой платформе
<ul>
<li>Недопустимость инструментирования</li>
<li>Тестирование через каналы бортовых интерфейсов</li>
<li>Тестирование требований реального времени</li>
<li>Интерактивное тестирование индикационных форматов</li>
<li>Многоэтапное тестирование</li>
<li>Сопровождение интеграции подсистем КБО</li>
</ul></li>
</ul>
<p><em>Необходимая функциональность:</em></p>
<ul>
<li>Поддержка стандартов бортовых интерфейсов</li>
<li>Многомашинные конфигурации</li>
<li>Выполнение тестов в реальном времени</li>
<li>Автоматическое и интерактивное тестирование</li>
<li>Пакетный режим</li>
<li>Формирование отчётов, прослеживаемость требований</li>
</ul>
<p><em>Примеры средств:</em> Rational Test RealTime, VectorCast, средства разработки ЛВК</p>
<p><strong>Структура комплекса стендов для поэтапной интеграции ПО и аппаратуры ИУС РВ на восходящей фазе ЖЦ</strong></p>
<p><em>Комплекс средств тестирования ИУС</em> (на картинке)</p>
<ul>
<li>Разработан в Лаборатории вычислительных комплексов ВМК МГУ</li>
<li>Предназначен для тестирования устройств ИУС через каналы бортовых интерфейсов (КБИ)</li>
<li>Функционирует на ПК под управлением ОС Linux, в состав которых входят адаптеры КБИ</li>
<li>Поддерживает распределенное выполнение тестовых сценариев</li>
<li>Удовлетворяет перечисленным выше требованиям (очень кратко перечислены в пункте про “Средства поддержки верификации и тестирования бортового ПО”)</li>
<li>Положен в основу семейства стендов тестирования, отработки и интеграции ИУС</li>
</ul>
<p><img src=".\img\13_3.PNG" alt="13_3" style="zoom:50%;" /></p>
<blockquote>
<p>про интеграцию и ее верификацию, думаю, что имели ввиду вот эти 2 картинки</p>
</blockquote>
<p><img src=".\img\13_4.PNG" alt="13_4" style="zoom:50%;" /></p>
<p><img src=".\img\13_5.PNG" alt="13_5" style="zoom: 50%;" /> Арчиловское: https://drive.google.com/drive/folders/0B3XUBeyj27tAaHBQSm56LU1zMVE</p>
<h2 id="cредние-и-эмпирические-операционные-характеристики-стратегий-распознавания-классификаторов-регрессий.-проблема-переобучения.-проблема-устойчивости-решений.-роль-обучающей-валидационной-и-контрольной-выборок-при-построении-распознающей-системы.-скользящий-контроль-кросс-валидация.-регуляризация-на-примере-линейной-регрессии">14. Cредние и эмпирические операционные характеристики стратегий распознавания (классификаторов, регрессий). Проблема переобучения. Проблема устойчивости решений. Роль обучающей, валидационной и контрольной выборок при построении распознающей системы. Скользящий контроль (кросс-валидация). Регуляризация на примере линейной регрессии</h2>
<h4 id="cредние-и-эмпирические-операционные-характеристики-стратегий-распознавания-классификаторов-регрессий">Cредние и эмпирические операционные характеристики стратегий распознавания (классификаторов, регрессий)</h4>
<p>Среди задач обучения с учителем можно выделить 2 основные:</p>
<ul>
<li>классификация</li>
<li>регрессия</li>
</ul>
<p><strong>Классификатором</strong> называется следующее отображение <br /><span class="math display"><em>ĉ</em> : <em>X</em> → <em>C</em>, <em>г</em><em>д</em><em>е</em> <em>C</em> = {<em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, ..., <em>C</em><sub><em>k</em></sub>} − <em>к</em><em>о</em><em>н</em><em>е</em><em>ч</em><em>н</em><em>о</em><em>е</em> <em>м</em><em>н</em><em>о</em><em>ж</em><em>е</em><em>с</em><em>т</em><em>в</em><em>о</em> <em>к</em><em>л</em><em>а</em><em>с</em><em>с</em><em>о</em><em>в</em></span><br /> Проблема обучения для классификации – обучить такую аппроксимацию $  $ истинной помечающей функции <span class="math inline"><em>c</em></span>.</p>
<blockquote>
<p>Примеры классификации: определить кошка, собака или какое-либо еще животное на фотографии (многоклассовая); определить есть ли кошка на фотографии или нету (бинарная).</p>
</blockquote>
<p>Для классификаторов оценить качество можно построив <strong>матрицу ошибок</strong>. Предположим, что некоторые данные можно разделить на 2 класса (бинарная классификация). Таким образом, матрица будет выглядеть следующим образом</p>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline"><em>y</em> = 1</span></th>
<th><span class="math inline"><em>y</em> = 0</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline"><em>ŷ</em> = 1</span></td>
<td>True Positive</td>
<td>False Positive (ошибка 1 рода)</td>
</tr>
<tr class="even">
<td><span class="math inline"><em>ŷ</em> = 0</span></td>
<td>False Negative (ошибка 2 рода)</td>
<td>True Negative</td>
</tr>
</tbody>
</table>
<p><span class="math inline"><em>y</em></span> – истинный класс объекта</p>
<p><span class="math inline"><em>ŷ</em></span> – предсказанный класс классификатором</p>
<p>Соответственно, на диагонали подобной матрицы будет находиться количество объектов распознанных правильно. В остальных местах – ошибки. Отмечу также, что подобную матрицу можно построить и для многоклассовой классификации (<span class="math inline">|<em>C</em>| &gt; 2</span>).</p>
<blockquote>
<p>В зависимости от постановки исходной задачи ошибки 1 и 2 рода показывают разное. Например, в задаче по определению оттока абонентов, ошибкой первого рода будет принятие лояльного абонента за уходящего, так как наша <a href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors">нулевая гипотеза</a> состоит в том, что никто из абонентов не уходит, а мы эту гипотезу отвергаем. Соответственно, ошибкой второго рода будет являться “пропуск” уходящего абонента и ошибочное принятие нулевой гипотезы.</p>
</blockquote>
<p><img src="img\precall.png" /></p>
<p>По такой матрице можно рассчитать различные <strong>показатели качества классификатора</strong> на размеченной выборке:</p>
<ul>
<li><p>accuracy (доля правильных ответов алгоритма) = <span class="math inline">$\frac{TP + TN}{TP + FP + TN + FN}$</span> – почти не используется из-за проблем с несбалансированными классами.</p></li>
<li><p>precision (точность) = <span class="math inline">$\frac{TP}{TP + FP}$</span></p></li>
<li><p>recall (полнота) = <span class="math inline">$\frac{TP}{TP + FN}$</span></p></li>
</ul>
<p><strong>Precision</strong> можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а <strong>recall</strong> показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм. Precision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок.</p>
<p>https://habr.com/ru/company/ods/blog/328372/</p>
<p>https://en.wikipedia.org/wiki/Precision_and_recall</p>
<p>Рассмотрим задачу регрессии. <strong>Оценочной функцией</strong> называется отображение: <br /><span class="math display">$$
\hat{f} : X \rightarrow \R
$$</span><br /> Проблема обучения регрессии заключается в построении оценочной функции по примерам <span class="math inline">(<em>x</em><sub><em>i</em></sub>, <em>f</em>(<em>x</em><sub><em>i</em></sub>))</span>.</p>
<blockquote>
<p>Примеры: задача поиска оценочной функции для индекса Доу-Джонса или для FTSE 100, исходя из выбранных экономических показателей. Также подобная функция может называться <em>гипотезой</em>.</p>
</blockquote>
<p>Регрессионные модели рассчитываются путем применения функции потерь к <strong>невязкам</strong> <span class="math inline"><em>f</em>(<em>x</em>) − <em>f̂</em>(<em>x</em>)</span> (для упрощения <span class="math inline"><em>y</em> − <em>ŷ</em></span>) – отличие предсказания <span class="math inline"><em>ŷ</em></span> от истинного значения <span class="math inline"><em>y</em></span></p>
<p>Несколько популярных <strong>функций потерь</strong> <span class="math inline">ℒ(<em>ŷ</em>, <em>y</em>)</span> –</p>
<p>MAE – Mean Absolute Error = <span class="math inline">$\frac{1}{m}|y - \hat{y}|$</span></p>
<p>MSE – Mean Squared Error = <span class="math inline">$\frac{1}{m}(y - \hat{y})^2$</span></p>
<p>где m – количество элементов x</p>
<p>(у этих функций потерь есть еще некоторые вероятностные интерпретации + гипотезы накладываемые на параметры, но давайте не будем об этом)</p>
<p><strong>Риск</strong>, ассоциированный с гипотезой <span class="math inline"><em>f̂</em>(<em>x</em>)</span>, определяется как математическое ожидание функции потерь: <br /><span class="math display"><em>R</em>(<em>h</em>) = 𝔼[ℒ(<em>f̂</em>(<em>x</em>), <em>y</em>)]</span><br /> Высшей целью алгоритма обучения будет являться поиск такой гипотезы <span class="math inline"><em>f̂</em><sup>*</sup></span> в фиксированном классе функций <span class="math inline"><em>H</em></span>, для которой подобный риск <span class="math inline"><em>R</em>(<em>f̂</em>)</span> <em>минимален</em>: <br /><span class="math display">$$
\hat{f}^{*} = \underset{\hat{f} \in H}{argmin} R(\hat{f})
$$</span><br /> https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D1%8D%D0%BC%D0%BF%D0%B8%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B3%D0%BE_%D1%80%D0%B8%D1%81%D0%BA%D0%B0</p>
<blockquote>
<p>================</p>
</blockquote>
<blockquote>
<p>Текст для дискуссии про эту часть билета:</p>
</blockquote>
<blockquote>
<p>Не знаю, что означает “средние и эмпирические” вот из билетов:</p>
</blockquote>
<blockquote>
<p>Эмпирические методы оценки обобщающей способности - методы основанные на контрольной выборке.</p>
</blockquote>
<blockquote>
<p>Средние операционные характеристики распознавания - ??? - возможно оценка обобщающей способности на самой обучающей выборке???</p>
</blockquote>
<blockquote>
<p>Предполагаю что эмпирически – глазами посмотреть красиво/некрасиво (пример: фильтр в инстаграмме). Но инфы как-то мало.</p>
</blockquote>
<blockquote>
<p>=======</p>
</blockquote>
<h4 id="проблема-переобучения">Проблема переобучения</h4>
<p>Основным способом поиска закономерностей (процесса обучения) является поиск в некотором априори заданном семействе алгоритмов прогнозирования <span class="math inline"><em>M</em>′ = <em>A</em> : <em>X</em>′ → <em>Y</em>′</span> алгоритма, наилучшим образом аппроксимирующего связь переменных из набора <span class="math inline"><em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub></span> с переменной <span class="math inline"><em>Y</em></span> на обучающей выборке, где <span class="math inline"><em>X</em>′</span> – область возможных значений векторов переменных <span class="math inline"><em>X</em><sub>1</sub>, ..., <em>X</em><em>n</em></span>(известные переменные); Y’ – область возможных значений переменной Y (прогнозируемая величина).</p>
<p>​ Расширение модели <span class="math inline"><em>M</em>′ = <em>A</em> : <em>X</em>′ → <em>Y</em>′</span> всегда приводит к повышению точности аппроксимации на обучающей выборке. Однако повышение точности на обучающей выборке, связанное с увеличением сложности модели, часто не ведет к увеличению обобщающей способности. Более того, обобщающая способность может даже снижаться. Различие между точностью на обучающей выборке и обобщающей способностью при этом возрастает. Данный эффект называется <strong>эффектом переобучения</strong>.</p>
<p><strong>Переобучение</strong>, <strong>переподгонка</strong> (overtraining, overfitting) — нежелательное явление, возникающее при решении задач <a href="http://www.machinelearning.ru/wiki/index.php?title=Обучение_по_прецедентам">обучения по прецедентам</a>, когда вероятность ошибки обученного алгоритма на объектах <a href="http://www.machinelearning.ru/wiki/index.php?title=Тестовая_выборка">тестовой выборки</a> оказывается существенно выше, чем средняя ошибка на <a href="http://www.machinelearning.ru/wiki/index.php?title=Обучающая_выборка">обучающей выборке</a>. Переобучение возникает при использовании избыточно сложных <a href="http://www.machinelearning.ru/wiki/index.php?title=Модель_зависимости">моделей</a>.</p>
<p><em>Обучение по прецедентам</em>, или <em>индуктивное обучение</em>, основано на выявлении общих закономерностей по частным <a href="http://www.machinelearning.ru/wiki/index.php?title=Выборка">эмпирическим данным</a>.</p>
<p><img src="img\LsmRunge-detailed.png" /></p>
<p>Пример:</p>
<blockquote>
<p>Рассмотрим задачу аппроксимации вещественной функции <span class="math inline">$y(x) = \frac1 {1+25x^2}$</span> по обучающей выборке из 50 точек <span class="math inline">$X^m = \left\{ x_i = 4\frac{i-1}{m-1}-2 \right\}$</span>. Это равномерная сетка на отрезке <span class="math inline">[ − 2, 2]</span>.</p>
</blockquote>
<blockquote>
<p>В качестве модели рассмотрим полиномы заданной степени <span class="math inline"><em>p</em></span>:</p>
</blockquote>
<p><br /><span class="math display"><em>a</em>(<em>x</em>, <em>w</em>) = <em>w</em><sub>0</sub> + <em>w</em><sub>1</sub><em>x</em> + ... + <em>w</em><sub><em>p</em></sub><em>x</em><sup><em>p</em></sup></span><br /> &gt; В качестве метода обучения возьмём <a href="http://www.machinelearning.ru/wiki/index.php?title=Метод_наименьших_квадратов">метод наименьших квадратов</a>:</p>
<p><br /><span class="math display">$$
\sum_{i=1}^{m}(y(x_i) - a(x_i, w))^2 \rightarrow \underset{w}{min}
$$</span><br /> &gt; Таким образом, функция потерь квадратична: <span class="math inline">ℒ(<em>a</em>, <em>x</em>) = (<em>y</em>(<em>x</em>) − <em>a</em>(<em>x</em>))<sup>2</sup></span>.</p>
<blockquote>
<p>Возьмём контрольную выборку — также равномерную сетку на отрезке <span class="math inline">[ − 2, 2]</span>, узлы которой находятся в точности между узлами первой сетки: <span class="math inline">$X^k = \Bigl\{ x'_i = 4\frac{i-0.5}{m-1}-2 \Bigr\}$</span>.</p>
</blockquote>
<blockquote>
<p>Зададимся вопросом: что будет на контрольной выборке при увеличении степени полинома <span class="math inline"><em>p</em></span> Степень связана с числом свободных параметров модели, то есть играет роль сложности модели.</p>
</blockquote>
<blockquote>
<p>Ниже показаны графики самой выборки и аппроксимирующей функции:</p>
</blockquote>
<ul>
<li>при <img src="http://www.machinelearning.ru/mimetex/?p=20" alt="p=20" /> — оптимальная сложность модели.</li>
<li>при <img src="http://www.machinelearning.ru/mimetex/?p=40" alt="p=40" /> — неустойчивость и переобучение.</li>
</ul>
<p><img src="img\LsmRunge20.png" /></p>
<p><img src="img\LsmRunge40.png" /></p>
<blockquote>
<p>http://www.machinelearning.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5</p>
</blockquote>
<blockquote>
<p>Еще такая картинка может помочь</p>
</blockquote>
<p><img src="img\bias-variance.png" /></p>
<blockquote>
<p>Для этого требуется понимать, что мы можем разложить ошибку на bias-variance,</p>
</blockquote>
<p><br /><span class="math display">$$
\large \begin{array}{rcl} \text{Err}\left(\vec{x}\right) &amp;=&amp; \mathbb{E}\left[\left(y - \hat{f}\left(\vec{\overline\right)^2\right] \\ &amp;=&amp; \sigma^2 + f^2 + \text{Var}\left(\hat{f}\right) + \mathbb{E}\left[\hat{f}\right]^2 - 2f\mathbb{E}\left[\hat{f}\right] \\ &amp;=&amp; \left(f - \mathbb{E}\left[\hat{f}\right]\right)^2 + \text{Var}\left(\hat{f}\right) + \sigma^2 \\ &amp;=&amp; \text{Bias}\left(\hat{f}\right)^2 + \text{Var}\left(\hat{f}\right) + \sigma^2 \end{array}
$$</span><br /></p>
<ul>
<li><blockquote>
<p>квадрат смещения Bias – средняя ошибка по всевозможным наборам данных;</p>
</blockquote></li>
<li><blockquote>
<p>дисперсии Var – вариативность ошибки, то, на сколько ошибка будет отличаться, если обучать модель на разных наборах данных;</p>
</blockquote></li>
<li><blockquote>
<p>ошибка <span class="math inline"><em>σ</em><sup>2</sup></span> является неустранимой</p>
</blockquote></li>
</ul>
<blockquote>
<p>читать подробнее здесь: https://habr.com/ru/company/ods/blog/323890/</p>
</blockquote>
<h4 id="проблема-устойчивости-решений">Проблема устойчивости решений</h4>
<p>Под <strong>устойчивыми</strong> обучающими алгоритмами понимаются такие, которые дают решение, незначительно изменяющееся при малом изменении обучающей выборки.</p>
<p>Для многомерной линейной регрессии:</p>
<p>(Задача восстановления линейной регрессии - задача обучения по прецедентам при <span class="math inline">$Y \rightarrow \R$</span>, связь задается в виде <span class="math inline"><em>Y</em> = <em>β</em><sub>0</sub> + <em>β</em><sub>1</sub><em>X</em><sub>1</sub> + ... + <em>β</em><sub><em>n</em></sub><em>X</em><sub><em>n</em></sub> + <em>ε</em></span>). При вычислении оценки вектора параметров <span class="math inline"><em>β</em> = (<em>β</em><sub>0</sub>, ..., <em>β</em><sub><em>n</em></sub>)</span> в случае многомерной линейной регрессии удобно использовать матрицу $X $размера <span class="math inline"><em>m</em> × (<em>n</em> + 1)</span> , которая строится по обучающей выборке. j-я строка матрицы <span class="math inline"><em>X</em></span> представляет собой вектор значений переменных (признаков) вида <span class="math inline">1, <em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub></span> для объекта <span class="math inline"><em>s</em><sub><em>j</em></sub></span> c одной добавленной слева компонентой, содержащей 1 (для <span class="math inline"><em>β</em><sub>0</sub></span>).</p>
<p>Связь <span class="math inline"><em>Y</em></span> с признаками <span class="math inline"><em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub></span> на объектах обучающей выборки может быть описана с помощью матричного уравнения <span class="math inline"><em>y</em> = <em>β</em><em>X</em><sup><em>T</em></sup> + <em>ε</em></span> , где <span class="math inline"><em>ε</em> = (<em>ε</em><sub>1</sub>, ..., <em>ε</em><sub><em>m</em></sub>)</span> - вектор ошибок прогнозирования для объектов из выборки. Необходимым условием минимума функционала метода наименьших квадратов (МНК) является выполнение системы из $ n + 1$ уравнений ( равенство нулю производных по каждой переменной <span class="math inline"><em>β</em><sub>0</sub>, ..., <em>β</em><sub><em>n</em></sub></span> ).</p>
<p>В матричной форме эта система может быть записана в виде : <span class="math inline"> − 2<em>X</em><sup><em>T</em></sup><em>y</em><sup><em>T</em></sup> + 2<em>X</em><sup><em>T</em></sup><em>X</em><em>β</em><sup><em>T</em></sup> = 0</span>. Решение этой системы существует, если <span class="math inline"><em>d</em><em>e</em><em>t</em>(<em>X</em><sup><em>T</em></sup><em>X</em>)</span> не равен 0. При сильной коррелированности одной из переменных <span class="math inline"><em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub></span> на выборке с какой-либо линейной комбинацией других переменных значение <span class="math inline"><em>d</em><em>e</em><em>t</em>(<em>X</em><sup><em>T</em></sup><em>X</em>)</span> оказывается близким к 0. При этом вычисленный вектор оценок <span class="math inline"><em>β</em><sup><em>T</em></sup></span> может сильно изменяться при относительно небольших чисто случайных изменениях вектора <span class="math inline"><em>y</em> = (<em>y</em><sub>1</sub>, ..., <em>y</em><sub><em>m</em></sub>)</span> .</p>
<p>Данное явление называется <strong>мультиколлинеарностью</strong>. Оценивание регрессионных коэффициентов с использованием МНК при наличии мультиколлинеарности оказывается неустойчивым. Также, <span class="math inline"><em>d</em><em>e</em><em>t</em>(<em>X</em><sup><em>T</em></sup><em>X</em>) = 0</span> при <span class="math inline"><em>n</em> + 1 &gt; <em>m</em></span>. Поэтому МНК не может использоваться для оценивания регрессионных коэффициентов, когда число переменных превышает число объектов в обучающей выборке. На практике высокая устойчивость достигается только, когда число объектов в выборках по крайней мере в 3-5 раз превышает число переменных.</p>
<h4 id="роль-обучающей-валидационной-и-контрольной-выборок-при-построении-распознающей-системы">Роль обучающей, валидационной и контрольной выборок при построении распознающей системы</h4>
<p>Предположим, что задача прогнозирования решается для некоторого процесса или явления F . Множество объектов, которые потенциально могут возникать в рамках F , называется генеральной совокупностью Ω .</p>
<p>​ Поиск алгоритма осуществляется по выборке прецедентов, которая обычно является случайной выборкой объектов из Ω с известными значениями <span class="math inline"><em>Y</em>, <em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub></span> . Выборку прецедентов также принято называть <strong>обучающей выборкой</strong>.</p>
<p>​ Обобщающая способность может оцениваться по случайной выборке объектов из одной и той же генеральной совокупности, соответствующей исследуемому процессу, которую принято называть <strong>контрольной выборкой</strong>. Контрольная выборка не должна содержать объекты из обучающей выборки.</p>
<p>Может быть задано несколько семейств алгоритмов прогнозирования.</p>
<p>- Обучающая выборка используется для выбора алгоритма из каждого семейства</p>
<p>- <strong>Валидационная выборка</strong> используется для выбора того семейства алгоритмов, для которого после обучения распознающая система наилучшая</p>
<p>- Контрольная выборка определяет качество обученной распознающей системы.</p>
<p>Валидационная выборка используется для настройки структуры распознающей системы (какое семейство алгоритмов нам больше подходит, гиперпараметры модели(задаются человеком)).</p>
<p>Контрольная выборка используется для оценки работы обученного классификатора.</p>
<p>Валидационную выборку нельзя использовать в качестве контрольной, потому что валидационная выбирала наилучший классификатор, а потому он покажет заниженную оценку ошибки для валидационной выборки.</p>
<h4 id="скользящий-контроль-кросс-валидация">Скользящий контроль (кросс-валидация)</h4>
<p><strong>Скользящий контроль</strong> или <strong>кросс-проверка</strong> или <strong>кросс-валидация</strong> (cross-validation, CV) — процедура эмпирического оценивания <a href="http://www.machinelearning.ru/wiki/index.php?title=Обобщающая_способность">обобщающей способности</a> алгоритмов, <a href="http://www.machinelearning.ru/wiki/index.php?title=Обучение_по_прецедентам">обучаемых по прецедентам</a>.</p>
<p>Фиксируется некоторое множество разбиений исходной выборки на две подвыборки: <a href="http://www.machinelearning.ru/wiki/index.php?title=Обучающая_выборка"><em>обучающую</em></a> и <a href="http://www.machinelearning.ru/wiki/index.php?title=Контрольная_выборка"><em>контрольную</em></a>. Для каждого разбиения выполняется настройка <a href="http://www.machinelearning.ru/wiki/index.php?title=Алгоритм">алгоритма</a> по обучающей подвыборке, затем оценивается его средняя ошибка на объектах контрольной подвыборки. <em>Оценкой скользящего контроля</em> называется средняя по всем разбиениям величина ошибки на контрольных подвыборках.</p>
<p>Если выборка независима, то средняя ошибка <em>скользящего контроля</em> даёт несмещённую оценку вероятности ошибки. Это выгодно отличает её от средней ошибки на обучающей выборке, которая может оказаться смещённой (оптимистически заниженной) оценкой вероятности ошибки, что связано с <a href="http://www.machinelearning.ru/wiki/index.php?title=Переобучение">явлением переобучения</a>.</p>
<p><em>Скользящий контроль</em> является стандартной методикой тестирования и сравнения алгоритмов <a href="http://www.machinelearning.ru/wiki/index.php?title=Классификация">классификации</a>, <a href="http://www.machinelearning.ru/wiki/index.php?title=Регрессия">регрессии</a> и <a href="http://www.machinelearning.ru/wiki/index.php?title=Прогнозирование">прогнозирования</a>.</p>
<blockquote>
<p>Рассматривается задача <a href="http://www.machinelearning.ru/wiki/index.php?title=Обучение_с_учителем">обучения с учителем</a>.</p>
</blockquote>
<blockquote>
<p>Пусть <img src="http://www.machinelearning.ru/mimetex/?X" alt="X" /> — множество описаний объектов, <img src="http://www.machinelearning.ru/mimetex/?Y" alt="Y" /> — множество допустимых ответов.</p>
</blockquote>
<blockquote>
<p>Задана конечная выборка прецедентов <img src="http://www.machinelearning.ru/mimetex/?X%5EL%20=%20(x_i,y_i)_%7Bi=1%7D%5EL%20\subset%20X\times%20Y" alt="X^L = (x_i,y_i)_{i=1}^L XY" />.</p>
</blockquote>
<blockquote>
<p>Задан <a href="http://www.machinelearning.ru/wiki/index.php?title=Алгоритм_обучения">алгоритм обучения</a> — отображение <img src="http://www.machinelearning.ru/mimetex/?\mu" alt="" />, которое произвольной конечной выборке прецедентов <img src="http://www.machinelearning.ru/mimetex/?X%5Em" alt="X^m" /> ставит в соответствие функцию (алгоритм) <img src="http://www.machinelearning.ru/mimetex/?a::X\to%20Y" alt="a::XY" />.</p>
</blockquote>
<blockquote>
<p>Качество алгоритма <img src="http://www.machinelearning.ru/mimetex/?a" alt="a" /> оценивается по произвольной выборке прецедентов <img src="http://www.machinelearning.ru/mimetex/?X%5Em" alt="X^m" /> с помощью <em>функционала качества</em> <img src="http://www.machinelearning.ru/mimetex/?Q(a,X%5Em)" alt="Q(a,X^m)" />. Для процедуры скользящего контроля не важно, как именно вычисляется этот функционал. Как правило, он аддитивен по объектам выборки:</p>
</blockquote>
<p><br /><span class="math display">$$
Q(a,X^m) = \frac1{m}\sum{x_i \in X^m} \mathcal{L}(a(x_i), y_i),
$$</span><br /> &gt; где <img src="http://www.machinelearning.ru/mimetex/?\mathcal%7BL%7D(a(x_i),y_i)" alt="(a(x_i),y_i)" /> — неотрицательная <a href="http://www.machinelearning.ru/wiki/index.php?title=Функция_потерь">функция потерь</a>, возвращающая величину ошибки ответа алгоритма <img src="http://www.machinelearning.ru/mimetex/?a(x_i)" alt="a(x_i)" /> при правильном ответе <img src="http://www.machinelearning.ru/mimetex/?y_i" alt="y_i" />.</p>
<h5 id="сама-процедура">Сама процедура:</h5>
<p>Выборка <img src="http://www.machinelearning.ru/mimetex/?X%5EL" alt="X^L" /> разбивается <img src="http://www.machinelearning.ru/mimetex/?N" alt="N" /> различными способами на две непересекающиеся подвыборки: <img src="http://www.machinelearning.ru/mimetex/?X%5EL%20=%20X%5Em_n%20\cup%20X%5Ek_n" alt="X^L = X^m_n X^k_n" />, где <img src="http://www.machinelearning.ru/mimetex/?X%5Em_n" alt="X^m_n" /> — обучающая подвыборка длины <em>m</em>, <img src="http://www.machinelearning.ru/mimetex/?X%5Ek_n" alt="X^k_n" /> — контрольная подвыборка длины <img src="http://www.machinelearning.ru/mimetex/?k=L-m" alt="k=L-m" />, <img src="http://www.machinelearning.ru/mimetex/?n=1,\ldots,N" alt="n=1,,N" /> — номер разбиения.</p>
<p>Для каждого разбиения <em>n</em> строится алгоритм <img src="http://www.machinelearning.ru/mimetex/?a_n%20=%20\mu(X%5Em_n)" alt="a_n = (X^m_n)" /> и вычисляется значение функционала качества <img src="http://www.machinelearning.ru/mimetex/?Q_n%20=%20Q%20(a_n,%20X%5Ek_n)" alt="Q_n = Q (a_n, X^k_n)" />. Среднее арифметическое значений <img src="http://www.machinelearning.ru/mimetex/?Q_n" alt="Q_n" /> по всем разбиениям называется <em>оценкой скользящего контроля</em>: <br /><span class="math display">$$
CV(\mu, X^L) = \frac1{N}\sum_{n=1}^{N}Q(\mu(X^m_n), X^k_n)
$$</span><br /></p>
<blockquote>
<p>Различные варианты скользящего контроля отличаются видами функционала качества и способами разбиения выборки.</p>
</blockquote>
<blockquote>
<p>k-fold cross validation – k = 5:</p>
</blockquote>
<p><img src="img\grid_search_cross_validation.png" /></p>
<h4 id="регуляризация-на-примере-линейной-регрессии">Регуляризация на примере линейной регрессии</h4>
<p>Задача линейной регрессии: https://habr.com/en/company/ods/blog/322076/</p>
<p>Давайте ограничим пространство гипотез только линейными функциями от m + 1 аргумента, будем считать, что нулевой признак для всех объектов равен единице <span class="math inline"><em>x</em><sub>0</sub> = 1</span></p>
<p><br /><span class="math display">$$\Large \begin{array}{rcl} \forall h \in \mathcal{H}, h\left(\overline{x}\right) &amp;=&amp; w_0 x_0 + w_1 x_1 + w_2 x_2 + \cdots + w_m x_m \\ &amp;=&amp; \sum_{i=0}^m w_i x_i \\ &amp;=&amp; \overline{x}^T \overline{w} \end{array}$$</span><br /></p>
<p>Эмпирический риск (функция стоимости) принимает форму среднеквадратичной ошибки:</p>
<p><br /><span class="math display">$$\Large \begin{array}{rcl}\mathcal{L}\left(X, \overline{y}, \overline{w} \right) &amp;=&amp; \frac{1}{2n} \sum_{i=1}^n \left(y_i - \overline{x}_i^T \overline{w}_i\right)^2 \\ &amp;=&amp; \frac{1}{2n} \left\| \overline{y} - X \overline{w} \right\|_2^2 \\ &amp;=&amp; \frac{1}{2n} \left(\overline{y} - X \overline{w}\right)^T \left(\overline{y} - X \overline{w}\right) \end{array}$$</span><br /></p>
<p>строки матрицы <span class="math inline"><em>X</em></span>— это признаковые описания наблюдаемых объектов. Один из алгоритмов обучения <span class="math inline"><em>M</em></span> такой модели — это метод наименьших квадратов. Вычислим производную функции стоимости:</p>
<p><span class="math inline">$\Large \begin{array}{rcl} \frac{\partial \mathcal{L}}{\partial \overline{w}} &amp;=&amp; \frac{\partial}{\partial \overline{w}} \frac{1}{2n} \left( \overline{y}^T \overline{y} -2\overline{y}^T X \overline{w} + \overline{w}^T X^T X \overline{w}\right) \\ &amp;=&amp; \frac{1}{2n} \left(-2 X^T \overline{y} + 2X^T X \overline{w}\right) \end{array}$</span></p>
<p>приравняем к нулю и найдем решение в явном виде:</p>
<p><br /><span class="math display">$$\Large \begin{array}{rcl} \frac{\partial \mathcal{L}}{\partial \overline{w}} = 0 &amp;\Leftrightarrow&amp; \frac{1}{2n} \left(-2 X^T \overline{y} + 2X^T X \overline{w}\right) = 0 \\ &amp;\Leftrightarrow&amp; -X^T \overline{y} + X^T X \overline{w} = 0 \\ &amp;\Leftrightarrow&amp; X^T X \overline{w} = X^T \overline{y} \\ &amp;\Leftrightarrow&amp; \overline{w} = \left(X^T X\right)^{-1} X^T \overline{y} \end{array}$$</span><br /></p>
<p>Сложный функционал содержит регуляризацию, которая обычно представлена в виде дополнительного регуляризационного слагаемого: <span class="math inline"><em>m</em><em>i</em><em>n</em> <em>L</em>(<em>X</em>, <em>y</em>, <em>w</em>) + <em>λ</em><em>F</em>(<em>w</em>)</span>, где <span class="math inline"><em>L</em>(<em>X</em>, <em>y</em>, <em>w</em>)</span> — функция потерь, <span class="math inline"><em>F</em>(<em>w</em>)</span> — регуляризационная функция, <span class="math inline"><em>λ</em></span> — параметр, задающий степень влияния регуляризации. Регуляризация предназначена для регулирования сложности модели и ее целью является упрощение модели. Это, в частности, помогает бороться с переобучением и позволяет увеличить обобщающую способность модели.</p>
<p>Типичные примеры регуляризационных функций:</p>
<ol type="1">
<li><p><span class="math inline"><em>L</em><sub>1</sub> = ∑|<em>w</em>|</span> Известная как LASSO-регуляризация (Least Absolute Shrinkage and Selection Operator), и, как несложно догадаться из названия, она позволяет снижать размерность коэффициентов, обращая некоторые из них в нули. И это весьма удобно, когда исходные данные сильно коррелированы.</p></li>
<li><p><span class="math inline"><em>L</em><sub>2</sub> = ∑<em>w</em><sup>2</sup></span> Иногда ее называют ridge-регуляризацией (гребневая), и она позволяет минимизировать значения коэффициентов модели, а заодно сделать ее робастной к незначительным изменениям исходных данных. А еще она хорошо дифференцируется, а значит модель можно рассчитать аналитически.</p></li>
<li><p><span class="math inline"><em>L</em><sub><em>E</em><em>N</em></sub> = <em>α</em><em>L</em><sub>1</sub> + (1—<em>α</em>)<em>L</em><sub>2</sub></span> Совмещая LASSO и ridge, получаем ElasticNet, которая объединяет два мира со всеми их плюсами и минусами.</p></li>
</ol>
<p><span class="math inline"><em>w</em>, <em>β</em></span> – это одно и тоже (параметры модели)</p>
<p><img src="img\Ridge_and_Lasso.png" /></p>
<blockquote>
<p>Продублируем наглядный пример из статьи о <a href="https://neerc.ifmo.ru/wiki/index.php?title=Вариации_регрессии">вариациях регрессии</a>. Рассмотрим для простоты двумерное пространство независимых переменных. В случае лассо регрессии ограничение на коэффициенты представляет собой ромб <span class="math inline">(|<em>β</em><sub>1</sub>| + |<em>β</em><sub>2</sub>| ≤ <em>t</em>)</span>, в случае гребневой регрессии — круг <span class="math inline">(<em>β</em><sub>1</sub><sup>2</sup> + <em>β</em><sub>2</sub><sup>2</sup> ≤ <em>t</em><sup>2</sup>)</span>. Необходимо минимизировать функцию ошибки, но при этом соблюсти ограничения на коэффициенты. С геометрической точки зрения задача состоит в том, чтобы найти точку касания линии, отражающей функцию ошибки с фигурой, отражающей ограничения на <em>β</em>. Из рисунка интуитивно понятно, что в случае лассо регрессии эта точка с большой вероятностью будет находиться на углах ромба, то есть лежать на оси, тогда как в случае гребневой регрессии такое происходит очень редко. Если точка пересечения лежит на оси, один из коэффициентов будет равен нулю, а значит, значение соответствующей независимой переменной не будет учитываться.</p>
</blockquote>
<h2 id="ансамбли-классификаторов.-основные-этапы-работы-типичного-базового-классификатора-возможность-коррекции-на-разных-этапах.-бэггинг-и-случайные-подпространства.-бустинг.-случайный-лес-как-композиция-основных-подходов-к-построению-ансамбля.">15. Ансамбли классификаторов. Основные этапы работы типичного базового классификатора, возможность коррекции на разных этапах. Бэггинг и случайные подпространства. Бустинг. Случайный лес как композиция основных подходов к построению ансамбля.</h2>
<p>https://dyakonov.org/2019/04/19/%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B8-%D0%B2-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8/</p>
<p>http://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B8%D0%B4%D1%8B_%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B5%D0%B9</p>
<p>http://www.machinelearning.ru/wiki/images/5/56/Guschin2015Stacking.pdf</p>
<h4 id="ансамбли-классификаторов">Ансамбли классификаторов</h4>
<p><strong>Ансамблем (Ensemble,Multiple Classifier System)</strong> называется алгоритм, который состоит из нескольких алгоритмов машинного обучения, а процесс построения ансамбля называется ансамблированием (ensemble learning). Простейший пример ансамбля в регрессии – усреднение нескольких алгоритмов:</p>
<figure>
<img src="https://alexanderdyakonov.files.wordpress.com/2019/04/f-1-1.png?w=700" alt="" /><figcaption>f-1</figcaption>
</figure>
<p>Алгоритмы из которых состоит ансамбль (в (1) – <span class="math inline"><em>b</em><sub><em>t</em></sub></span>) называются <strong>базовыми алгоритмами (base learners).</strong></p>
<p>Если рассматривать значения базовых алгоритмов на объекте как независимые случайные величины с одинаковым матожиданием и одинаковой конечной дисперсией, то понятно, что случайная величина (1) имеет такое же матожидание, но меньшую дисперсию:</p>
<figure>
<img src="https://alexanderdyakonov.files.wordpress.com/2019/04/f-2.png?w=700" alt="" /><figcaption>f-2.png</figcaption>
</figure>
<p><strong>Замечание.</strong> Требование равенства матожиданий ответов базовых алгоритмов вполне естественное: если мы берём алгоритмы из несмещённой модели, то их матожидания не только совпадают, но и равны значению истинной метки.</p>
<p>Ансамбль алгоритмов (методов) — метод, который использует несколько обучающих алгоритмов с целью получения лучшей эффективности прогнозирования, чем можно было бы получить от каждого обучающего алгоритма по отдельности.</p>
<p>В задачах классификации простейший пример ансамбля – <strong>комитет большинства</strong>:</p>
<figure>
<img src="https://alexanderdyakonov.files.wordpress.com/2019/04/f-3.png?w=700" alt="" /><figcaption>f-3.png</figcaption>
</figure>
<p>где <strong>mode</strong> – мода (значение, которое встречается чаще других среди аргументов функции).</p>
<p>Большинство приёмов в прикладном ансамблировании направлено на то, чтобы ансамбль был «достаточно разнообразным»**, тогда ошибки отдельных алгоритмов на отдельных объектах будут компенсироваться корректной работой других алгоритмов. По сути, при построении ансамбля:</p>
<ul>
<li>повышают качество базовых алгоритмов,</li>
<li>повышают разнообразие (diversity) базовых алгоритмов.</li>
</ul>
<h4 id="основные-этапы-работы-типичного-базового-классификатора-возможность-коррекции-на-разных-этапах">Основные этапы работы типичного базового классификатора, возможность коррекции на разных этапах</h4>
<p>В целом я хз, че тут говорить, но вот например я сгенерировал такой текст:</p>
<p>По сути внутри базового классификатора лежит какая-то из моделей – линейная регрессия, решающее дерево, например.</p>
<p>В случае бэггинга каждому базовому классификатору соответствует какая-то выборка из обучающего датасета, на ней каждый классификатор обучается и подстраивает свои параметры. Общая композиция из этих “недообученных” классификаторов затем одним из методов принимает решение, к какому классу принадлежит тот или иной объект.</p>
<p>В случае бустинга итоговый результат представляется в виде взвешенной суммы из корректирующих друг друга классификаторов.</p>
<p>В то время как бустинг алгоритмически не ограничен, большинство алгоритмов бустинга состоит из итеративного обучения слабых классификаторов с целью сборки их в сильный классификатор. Когда они добавляются, им обычно приписываются некоторым образом веса, которые, обычно, связаны с точностью обучения. После того, как слабый классификатор добавлен, веса пересчитываются, что известно как <a href="https://ru.wikipedia.org/w/index.php?title=Весовые_коэффициенты&amp;action=edit&amp;redlink=1">«пересчёт весовых коэффициентов»</a>[<a href="https://en.wikipedia.org/wiki/weighting">en]</a>. Неверно классифицированные входные данные получают больший вес, а правильно классифицированные экземпляры теряют вес[<a href="https://ru.wikipedia.org/wiki/Бустинг#cite_note-9">nb 1]</a>. Тем самым последующее слабое обучение фокусируется больше на примерах, где предыдущие слабые обучения дали ошибочную классификацию.</p>
<h4 id="бэггинг-и-случайные-подпространства">Бэггинг и случайные подпространства</h4>
<p>Пусть имеется выборка <em>X</em> размера <em>N</em>. Количество классификаторов <em>M</em></p>
<p>Алгоритм использует метод бутстрэпа (англ. <em>bootstrap</em>):</p>
<pre><code>   Из всего множества объектов равновероятно выберем N объектов с возвращением. Это значит, что после выбора каждого из объектов мы будем возращать его в множество для выбора. Отметим, что из-за возвращения некоторые объекты могут повторяться в выбранном множестве.
   Обозначим новую выборку через X1
. Повторяя процедуру M
 раз, сгенерируем M
 подвыборок X1...XM
. Теперь мы имеем достаточно большое число выборок и можем оценивать различные статистики исходного распределения.</code></pre>
<p>Шаги алгоритма бэггинг:</p>
<ul>
<li>Генерируется с помощью бутстрэпа M выборок размера N для каждого классификатора.</li>
<li>Производится независимое обучения каждого элементарного классификатора (каждого алгоритма, определенного на своем подпространстве).</li>
<li>Производится классификация основной выборки на каждом из подпространств (также независимо).</li>
<li>Принимается окончательное решение о принадлежности объекта одному из классов. Это можно сделать несколькими разными способами, подробнее описано ниже.</li>
</ul>
<p><img src="img\Виды_ансамблей_Бэггинг_рус.png" /></p>
<p>В методе случайных подпространств (random subspace method, RSM) базовые алгоритмы обучаются на различных подмножествах признакового описания, которые также выделяются случайным образом. Этот метод предпочтителен в задачах с большим числом признаков и относительно небольшим числом объектов, а также при наличии избыточных неинформативных признаков. В этих случаях алгоритмы,построенные по части признакового описания, могут обладать лучшей обобщающей способностью по сравнению с алгоритмами, построенными по всем признакам. Широко известным алгоритмом, использующим одновременно метод случайных подпространств и бэггинг, является случайный лес. Разбиение объектов в вершине случайного леса ищется среди случайного подмножества признаков, а обучение каждого дерева в композиции происходит на выборке, полученной с помощью операции бутстрапа.</p>
<h4 id="бустинг">Бустинг</h4>
<p>https://neerc.ifmo.ru/wiki/index.php?title=%D0%91%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3,_AdaBoost</p>
<p>Бустинг основан на вопросе, поднятом Кернсом и <a href="https://ru.wikipedia.org/wiki/Вэлиант,_Лесли">Вэлиантом</a> (1988, 1989)[<a href="https://ru.wikipedia.org/wiki/Бустинг#cite_note-_ec01e06736d97577-3">3]</a>[<a href="https://ru.wikipedia.org/wiki/Бустинг#cite_note-_d5a47fc0ef9867e4-4">4]</a>: «Может ли набор слабых обучающих алгоритмов создать сильный обучающий алгоритм?». Слабый обучающий алгоритм определяется как <a href="https://ru.wikipedia.org/wiki/Задача_классификации">классификатор</a>, который слабо коррелирует с правильной классификацией (может пометить примеры лучше, чем случайное угадывание). В отличие от слабого алгоритма, сильный обучающий алгоритм является классификатором, хорошо коррелирующим с верной классификацией.</p>
<p>Положительный ответ Роберта Шапирe в статье 1990 года[<a href="https://ru.wikipedia.org/wiki/Бустинг#cite_note-_f79a06ed82a55228-5">5]</a> на вопрос Кернса и Вэлианта имел большое значение для теории машинного обучения и <a href="https://ru.wikipedia.org/wiki/Статистика">статистики</a>, и привёл к созданию широкого спектра алгоритмов бустинга[<a href="https://ru.wikipedia.org/wiki/Бустинг#cite_note-_e38de82ace1c77bb-6">6]</a>.</p>
<p><strong><em>Гипотеза о бустинге</em></strong> относилась к процессу настройки алгоритма слабого обучения для получения строгого обучения. Неформально, спрашивается, вытекает ли из существования эффективного алгоритма обучения, выходом которого служит гипотеза, эффективность которой лишь слегка лучше случайного гадания (то есть слабое обучение), существование эффективного алгоритма, который даёт гипотезу произвольной точности (то есть сильное обучение)[<a href="https://ru.wikipedia.org/wiki/Бустинг#cite_note-_ec01e06736d97577-3">3]</a>. Алгоритмы, которые получают быстро такую гипотезу, становятся известны просто как «бустинг».</p>
<p><strong>Бустинг.</strong> Пошаговое наращивание ансамбля алгоритмов. Алгоритм, который присоединяется к ансамблю на шаге k обучается по выборке, которая формируется из объектов исходной обучающей выборки.</p>
<p>Классификаторы ансамбля строятся последовательно и на каждой итерации происходит коррекция (перевзвешивание) наблюдений обучающей выборки (на первой итерации веса всех наблюдений равны). Коррекция осуществляется таким образом, чтобы соответствующий классификатор делал меньше ошибок на тех наблюдениях, на которых часто делали ошибки классификаторы, построенные на предыдущих итерациях алгоритма. Кроме того, каждому классификатору приписывается некоторый вес исходя из количества допущенных им ошибок.</p>
<p>Например, один из первых алгоритмов бустинга Boost1 использовал ансамбль из 3-х моделей, первая из которых обучалась на всем наборе данных, вторая – на выборке примеров, в половине из которых первая дала правильные ответы, а третья - на примерах, где «ответы» первых двух разошлись. Т.е. происходит последовательная обработка примеров цепочкой классификаторов, причем так, что задача для каждого последующего становится труднее. Результат определяется путем простого голосования: пример относится к тому классу, который выдан большинством моделей ансамбля.</p>
<p>Развитием данного подхода явилась разработка более совершенного семейства алгоритмов бустинга AdaBoost, который может использовать произвольное число классификаторов и производить обучение на одном наборе примеров, поочередно применяя их на различных шагах.</p>
<h4 id="случайный-лес-как-композиция-основных-подходов-к-построению-ансамбля.">Случайный лес как композиция основных подходов к построению ансамбля.</h4>
<p>https://dyakonov.org/2016/11/14/%d1%81%d0%bb%d1%83%d1%87%d0%b0%d0%b9%d0%bd%d1%8b%d0%b9-%d0%bb%d0%b5%d1%81-random-forest/</p>
<p><strong>Решающие деревья</strong> – классификация объекта с помощью ответов на иерархически организованную систему вопросов. Вопрос, задаваемый на последующем иерархическом уровне, зависит от ответа, полученного на предыдущем уровне.</p>
<p><img src="img/360px-CART_tree_titanic_survivors_%28RU%29.png" /></p>
<p><strong>RF (random forest)</strong> — это множество решающих деревьев (ансамбль). В задаче регрессии их ответы усредняются, в задаче классификации принимается решение голосованием по большинству. Все деревья строятся независимо по следующей схеме:</p>
<ul>
<li>Выбирается подвыборка обучающей выборки размера samplesize (м.б. с возвращением) – по ней строится дерево (для каждого дерева — своя подвыборка). (<strong>бэггинг</strong>)</li>
<li>Для построения каждого расщепления в дереве просматриваем max_features случайных признаков (для каждого нового расщепления — свои случайные признаки). (<strong>случайные подпространства</strong>)</li>
<li>Выбираем наилучшие признак и расщепление по нему (по заранее заданному критерию). Дерево строится, как правило, до исчерпания выборки (пока в листьях не останутся представители только одного класса), но в современных реализациях есть параметры, которые ограничивают высоту дерева, число объектов в листьях и число объектов в подвыборке, при котором проводится расщепление.</li>
</ul>
<p><strong>Алгоритм случайного леса</strong> сочетает в себе две идеи: метод бэггинга и метод случайных подпространств. Для полученных данных алгоритм создает множество деревьев принятия решений и потом усредняет результат их предсказаний (бэггинг). Случайность: если создать много одинаковых деревьев, то результат их усреднения будет обладать точностью одного дерева. На практике: из всего набора входных данных случайным образом выбирается некоторое количество столбцов и строк и строится первое дерево принятия решений. Такая процедура повторяется множество раз, на выходе получается множество деревьев =&gt; результат – класс, к которому отнесли большинство деревьев.</p>
<h2 id="задача-кластеризации-как-фундаментальная-задача-интеллектуального-анализа-данных-сопоставление-с-операцией-группирования-и-задачей-классификации.-различные-постановки-разбиение-стохастическая-нечёткая-иерархическая-упорядочивание-однокластерная-последовательная.-примеры-методов-кластеризации-для-разных-постановок.">16. Задача кластеризации как фундаментальная задача интеллектуального анализа данных, сопоставление с операцией группирования и задачей классификации. Различные постановки: разбиение, стохастическая, нечёткая, иерархическая, упорядочивание, однокластерная (последовательная). Примеры методов кластеризации для разных постановок.</h2>
<p>Предварительно отмечу, что этой темы не было у нас в курсе вообще!!!</p>
<h4 id="задача-кластеризации-как-фундаментальная-задача-интеллектуального-анализа-данных-сопоставление-с-операцией-группирования-и-задачей-классификации">Задача кластеризации как фундаментальная задача интеллектуального анализа данных, сопоставление с операцией группирования и задачей классификации</h4>
<p>http://www.machinelearning.ru/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F</p>
<p>https://habr.com/ru/post/101338/</p>
<p><strong>Кластерный анализ</strong> (Data clustering) — задача разбиения заданной <a href="http://www.machinelearning.ru/wiki/index.php?title=Выборка">выборки</a> <em>объектов</em> (ситуаций) на непересекающиеся подмножества, называемые <a href="http://www.machinelearning.ru/wiki/index.php?title=Кластер&amp;action=edit">кластерами</a>, так, чтобы каждый кластер состоял из схожих объектов, а объекты разных кластеров существенно отличались.</p>
<p><img src="img\clustering.jpg" /></p>
<p>Задача кластеризации относится к широкому классу задач <a href="http://www.machinelearning.ru/wiki/index.php?title=Обучение_без_учителя">обучения без учителя</a>.</p>
<p>Пусть <img src="http://www.machinelearning.ru/mimetex/?X" alt="X" /> — множество объектов, <img src="http://www.machinelearning.ru/mimetex/?Y" alt="Y" /> — множество номеров (имён, меток) кластеров. Задана функция расстояния между объектами <img src="http://www.machinelearning.ru/mimetex/?\rho(x,x&#39;)" alt="(x,x’)" />. Имеется конечная обучающая выборка объектов <img src="http://www.machinelearning.ru/mimetex/?X%5Em%20=%20%7B%20x_1,%20\dots,%20x_m%20%7D%20\subset%20X" alt="X^m = { x_1, , x_m } X" />. Требуется разбить выборку на непересекающиеся подмножества, называемые <em>кластерами</em>, так, чтобы каждый кластер состоял из объектов, близких по метрике <img src="http://www.machinelearning.ru/mimetex/?\rho" alt="" />, а объекты разных кластеров существенно отличались. При этом каждому объекту <img src="http://www.machinelearning.ru/mimetex/?x_i\in%20X%5Em" alt="x_iX^m" /> приписывается номер кластера <img src="http://www.machinelearning.ru/mimetex/?y_i" alt="y_i" />.</p>
<p>Примеры функций расстояния:</p>
<ul>
<li><p><em>Евклидово расстояние</em> Наиболее распространенная функция расстояния. Представляет собой геометрическим расстоянием в многомерном пространстве: <img src="https://habrastorage.org/getpro/habr/post_images/aa4/6e7/d7b/aa46e7d7b544dbaa221a43bb671fb43c.jpg" alt="img" /></p></li>
<li><p><em>Квадрат евклидова расстояния</em> Применяется для придания большего веса более отдаленным друг от друга объектам. Это расстояние вычисляется следующим образом: <img src="https://habrastorage.org/getpro/habr/post_images/5dc/84a/1d6/5dc84a1d66392e9f11ba13be381ad036.jpg" alt="img" /></p></li>
<li><p><em>Расстояние городских кварталов (манхэттенское расстояние)</em> Это расстояние является средним разностей по координатам. В большинстве случаев эта мера расстояния приводит к таким же результатам, как и для обычного расстояния Евклида. Однако для этой меры влияние отдельных больших разностей (выбросов) уменьшается (т.к. они не возводятся в квадрат). Формула для расчета манхэттенского расстояния: <img src="https://habrastorage.org/getpro/habr/post_images/930/f68/0a2/930f680a27caed2bed04f6b09a70a785.jpg" alt="img" /></p></li>
</ul>
<p><em>Алгоритм кластеризации</em> — это функция <img src="http://www.machinelearning.ru/mimetex/?a:,%20X\to%20Y" alt="a:, XY" />, которая любому объекту <img src="http://www.machinelearning.ru/mimetex/?x\in%20X" alt="xX" /> ставит в соответствие номер кластера <img src="http://www.machinelearning.ru/mimetex/?y\in%20Y" alt="yY" />. Множество <img src="http://www.machinelearning.ru/mimetex/?Y" alt="Y" /> в некоторых случаях известно заранее, однако чаще ставится задача определить оптимальное число кластеров, с точки зрения того или иного <em>критерия качества</em> кластеризации.</p>
<p><img src="img\classificclustering.jpg" /></p>
<p>Кластеризация (<a href="http://www.machinelearning.ru/wiki/index.php?title=Обучение_без_учителя">обучение без учителя</a>) отличается от <a href="http://www.machinelearning.ru/wiki/index.php?title=Классификация">классификации</a> (<a href="http://www.machinelearning.ru/wiki/index.php?title=Обучение_с_учителем">обучения с учителем</a>) тем, что метки исходных объектов <img src="http://www.machinelearning.ru/mimetex/?y_i" alt="y_i" /> изначально не заданы, и даже может быть неизвестно само множество <img src="http://www.machinelearning.ru/mimetex/?Y" alt="Y" />.</p>
<p>Решение задачи кластеризации принципиально неоднозначно, и тому есть несколько причин:</p>
<ul>
<li>Не существует однозначно наилучшего критерия качества кластеризации. Известен целый ряд эвристических критериев, а также ряд алгоритмов, не имеющих чётко выраженного критерия, но осуществляющих достаточно разумную кластеризацию «по построению». Все они могут давать разные результаты.</li>
<li>Число кластеров, как правило, неизвестно заранее и устанавливается в соответствии с некоторым субъективным критерием.</li>
<li>Результат кластеризации существенно зависит от метрики, выбор которой, как правило, также субъективен и определяется экспертом.</li>
</ul>
<h6 id="типы-входных-данных">Типы входных данных</h6>
<ul>
<li><a href="http://www.machinelearning.ru/wiki/index.php?title=Признаковое_описание">Признаковое описание</a> объектов. Каждый объект описывается набором своих характеристик, называемых <em>признаками</em>. Признаки могут быть числовыми, порядковыми и категориальными.</li>
<li><a href="http://www.machinelearning.ru/wiki/index.php?title=Матрица_расстояний&amp;action=edit">Матрица расстояний</a> между объектами. Каждый объект описывается расстояниями до всех остальных объектов обучающей выборки.</li>
</ul>
<h6 id="цели-кластеризации">Цели кластеризации</h6>
<ul>
<li><a href="http://www.machinelearning.ru/wiki/index.php?title=Понимание_данных&amp;action=edit">Понимание данных</a> путём выявления кластерной структуры. Разбиение выборки на группы схожих объектов позволяет упростить дальнейшую обработку данных и принятия решений, применяя к каждому кластеру свой метод анализа (стратегия «<a href="http://www.machinelearning.ru/wiki/index.php?title=Разделяй_и_властвуй&amp;action=edit">разделяй и властвуй</a>»).</li>
<li><a href="http://www.machinelearning.ru/wiki/index.php?title=Сжатие_данных&amp;action=edit">Сжатие данных</a>. Если исходная выборка избыточно большая, то можно сократить её, оставив по одному наиболее типичному представителю от каждого кластера.</li>
<li><a href="http://www.machinelearning.ru/wiki/index.php?title=Обнаружение_новизны&amp;action=edit">Обнаружение новизны</a> (novelty detection). Выделяются нетипичные объекты, которые не удаётся присоединить ни к одному из кластеров.</li>
</ul>
<h4 id="различные-постановки-разбиение-стохастическая-нечёткая-иерархическая-упорядочивание-однокластерная-последовательная.-примеры-методов-кластеризации-для-разных-постановок.">Различные постановки: разбиение, стохастическая, нечёткая, иерархическая, упорядочивание, однокластерная (последовательная). Примеры методов кластеризации для разных постановок.</h4>
<ul>
<li><p>Разбиение – непосредственно разбиение объектов на конкретные кластеры, алгоритмы: k-means, алгоритмы иерархической кластеризации. (наверное)</p></li>
<li><p>Стохастическая – хз что это, не могу нигде найти. Предположу, что выдвигается гипотеза о том, что каждый кластер представляет из себя некоторое распределение, а значит, все разделяемое пространство объектов – смесь таких распределений. Значит, задача сведется к разделению смеси распределений. Алгоритм: Gaussian Mixture Models.</p></li>
<li><p>Нечеткая кластеризация – Нечёткую кластеризацию от просто кластеризации отличает то, что объекты, которые подвергаются кластеризации, относятся к конкретному кластеру с некой принадлежностью, а не однозначно, как это бывает при обычной кластеризации. Например, при нечёткой кластеризации объект A относится к кластеру K1 с вероятностью 0.9, к кластеру K2 — с вероятностью 0.04 и к кластеру К3 — с вероятностью 0.06. При обычной же (чёткой) кластеризации объект А был бы отнесён к кластеру K1. Алгоритм: c-means</p></li>
<li><p>Иерархические алгоритмы (также называемые алгоритмами таксономии) строят не одно разбиение выборки на непересекающиеся кластеры, а систему вложенных разбиений. Т.о. на выходе мы получаем дерево кластеров, корнем которого является вся выборка, а листьями — наиболее мелкие кластера. Нисходящие алгоритмы работают по принципу «сверху-вниз»: в начале все объекты помещаются в один кластер, который затем разбивается на все более мелкие кластеры. Более распространены восходящие алгоритмы, которые в начале работы помещают каждый объект в отдельный кластер, а затем объединяют кластеры во все более крупные, пока все объекты выборки не будут содержаться в одном кластере. Таким образом строится система вложенных разбиений.</p></li>
<li><p>Упорядочивание – не знаю, вероятно, выдача меток объектам, при этом кластеры не образуют никаких вложенных структур. Алгоритмы: K-Means</p></li>
<li><p>Однокластерная – (выдуманное определение) в данной постановке размечаются объекты, принадлежащие к одному и тому же кластеру, остальные считаются не принадлежащими к нему, каждый кластер ищется последовательно, одним из примеров алгоритмов, который использует данные принципы, алгоритм плотностной кластеризации DBScan</p></li>
</ul>
<p><img src="img\algos.png" /></p>
<p>На картинке демонстрация результатов работы различных алгоритмов кластеризации. Как видно, для разных данных разные алгоритмы по-разному работают.</p>
<h5 id="дискреционное-управление-доступом.-модели-hru-и-take-grant.-задача-проверки-безопасности-системы-защиты-от-нсд.">17. Дискреционное управление доступом. Модели HRU и Take-Grant. Задача проверки безопасности системы защиты от НСД.</h5>
<h6 id="модели-дискреционного-доступа"><strong>Модели дискреционного доступа</strong></h6>
<p>Политика дискреционного доступа охватывает самую многочисленную совокупность моделей разграничения доступа, реализованных в большинстве защищенных КС, и исторически является первой, проработанной в теоретическом и практическом плане.</p>
<p>Модели дискреционного доступа непосредственно основываются и развивают субъектно-объектную модель КС как совокупность некоторых множеств взаимодействующих элементов (субъектов, объектов и т. д.).</p>
<p>Множество (область) безопасных доступов в моделях дискреционного доступа определяется дискретным набором троек <strong>“Пользователь (субъект)-поток (операция)-объект”</strong>.</p>
<p>Права доступа предоставляются («прописываются» в специальных информационных объектах-структурах, ассоциированных с монитором безопасности), отдельно каждому пользователю к тем объектам, которые ему необходимы для работы в КС.</p>
<p>При запросе субъекта на доступ к объекту монитор безопасности, обращаясь к ассоциированным с ним информационным объектам, в которых «прописана» политика разграничения доступа, определяет «легальность» запрашиваемого доступа и разрешает/отвергает доступ</p>
<p><strong>Механизмы реализации дискреционного разграничения доступа</strong> Различаются:</p>
<ul>
<li>в зависимости от принципов и механизмов программно-информационной структуры объекта(объектов), ассоциированных с монитором безопасности, в которых хранятся «прописанные» права доступа (тройки доступа)</li>
<li>в зависимости от принципа управления правами доступа, т.е. в зависимости от того – кто и как заполняет/изменяет ячейки матрицы доступа (принудительный и добровольный принцип управления доступом).</li>
</ul>
<p>Проблема безопасности в КС рассматривается с точки зрения анализа и исследования условий, правил, порядка и т. п. разрешений запросов на доступ, при которых система, изначально находясь в безопасном состоянии, за конечное число переходов перейдет также в безопасное состояние.</p>
<p><strong><em>модель на основе матрицы доступа:</em></strong> - матрица определяющая права субъекта по отношению к объекту</p>
<ul>
<li>централизованная или децентрализованная:
<ul>
<li>при централизованной: матрица доступа создается как отдельный самостоятельный объект с особым порядком размещения и доступа к нему, она может достигать очень больших величин, и, кроме того, подвержено динамическому изменению. В большинстве систем при централизованном подходе строки матрицы доступа характеризуют не субъектов, а непосредственно самих пользователей и их группы, зарегистрированные для работы в системе.</li>
<li>при децентрадизованной: матрица доступа как отдельный объект не создается, а представляется или так называемыми “списками доступа”, распределенными по объектам системы, или так называемыми “списками возможностей”, распределенными по субъектам доступа.</li>
</ul></li>
<li>с понятием владения объектами (тогда владелец сам задаёт права доступа для других) или без понятия владения (тогда админ всем заправляет)</li>
</ul>
<h6 id="модели-hru-харрисона-руззо-ульмана"><strong>Модели HRU (Харрисона-Руззо-Ульмана)</strong></h6>
<p>одна из <a href="https://ru.wikipedia.org/w/index.php?title=Формальная_модель&amp;action=edit&amp;redlink=1">формальных моделей</a> <a href="https://ru.wikipedia.org/wiki/Избирательное_управление_доступом">управления доступом</a> субъектов (пользователей) к объектам, реализованная с помощью <a href="https://ru.wikipedia.org/w/index.php?title=Матрица_доступа&amp;action=edit&amp;redlink=1">матрицы доступов</a> – матрица с полным описанием пользовательских прав к файлам. Изменения в эту матрицу вводятся с помощью специальных команд.</p>
<p>Введем некоторые обозначения: S - множество субъектов; O - множество объектов; R = (r<sub>1</sub>,r<sub>2</sub>,…,r<sub>n</sub>) - множество прав доступа; Строки матрицы доступа M соответствуют субъектам, столбцы объектам. Текущее состояние системы Q однозначно записывается тройкой Q=(S,O,M)</p>
<p>Для того, чтобы был возможен переход из Q=(S,O,M) в Q’=(S’,O’,M’) нужно ввести некоторые элементарные операции. Для этой цели в данной модели существует шесть операторов op:</p>
<ul>
<li><em>Enter r into M(s,o)</em> - ввести право r в ячейку M(s,o);</li>
<li><em>Delete r from M(s,o)</em> - удалить право r из ячейки M(s,o);</li>
<li><em>Create subject s</em> - создать субъект s (т.е. новую строку матрицы M);</li>
<li><em>Create object o</em> - создать объект o (т.е. новый столбец матрицы M);</li>
<li><em>Destroy subject s</em> - уничтожить субъект s;</li>
<li><em>Destroy object o</em> - уничтожить объект o;</li>
</ul>
<p>Условия выполнения и новое состояние системы записаны в виде таблицы</p>
<p><img src=".\img\17_1.PNG" alt="17_1" style="zoom: 50%;" /></p>
<p><strong>Системы в модели HRU</strong> Любая система в модели HRU характеризуется матрицей доступа M, конечным количеством прав R = (r<sub>1</sub>,r<sub>2</sub>,…,r<sub>n</sub>), объектов O = (o<sub>1</sub>,o<sub>2</sub>,…,o<sub>m</sub>), субъектов S = (s<sub>1</sub>,s<sub>2</sub>,…,s<sub>l</sub>) и операций A=(a<sub>1</sub>, a<sub>2</sub>, …, a<sub>k</sub>). Система является монооперационной, если каждая команда a<sub>i</sub> данной системы выполняет лишь одну элементарную операцию op.</p>
<p><strong>Критерий безопасности системы</strong> Для заданной системы исходное состояние Q<sub>0</sub>=(S<sub>0</sub>,O<sub>0</sub>,M<sub>0</sub>) называется безопасным относительно права r, если не существует такой последовательности команд, которая изменила бы заданное начальное состояние системы так, что право r записалось бы в ячейку M(s,o), в которой оно отсутствовало в начальном состоянии Q<sub>0</sub>. Если это условие не выполнено, то произошла утечка информации</p>
<p><strong>Теоремы:</strong></p>
<ul>
<li>Существует алгоритм, проверяющий исходное состояние Q<sub>0</sub> монооперационной системы на безопасность относительно права r.</li>
<li>Задача определения безопасности исходного состояния Q<sub>0</sub> системы общего вида для данного права r является неразрешимой. (Чтобы доказать данную теорему, достаточно свести задачу определения безопасности к задаче остановки <a href="https://ru.wikipedia.org/wiki/Машина_Тьюринга">машины Тьюринга</a>, которая является заведомо неразрешимой.)</li>
</ul>
<p><strong>Преимущества HRU</strong></p>
<ol type="1">
<li>Простота и наглядность, так как для данной модели не требуется сложных алгоритмов.</li>
<li>Эффективность в управлении, так как возможно управление правами пользователей с точностью до операции.</li>
<li>Сильный критерий безопасности.</li>
</ol>
<p><strong>Недостатки HRU</strong></p>
<ol type="1">
<li>Не существует алгоритма проверки на безопасность для произвольной системы.</li>
<li>Не существует алгоритма проверки на безопасность для произвольной системы.</li>
</ol>
<h6 id="модель-take-grant"><strong>Модель Take-Grant</strong></h6>
<p>Система защиты представляет совокупность следующих множеств:</p>
<ul>
<li>множество исходных объектов O = (o<sub>1</sub>,o<sub>2</sub>,…,o<sub>m</sub>)</li>
<li>множество исходных субъектов S = (s<sub>1</sub>,s<sub>2</sub>,…,s<sub>l</sub>), при этом <span class="math inline"><em>S</em> ⊂ <em>O</em></span></li>
<li>множество прав, которые м.б. даны субъектам по отношению к объектам (r<sub>1</sub>,r<sub>2</sub>,…,r<sub>n</sub>)<span class="math inline"> ∪ {<em>t</em>, <em>g</em>}</span>
<ul>
<li>право take (t – право брать права доступа у какого-либо объекта по отношению к другому объекту)</li>
<li>право grant (g – право предоставлять права доступа к определенному объекту другому субъекту)</li>
</ul></li>
<li>множеством E установленных прав доступа (x, y,<span class="math inline"><em>α</em></span>) субъекта x к объекту y с правом <span class="math inline"><em>α</em></span> из конечного набора прав.</li>
</ul>
<p>При этом состояние системы представляется графом доступов Г(O,S,E)</p>
<figure>
<img src=".\img\17_2.PNG" alt="" /><figcaption>17_2</figcaption>
</figure>
<p>Состояние системы (Графа доступов) изменяется под воздействием элементарных команд 4-х видов:</p>
<ul>
<li>Команда “Брать” – take(<span class="math inline"><em>α</em></span>, x, y, z): субъект x берет права доступа <span class="math inline"><em>α</em> ⊆ <em>β</em></span> на объект z у объекта y</li>
</ul>
<figure>
<img src=".\img\17_3.PNG" alt="" /><figcaption>17_3</figcaption>
</figure>
<ul>
<li>Команда “Давать” – grant(<span class="math inline"><em>α</em></span>, x, y, z): субъект x дает объекту y право <span class="math inline"><em>α</em> ⊆ <em>β</em></span> на доступ к объекту z</li>
</ul>
<figure>
<img src=".\img\17_4.PNG" alt="" /><figcaption>17_4</figcaption>
</figure>
<ul>
<li>Команда “Создать” – create(<span class="math inline"><em>β</em></span>, x, y): субъект x создает объект y с правами доступа на него β <span class="math inline">⊆</span> R (y – новый объект, O’=O <span class="math inline">∪</span> {y}), в т. ч. с правами t, или g, или {t, g}.</li>
</ul>
<figure>
<img src=".\img\17_5.PNG" alt="" /><figcaption>17_5</figcaption>
</figure>
<ul>
<li>Команда “Изъять” – remove(<span class="math inline"><em>α</em></span>, x, y): субъект x удаляет права доступа <span class="math inline"><em>α</em> ⊆ <em>β</em></span> на объект y</li>
</ul>
<figure>
<img src=".\img\17_6.PNG" alt="" /><figcaption>17_6</figcaption>
</figure>
<p><strong>Безопасность системы</strong> рассматривается с точки зрения возможности получения каким-либо субъектом прав доступа к определенному объекту (в начальном состоянии Г<sub>0</sub> (O<sub>0</sub>, S<sub>0</sub>, E<sub>0</sub>) такие права отсутствуют) при определенной кооперации субъектов путем последовательного изменения состояния системы на основе выполнения элементарных команд.</p>
<p>Рассматриваются две ситуации – условия санкционированного, т.е. законного получения прав доступа, и условия «похищения» прав доступа.</p>
<p><strong>Обозначения:</strong> ├с – переход графа Г в новое состояние Г ’ по команде c ;</p>
<p><strong>Определения:</strong></p>
<ul>
<li><p>Для исходного состояния системы Г<sub>0</sub> (O<sub>0</sub>, S<sub>0</sub>, E<sub>0</sub> ) и прав доступа <span class="math inline"><em>α</em>⊆</span> R предикат “возможен доступ(<span class="math inline"><em>α</em></span>, x, y, Г<sub>0</sub> )” является истинным тогда и только тогда, когда существуют графы доступов системы Г<sub>1</sub>, Г<sub>2</sub>, …, Г<sub>N</sub> такие, что: Г<sub>0</sub>├с1 Г<sub>1</sub>├с2…├сN Г<sub>N</sub> , и (x, y, <span class="math inline"><em>α</em></span>) <span class="math inline">∈</span>E<sub>N</sub>, где c1, c2, …, cN – команды переходов</p></li>
<li><p>Вершины графа доступов являются tg-связными (соединены tg-путем), если в графе между ними существует такой путь, что каждая дуга этого пути выражает право t или g (без учета направления дуг)</p></li>
<li><p>Для исходного состояния системы Г<sub>0</sub> (O<sub>0</sub>, S<sub>0</sub>, E<sub>0</sub> ) и прав доступа <span class="math inline"><em>α</em>⊆</span> R предикат “возможно похищение (<span class="math inline"><em>α</em></span>, x, y, Г<sub>0</sub> )” является истинным тогда и только тогда, когда существуют графы доступов системы Г<sub>1</sub>, Г<sub>2</sub>, …, Г<sub>N</sub> такие, что: Г<sub>0</sub>├с1 Г<sub>1</sub>├с2…├сN Г<sub>N</sub> , и (x, y, <span class="math inline"><em>α</em></span>) <span class="math inline">∈</span>E<sub>N</sub>, где c1, c2, …, cN – команды переходов; при этом, если <span class="math inline">$\exist$</span> (s, y, <span class="math inline"><em>α</em></span>) <span class="math inline">∈</span> E<sub>0</sub>, то <span class="math inline">∀<em>z</em> ∈ <em>S</em><sub><em>j</em></sub>, <em>j</em> = 0, 1, ...<em>N</em></span>, выполняется: c1 <span class="math inline">≠</span> grant(<span class="math inline"><em>α</em></span>, s, z, y).</p></li>
</ul>
<p><strong>Теоремы:</strong></p>
<ul>
<li><p>В графе доступов Г<sub>0</sub> (O<sub>0</sub>, S<sub>0</sub>, E<sub>0</sub> ), содержащем только вершины-субъекты, предикат “возможен доступ(<span class="math inline"><em>α</em></span>, x, y, Г0 )” истинен тогда и только тогда, когда выполняются следующие условия:</p>
<ul>
<li>существуют субъекты s<sub>1</sub>,…,s<sub>m</sub> такие, что (s<sub>i</sub>, y, <span class="math inline"><em>γ</em><sub><em>i</em></sub></span>)<span class="math inline">∈</span>E<sub>0</sub> для i=1, …, m и <span class="math inline"><em>α</em> = <em>γ</em><sub>1</sub> ∪ ... ∪ <em>γ</em><sub><em>m</em></sub></span>.</li>
<li>субъект х соединен в графе Г<sub>0</sub> tg-путем с каждым субъектом s<sub>i</sub> для i=1, …, m</li>
</ul></li>
<li><p>Еще одна теорема на слайде</p>
<p><img src=".\img\17_7.PNG" alt="17_7" style="zoom: 50%;" /></p>
<p><img src=".\img\17_8.PNG" alt="17_8" style="zoom:50%;" /></p></li>
<li><p>В произвольном графе доступов Г<sub>0</sub> (O<sub>0</sub>, S<sub>0</sub>, E<sub>0</sub> ) предикат “возможно похищение (<span class="math inline"><em>α</em></span>, x, y, Г<sub>0</sub> )” истинен тогда и только тогда, когда выполняются условия:</p>
<ul>
<li>(x, y,<span class="math inline"><em>α</em></span>) <span class="math inline">∉</span> E<sub>0</sub></li>
<li>существуют субъекты s<sub>1</sub>,…,s<sub>m</sub> такие, что (s<sub>i</sub>, y, <span class="math inline"><em>γ</em><sub><em>i</em></sub></span>)<span class="math inline">∈</span> E<sub>0</sub> для i=1, …, m и <span class="math inline"><em>α</em> = <em>γ</em><sub>1</sub> ∪ ... ∪ <em>γ</em><sub><em>m</em></sub></span>.<br />
</li>
<li>являются истинными предикаты “возможен доступ(t, x, s<sub>i</sub>, Г<sub>0</sub>)” для i=1, …, m.</li>
</ul></li>
</ul>
<p><strong>Достоинства дискреционных моделей</strong></p>
<ul>
<li>Хорошая гранулированность защиты (позволяют управлять доступом с точностью до отдельной операции над отдельным объектом)</li>
<li>Простота реализации</li>
</ul>
<p><strong>Недостатки дискреционных моделей</strong></p>
<ul>
<li>Слабые защитные характеристики из-за невозможности для реальных систем выполнять все ограничения безопасности</li>
<li>Проблема “троянских коней”</li>
<li>Сложности в управлении доступом из-за большого количества назначений прав доступа</li>
</ul>
<h6 id="задача-проверки-системы-от-несанкционированного-доступа"><strong>Задача проверки системы от несанкционированного доступа</strong></h6>
<p><strong><em>Защита информации от несанкционированного доступа</em> (НСД)</strong> - деятельность, направленная на предотвращение получения защищаемой информации заинтересованным субъектом с нарушением установленных правовыми документами или собственником, владельцем информации прав или правил доступа к защищаемой информации. <strong><em>Несанкционированный доступ к информации</em> (НСД)</strong> - доступ к информации, нарушающий правила разграничения доступа с использованием штатных средств, предоставляемых средствами вычислительной техники или автоматизированными системами. <strong><em>Организация защиты информации</em></strong> - содержание и порядок действий, направленных на обеспечение защиты информации. <strong><em>Система защиты информации</em></strong> - совокупность органов и (или) исполнителей, используемой ими техники защиты информации, а также объектов защиты, организованная и функционирующая по правилам, установленным соответствующими правовыми, организационно -распорядительными и нормативными документами в области защиты информации <strong><em>Средство защиты информации</em></strong> - техническое, программное средство, вещество и (или) материал, предназначенные или используемые для защиты информации <strong><em>Средство контроля эффективности защиты информации</em></strong> - техническое, программное средство, вещество и (или) материал, предназначенные или используемые для контроля эффективности защиты информации <strong><em>Потоком информации</em></strong> между объектом O<sub>m</sub> и объектом O<sub>j</sub> называется произвольная операция над объектом O<sub>j</sub>, реализуемая в субъекте S<sub>i</sub> и зависящая от О<sub>m</sub>. <em>Stream(S<sub>i</sub> О<sub>m</sub>) → O<sub>j</sub></em> <strong><em>Монитор порождения субъектов (МПС)</em></strong> — субъект, активизирующийся при любом порождении субъектов. <strong><em>Монитор безопасности субъектов</em> (МБС)</strong> — субъект, который разрешает порождение потоков только для фиксированного подмножества пар активизирующих субъектов и объектов-источников.</p>
<p>Потоки информации в рамках субъектно-объектной модели документа либо легальны (множество потоков L), либо нелегальны (множество потоков N), т.е. нарушают целостность или конфиденциальность.</p>
<p>Требования к МБО - монитору безопасности:</p>
<ul>
<li>полнота и непрерывность (он работает всегда и его не обойти)</li>
<li>изолированность (монитор должен быть защищён)</li>
<li>верифицируемость (нужно уметь проверить корректность монитора)</li>
</ul>
<h1 id="методы-аутентификации-в-сети.-протокол-аутентификации-kerberos.">18. Методы аутентификации в сети. Протокол аутентификации Kerberos.</h1>
<h2 id="основные-определения">Основные определения</h2>
<p><strong>Идентификация</strong> — это процесс распознавания элемента системы, обычно с помощью заранее определённого идентификатора или другой уникальной информации — каждый субъект или объект системы должен быть однозначно идентифицируем.</p>
<p><strong>Аутентификация</strong> — это проверка подлинности идентификации пользователя, процесса, устройства или другого компонента системы (обычно осуществляется перед разрешением доступа).</p>
<p>Идентификация и аутентификация — взаимосвязанные процессы распознавания и проверки подлинности субъектов (пользователей). Именно от них зависит решение системы, можно ли разрешить доступ к ресурсам системы конкретному пользователю или процессу.</p>
<p>После того как субъект <em>идентифицирован и аутентифицирован,</em> выполняется его <em>авторизация</em>.</p>
<h2 id="методы-идентификации-на-основе-секрета">Методы идентификации на основе секрета</h2>
<ul>
<li><p><strong>Простая аутентификация</strong> (на основе использования паролей);</p></li>
<li><p><strong>Строгая аутентификация</strong> (на основе использования криптографических методов и средств);</p></li>
<li><p>Процессы (протоколы) аутентификации, обладающие свойством доказательства <strong>с нулевым знанием.</strong></p></li>
</ul>
<p>Слабость простой аутентификации именно в самом пароле и человеческом факторе. Далее рассматриваем строгую аутентификацию.</p>
<h2 id="строгая-аутентификация">Строгая аутентификация</h2>
<p>Идея строгой аутентификации, реализуемая в криптографических протоколах, заключается в следующем. Проверяемая (доказывающая) сторона доказывает свою подлинность проверяющей стороне, демонстрируя знание какого-либо секрета, который, например, может быть предварительно распределен безопасным способом между сторонами аутентификационного обмена. Важно, что доказывающая сторона демонстрирует только знание секрета, но сам он в ходе аутентификационного обмена не раскрывается.</p>
<p>В соответствии с рекомендациями стандарта Х.509 различают процедуры строгой аутентификации следующих типов:</p>
<ul>
<li><p>односторонняя аутентификация;</p></li>
<li><p>двусторонняя аутентификация;</p></li>
<li><p>трехсторонняя аутентификация.</p></li>
</ul>
<p>В зависимости от используемых криптографических алгоритмов протоколы строгой аутентификации можно разделить на следующие группы:</p>
<ul>
<li><p>протоколы аутентификации на основе симметричных алгоритмов;</p></li>
<li><p>протоколы аутентификации на основе хэш-функций;</p></li>
<li><p>протоколы аутентификации на основе асимметричных алгоритмов;</p></li>
<li><p>протоколы аутентификации на основе цифровой подписи.</p></li>
</ul>
<p>Так как билет про Kerberos, далее рассматриваются протоколы аутентификации на основе симметричных алгоритмов. На всякий случай вспомним:</p>
<p><strong>Симметричное шифрование</strong> — способ шифрования, в котором для шифрования и расшифровывания применяется один и тот же криптографический ключ.</p>
<p>Простой пример как можно сделать двустороннюю аутентификацию на симметричном шифровании:</p>
<ol type="1">
<li><p><span class="math inline"><em>A</em> ← <em>B</em> : <em>R</em><sub><em>B</em></sub></span></p></li>
<li><p><span class="math inline"><em>A</em> → <em>B</em> : <em>E</em><sub><em>K</em></sub>(<em>R</em><sub><em>A</em></sub>, <em>R</em><sub><em>B</em></sub>, <em>B</em>)</span></p></li>
<li><p><span class="math inline"><em>A</em> ← <em>B</em> : <em>E</em><sub><em>K</em></sub>(<em>R</em><sub><em>A</em></sub>, <em>R</em><sub><em>B</em></sub>)</span></p></li>
</ol>
<p>Шаг 0: A и B хотят взаимно аутентифицироваться, симметричный ключ <span class="math inline"><em>E</em><sub><em>K</em></sub></span> есть у обоих участников</p>
<p>Шаг 1: Участник B посылает участнику A случайное число</p>
<p>Шаг 2: Участник A отвечает зашифрованной <span class="math inline"><em>E</em><sub><em>K</em></sub></span> последовательностью из принятого числа, еще одного случайного числа и идентификатора B.</p>
<p>Шаг 3: Участник B отвечает зашифрованной последовательностью из двух ранее посланных случайных чисел.</p>
<h2 id="kdc">KDC</h2>
<p>Помимо аутентификации нужно еще генерировать ключ сессии для шифрования пользовательских данных, которые мы хотим послать (а шифровать все одним ключом не по феншую), поэтому для обеспечения аутентификации и распределения ключа сессии в сети используется двухуровневая иерархия ключей симметричного шифрования, которая используется двумя сторонами или основана на использовании доверенного центра (3-й стороны) распределения ключей (KDC).</p>
<p>Рассмотрим вариант с KDC.</p>
<p>Каждый участник разделяет секретный ключ, называемый также мастер-ключом, с KDC. KDC отвечает за создание ключей, называемых ключами сессии, и за распределение этих ключей с использованием мастер-ключей. Ключи сессии применяются для шифрования только данной сессии между двумя участниками.</p>
<p>Существует много протоколов, реализующих эту идею, нам будет важен протокол Нидхэма-Шредера, взятый за основу для Kerberos. Опять же, у протокола много вариантов, рассмотрим самый базовый.</p>
<ol type="1">
<li>$A KDC: ID_a || ID_b || N_a $</li>
<li><span class="math inline">$KDC \rightarrow A: E_{K_a} [K_s || ID_b || N_a ] \\ E_{K_b} [K_s || ID_a ]$</span></li>
<li><span class="math inline"><em>A</em> → <em>B</em> : <em>E</em><sub><em>K</em><sub><em>b</em></sub></sub>[<em>K</em><sub><em>s</em></sub>||<em>I</em><em>D</em><sub><em>a</em></sub>]</span></li>
<li><span class="math inline"><em>B</em> → <em>A</em> : <em>E</em><sub><em>K</em><sub><em>s</em></sub></sub>[<em>N</em><sub><em>b</em></sub>]</span></li>
<li><span class="math inline"><em>A</em> → <em>B</em> : <em>E</em><sub><em>K</em><sub><em>s</em></sub></sub>[<em>f</em>(<em>N</em><sub><em>b</em></sub>)]</span></li>
</ol>
<p>Шаг 0: Предполагается, что секретные мастер-ключи <span class="math inline"><em>K</em><sub><em>a</em></sub></span> и <span class="math inline"><em>K</em><sub><em>b</em></sub></span> разделяют соответственно А и KDC, В и KDC. Целью протокола является аутентификация и безопасное распределение ключа сессии <span class="math inline"><em>K</em><sub><em>s</em></sub></span> между А и В</p>
<p>Шаг 1: А запрашивает у KDC ключ сессии для установления защищенного соединения с В. Сообщение включает идентификаторы А и В и уникальный идентификатор (номер) данной транзакции, который обозначен как <span class="math inline"><em>N</em><sub><em>a</em></sub></span> — он должен быть уникальным для каждого запроса — суть идентификатор сессии, не дает ей повториться. Сообщение зашифровано мастер-ключом <span class="math inline"><em>K</em><sub><em>a</em></sub></span>.</p>
<p>Шаг 2: Все и так понятно, <span class="math inline"><em>K</em><sub><em>s</em></sub></span> это ключ сессии, приходит 2 сообщения к стороне A.</p>
<p>Шаг 3: A передает второе сообщение от KDC на B.</p>
<p>Шаг 4 и 5: По сути проверка сессионного ключа: <span class="math inline"><em>N</em><sub><em>b</em></sub></span> случайное число, <span class="math inline"><em>f</em></span> известная функция (например квадрат числа).</p>
<h2 id="kerberos">Kerberos</h2>
<ul>
<li>Протокол аутентификации пользователей на основе доверенной третьей стороны (KDC)</li>
<li>Работает по умолчанию при доменной аутентификации в Windows (можно настроить и для linux с AD контроллером на винде, причем вы не только сможете логиниться с linux машины на сервисы с доменной аутентификацией, но и сами ее проводить, шок да и только), но если живете в чисто linux мире вредил вам это понадобиться, скорее всего ограничитесь x509 сертами.</li>
<li>Использует в качестве транспорта протокол TCP. Ну как бы очевидно.</li>
<li>Сама система работает прозрачно для пользователя, он просто вводит пароль</li>
</ul>
<h3 id="протокол-с-билетом">Протокол с билетом</h3>
<p>Сервер аутентификации Kerberos использует развитие двухуровневой системы аутентификации на основе применения концепции “билетов/мандатов”.</p>
<ol type="1">
<li>$A → B: ID_a || N_a $</li>
<li><span class="math inline"><em>B</em> → <em>K</em><em>D</em><em>C</em> : <em>I</em><em>D</em><sub><em>b</em></sub>||<em>N</em><sub><em>b</em></sub>||<em>E</em><sub><em>K</em><sub><em>b</em></sub></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>N</em><sub><em>a</em></sub>||<em>T</em><sub><em>b</em></sub>]</span></li>
<li><span class="math inline">$KDC → A: E_{K_a} [ID_b || N_a || K_s || T_b ||\\ E_{K_b} [ID_a || K_s || T_b] || N_b ]$</span></li>
<li><span class="math inline"><em>A</em> → <em>B</em> : <em>E</em><sub><em>K</em><sub><em>b</em></sub></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>K</em><sub><em>s</em></sub>||<em>T</em><sub><em>b</em></sub>]||<em>E</em><sub><em>K</em><sub><em>s</em></sub></sub>[<em>N</em><sub><em>b</em></sub>]</span></li>
</ol>
<p>Шаг 0: Предполагается, что секретные мастер-ключи <span class="math inline"><em>K</em><sub><em>a</em></sub></span> и <span class="math inline"><em>K</em><sub><em>b</em></sub></span> разделяют соответственно А и KDC, В и KDC. Целью протокола является аутентификация и безопасное распределение ключа сессии <span class="math inline"><em>K</em><sub><em>s</em></sub></span> между А и В</p>
<p>Шаг 1: А инициализирует аутентификационный обмен созданием идентификатора <span class="math inline"><em>N</em><sub><em>a</em></sub></span> и посылкой его и своего идентификатора к В в незашифрованном виде. Этот <span class="math inline"><em>N</em><sub><em>a</em></sub></span> вернется к А в зашифрованном сообщении, включающем ключ сессии, гарантируя А, что ключ сессии не старый.</p>
<p>Шаг 2: B сообщает KDC, что необходим ключ сессии. Это сообщение к KDС включает идентификатор В и <span class="math inline"><em>N</em><sub><em>b</em></sub></span>. Данный <span class="math inline"><em>N</em><sub><em>b</em></sub></span> вернется к В в зашифрованном сообщении, которое включает ключ сессии, гарантируя B, что ключ сессии не устарел. Последний блок используется для указания KDC, когда заканчивается время жизни <span class="math inline"><em>T</em><sub><em>b</em></sub></span> данного ключа сессии и специфицирует намеченного получателя и содержит <span class="math inline"><em>N</em><sub><em>a</em></sub></span> , полученный от A.</p>
<p>Шаг 3: Да, да это одно сообщение, но можно и два, ничего не изменит. KDC получил <span class="math inline"><em>N</em><sub><em>a</em></sub></span> и <span class="math inline"><em>N</em><sub><em>b</em></sub></span> от А и В и посылает A блок, зашифрованный секретным ключом, который В разделяет с KDC. Блок служит <strong>билетом</strong>, который может быть использован А для последующих аутентификаций. KDC также посылает А блок, зашифрованный секретным ключом, разделяемым А и KDC, что доказывает:</p>
<ul>
<li>В получил начальное сообщение А (<span class="math inline"><em>I</em><em>D</em><sub><em>b</em></sub></span> );</li>
<li>в нем содержится допустимая отметка времени и нет повтора (<span class="math inline"><em>N</em><sub><em>a</em></sub></span>).</li>
</ul>
<p>То есть запомним <strong>билет</strong> это: <span class="math inline"><em>E</em><sub><em>K</em><sub><em>b</em></sub></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>K</em><sub><em>s</em></sub>||<em>T</em><sub><em>b</em></sub>]</span></p>
<p>Шаг 4: А посылает полученный билет В вместе с Nb , зашифрованным ключом сессии. Этот билет обеспечивает В ключом сессии, который тот использует для дешифрования и проверки <span class="math inline"><em>N</em><sub><em>b</em></sub></span> . Тот факт, что <span class="math inline"><em>N</em><sub><em>b</em></sub></span> расшифрован ключом сессии, доказывает, что сообщение пришло от А и не является повтором.</p>
<p>Вот и все, это основная идея, осталось повторить 2 раза.</p>
<p>Данный протокол аутентифицирует А и В и распределяет ключ сессии. Более того, протокол предоставляет в распоряжение А билет, который может использоваться для его последующей аутентификации, исключая необходимость повторных контактов с аутентификационным сервером.</p>
<h3 id="мандаты-на-мандаты-в-kerberos">Мандаты на мандаты в Kerberos</h3>
<p>В протоколе аутентификации Kerberos используются два уровня билетов (мандат на право получения билета и собственно билет) и следовательно имеем 2 сервера:</p>
<ul>
<li>Kerberos — сервера аутентификациираспространения ключей (KDC), который выдает мандат (“главный билет”)</li>
<li>TGS сервер, для выдачи “билетов” (вторичных мандатов) для доступа к сетевым службам.</li>
</ul>
<p>По сути, это разделение функций аутентификации и авторизации.</p>
<p>Процедура получения мандата, за счет использования меток времени вместо случайных номеров, сокращена по сравнению с описанной выше:</p>
<ol type="1">
<li><p>$A KDC: ID_a || ID_{tgs} || T_a $</p></li>
<li><p><span class="math inline"><em>K</em><em>D</em><em>C</em> → <em>A</em> : <em>E</em><sub><em>K</em><sub><em>a</em></sub></sub>[<em>I</em><em>D</em><sub><em>t</em><em>g</em><em>s</em></sub>||<em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub>||<em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>||(<em>δ</em><em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>)||(<em>M</em><sub><em>t</em><em>g</em><em>s</em></sub>)]</span>, где M (<strong>мандат</strong>):</p></li>
</ol>
<p><br /><span class="math display">(<em>M</em><sub><em>t</em><em>g</em><em>s</em></sub>) = <em>E</em><sub><em>K</em><sub><em>t</em><em>g</em><em>s</em></sub></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub>||<em>A</em><em>D</em><sub><em>a</em></sub>||<em>I</em><em>D</em><sub><em>t</em><em>g</em><em>s</em></sub>||<em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>||(<em>δ</em><em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>)]</span><br /></p>
<p>В отличие от описанной выше схемы <span class="math inline"><em>N</em><sub><em>x</em></sub></span> заменены на временные метки <span class="math inline"><em>T</em><sub><em>x</em></sub></span> и срок (<span class="math inline"><em>δ</em><em>T</em><sub><em>x</em></sub></span>) для объекта х. Добавлен параметр сетевой адрес A - <span class="math inline"><em>A</em><em>D</em><sub><em>a</em></sub></span> и В заменен на TGS (соответственно сеансовый ключ стал обозначаться <span class="math inline"><em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub></span> , а общий секрет TGS и KDC — <span class="math inline"><em>K</em><sub><em>t</em><em>g</em><em>s</em></sub></span> ).</p>
<p>Важно, что сообщение (2) шифруется общим секретом A и KDC (разделяемым ключом или его генерацией на основе пароля пользователя), а следующие сообщения шифруются уже полученным сеансовым ключом.</p>
<p>После этого на основе этого мандата можно обращаться в TGS за вторичными мандатами (билетами), на каждый новый сервис (например B). Билет (мандат) на получение сервиса имеет ту же структуру, что и мандат на получение мандата:</p>
<p>(Билет B) = <span class="math inline"><em>E</em><sub><em>K</em><em>b</em></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>K</em><sub><em>s</em> − <em>b</em></sub>||<em>A</em><em>D</em><sub><em>a</em></sub>||<em>I</em><em>D</em><sub><em>b</em></sub>||<em>T</em><sub><em>b</em></sub>||(<em>δ</em><em>T</em><sub><em>b</em></sub>)]</span></p>
<p>Таким образом, пользователь сначала запрашивает мандат на получение мандата (Мандат TGS ) у сервера аутентификации AS.</p>
<p>Этот мандат сохраняется модулем клиента на рабочей станции пользователя. Каждый раз, когда пользователю требуется новый сервис, клиент обращается к TGS и использует этот мандат, чтобы идентифицировать себя.</p>
<p>В ответ TGS выдает билет (вторичный мандат) на получение конкретного сервиса. Клиент сохраняет билет на получение сервиса и использует его для идентификации пользователя сервером всякий раз, когда запрашивается данный сервис.</p>
<p>Теперь рассмотрим как происходит получение итогового мандата (билета):</p>
<ol start="3" type="1">
<li><p><span class="math inline"><em>A</em> → <em>T</em><em>G</em><em>S</em> : <em>I</em><em>D</em><sub><em>b</em></sub>||<em>M</em><sub><em>t</em><em>g</em><em>s</em></sub>||<em>U</em><sub><em>A</em><sub>1</sub></sub></span></p></li>
<li><p><span class="math inline"><em>T</em><em>G</em><em>S</em> → <em>A</em> : <em>E</em><sub><em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub></sub>[<em>K</em><sub><em>a</em> − <em>b</em></sub>||<em>I</em><em>D</em><sub><em>b</em></sub>||<em>T</em><em>s</em><sub>4</sub>||<em>δ</em><em>T</em><em>s</em><sub>2</sub>||<em>M</em><sub><em>b</em></sub>]</span></p></li>
</ol>
<p>Мандат tgs: <span class="math inline"><em>M</em><sub><em>t</em><em>g</em><em>s</em></sub> = <em>E</em><sub><em>K</em><sub><em>t</em><em>g</em><em>s</em></sub></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub>||<em>A</em><em>D</em><sub><em>a</em></sub>||<em>I</em><em>D</em><sub><em>t</em><em>g</em><em>s</em></sub>||<em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>||(<em>δ</em><em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>)]</span></p>
<p>Мандат b: $M_b = E Kv [K_{a-b} || ID_a ||AD_a || ID_b || Ts_4 || Ts_4 ] $</p>
<p>Удостоверение A1: <span class="math inline"><em>U</em><sub><em>A</em><sub>1</sub></sub> = <em>E</em><sub><em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub></sub>[<em>I</em><em>D</em><sub><em>a</em></sub>||<em>A</em><em>D</em><sub><em>a</em></sub>||<em>T</em><em>s</em><sub>3</sub>]</span></p>
<p>A передает удостоверение, включающее идентификатор и адрес пользователя A, а также метку даты-времени. В отличие от мандата, который предполагает многократное использование, удостоверение предлагается использовать только один раз и срок его действия весьма ограничен. TGS может сравнить содержащиеся в удостоверении имя и сетевой адрес с соответствующими элементами мандата и с сетевым адресом поступившего сообщения. Мандат никого не идентифицирует, а обеспечивает способ защищенного распределения ключей. Задачи аутентификации клиента выполняет удостоверение.</p>
<ol start="5" type="1">
<li><p><span class="math inline"><em>A</em> → <em>B</em> : <em>M</em><sub><em>b</em></sub>||<em>U</em><sub><em>A</em><sub>2</sub></sub></span></p></li>
<li><p>$B A: E_{K_{a-b}} [T_{s5} + 1] $</p></li>
</ol>
<p>Удостоверение A2: $ U_{A_2} = E_{K_{a-b}} [ID_a || AD_a || Ts_5 ]$</p>
<p>Если требуется взаимная аутентификация, сервер может ответить так, как предлагается в сообщении (6). Сервер возвращает значение метки даты-времени из удостоверения, увеличенное на 1 и зашифрованное на сеансовом ключе. Система A может расшифровать это сообщение и проверить увеличенное значение метки даты-времени. Поскольку сообщение было зашифровано сеансовым ключом, A убеждается в том, что это сообщение могло быть создано только сервером B и не является воспроизведением старого ответа.</p>
<p>Итого все вместе:</p>
<ul>
<li>Обмен службы аутентификации: получение мандата на получение мандата:
<ul>
<li>$A KDC: ID_a || ID_{tgs} || T_a $</li>
<li><span class="math inline"><em>K</em><em>D</em><em>C</em> → <em>A</em> : <em>E</em><sub><em>K</em><sub><em>a</em></sub></sub>[<em>I</em><em>D</em><sub><em>t</em><em>g</em><em>s</em></sub>||<em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub>||<em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>||(<em>δ</em><em>T</em><sub><em>t</em><em>g</em><em>s</em></sub>)||(<em>M</em><sub><em>t</em><em>g</em><em>s</em></sub>)]</span></li>
</ul></li>
<li>Обмен службы выдачи мандатов: получение мандата (билета) на получение сервиса
<ul>
<li><span class="math inline"><em>A</em> → <em>T</em><em>G</em><em>S</em> : <em>I</em><em>D</em><sub><em>b</em></sub>||<em>M</em><sub><em>t</em><em>g</em><em>s</em></sub>||<em>U</em><sub><em>A</em><sub>1</sub></sub></span></li>
<li><span class="math inline"><em>T</em><em>G</em><em>S</em> → <em>A</em> : <em>E</em><sub><em>K</em><sub><em>a</em> − <em>t</em><em>g</em><em>s</em></sub></sub>[<em>K</em><sub><em>a</em> − <em>b</em></sub>||<em>I</em><em>D</em><sub><em>b</em></sub>||<em>T</em><em>s</em><sub>4</sub>||<em>δ</em><em>T</em><em>s</em><sub>2</sub>||<em>M</em><sub><em>b</em></sub>]</span></li>
</ul></li>
<li>Обмен аутентификации клиента/сервера: получение сервиса
<ul>
<li><span class="math inline"><em>A</em> → <em>B</em> : <em>M</em><sub><em>b</em></sub>||<em>U</em><sub><em>A</em><sub>2</sub></sub></span></li>
<li>$B A: E_{K_{a-b}} [T_{s5} + 1] $</li>
</ul></li>
</ul>
<p>Ура</p>
<p>Заметим, что в Kerberos еще есть понятие области (домена, realm). И возможна также междоменная аутентификация. Сделать это можно разделив секретный ключ с интересующей областью. По факту появится 3-й уровень мандатов.</p>
<h3 id="kerberos-5">Kerberos 5</h3>
<p>Вышесказанное справедливо для Kerberos 4, в 5 версии был сделан ряд улучшений:</p>
<ul>
<li>версия 4 требует применения DES. В версии 5 к шифрованному тексту присоединяется идентификатор типа шифрования, поэтому может использоваться любая схема шифрования. Для ключей шифрования указываются длины, что позволяет использовать одни и те же ключи в различных алгоритмах и указывать варианты одного алгоритма для применения.</li>
<li>сетевые адреса сопровождаются метками типа и длины, что дает возможность использовать любые типы сетевых адресов.</li>
<li>включают явное указание времени начала и окончания действия мандата, что позволяет указывать любые сроки действия мандатов.</li>
<li>оптимизация аутентификации в удаленной области.</li>
</ul>
<p>Конечно поменялся и сам алгоритм, в мандаты добавились области, границы времени, флаги и на этом моменте стоит остановиться и при желании посмотреть слайды.</p>
<h3 id="недостатки">Недостатки</h3>
<p><strong>Версия 4</strong> Kerberos имеет технические недостатки:</p>
<ol type="1">
<li>Двойное шифрование. Обратите внимание (сообщения 2 и 4), мандаты, выдаваемые клиентам, шифруются дважды — один раз секретным ключом сервера назначения, а затем снова, секретным ключом, известным клиенту. Второе шифрование не является необходимым, и поэтому вызывает излишнее потребление вычислительных ресурсов.</li>
<li>DES</li>
<li>Сеансовые ключи. Каждый мандат включает сеансовый ключ, используемый клиентом для шифрования удостоверений, посылаемых службе, связываемой с данным мандатом. Кроме того, этот сеансовый ключ может впоследствии использоваться клиентом и сервером для защиты сообщений, пересылаемых в ходе сеанса. Однако, ввиду того, что один и тот же мандат может использоваться повторно для получения соответствующего сервиса от конкретного сервера, существует риск, что нарушитель может предъявить клиенту или серверу воспроизведенные сообщения старого сеанса. В версии 5 для клиента и сервера существует возможность договориться о сеансовом подключе, который действует только в одном соединении. При новом доступе клиент должен будет использовать новый сеансовый подключ.</li>
</ol>
<p><strong>Версии 4 и 5</strong> Kerberos имеет технические недостатки:</p>
<ol type="1">
<li>Атаки на пароль. Обе версии уязвимы в отношении атак на пароль. Сообщение клиенту от системы AS включает данные, зашифрованные с помощью ключа, построенного на основе пароля клиента. Нарушитель может перехватить это сообщение и попытаться дешифровать его, используя разные пароли. Если в результате попыток расшифрования получится сообщение правильного вида, то нарушитель узнает пароль клиента и сможет впоследствии использовать этот пароль для того, чтобы получать удостоверения аутентификации от Kerberos. Версия 5 предлагает механизм, называемый предварительной аутентификацией, призванный затруднить атаки на пароль, но не исключает их возможность полностью. # 19. Пасивные и активные сетевые атаки (снифинг, спуфинг, MITM, имперсонация).</li>
</ol>
<h2 id="типичная-атака">Типичная атака</h2>
<p>Стадия 1: Внешняя разведка</p>
<p>Стадия 2: Внутренняя разведка</p>
<p>Стадия 3: Атака</p>
<p>Стадия 4: Скрытие следов</p>
<p>Стадия 5: Получение прибыли</p>
<h2 id="пассивные-атаки">Пассивные атаки</h2>
<h3 id="прослушивание-снифинг">Прослушивание (снифинг)</h3>
<p>Перехват трафика может осуществляться:</p>
<ul>
<li>обычным «прослушиванием» сетевого интерфейса. Метод эффективен при использовании в сегменте концентраторов вместо коммутаторов, в противном случае данный метод малоэффективен, поскольку на снифер попадают лишь отдельные кадры;</li>
<li>подключением снифера в разрыв канала;</li>
<li>ответвлением (программным или аппаратным) трафика и направлением его копии на снифер;</li>
<li>через атаку на канальном или сетевом уровне, приводящую к перенаправлению трафика жертвы или всего трафика сегмента на снифер с последующим возвращением трафика в надлежащий адрес.</li>
</ul>
<h4 id="противодействие">Противодействие</h4>
<p>Ограничить область прослушивания в сети Ethernet можно разбиением сети на сегменты с помощью коммутаторов. В этом случае злоумышленник, не прибегая к активным действиям, может перехватить только кадры, получаемые или отправляемые узлами сегмента, к которому он подключен.</p>
<p>Простое прослушивание также не позволяет злоумышленнику модифицировать передаваемые между двумя другими узлами данные. Для решения этих задач злоумышленник должен перейти к активным действиям, чтобы внедрить себя в тракт передачи данных в качестве промежуточного узла.</p>
<p><strong>Единственным надежным способом борьбы с прослушиванием сегмента Ethernet является шифрование данных.</strong></p>
<p>Еще в слайдах описан метод AntiSniff — метод выявления пакетных сниферов основанный на предположении, что программа прослушивания на хосте злоумышленника выполняет обратные DNS-преобразования для IP-адресов подслушанных датаграмм, но это как мне кажется смешно. Однако у AntiSniff есть интересный метод выявление нод в монитор моде, посылом шквала сообщений с несуществующими в текущем сегменте Mac-адресами.</p>
<h3 id="сканирование-сети">Сканирование сети</h3>
<p>Сканирование сети имеет своей целью выявление активных компьютеров сети. Почему то в этом пункте перечислены только ping и traceroute (и внезапно DNS).</p>
<h3 id="сканирование-tcp-портов">Сканирование TCP портов</h3>
<blockquote>
<p>Мне правда нужно про это писать?</p>
</blockquote>
<p>Сканируем TCP порты через хэндшейк.</p>
<p>1.Методы открытого сканирования: непосредственный инициатор однозначно определяется объектом сканирования по IP-адресу запросов.</p>
<p>2.Методы “невидимого” анонимного сканирования. Непосредственный инициатор не определяется объектом сканирования (однозначно определяется только “промежуточный” источник сканирующих запросов), таким образом, гарантируется анонимность инициатора сканирования.</p>
<p>Есть более хитрые способы чем ломиться с хэндшейком.</p>
<p>Сканирование TCP FIN — в этом методе на сканируемый порт посылается сегмент с установленным битом FIN. Хост должен ответить RST-сегментом, если FIN-сегмент адресован закрытому порту.</p>
<p>Сканирование с использованием IP-фрагментации — не является само по себе новым видом сканирования. Данный метод предназначен для усложнения задачи обнаружения факта сканирования и может применяться совместно с упомянутыми ранее методами. Суть его состоит в разбиении TCP SYN- или TCP FIN-зaпpoca на несколько маленьких IP-фрагментов (минимальный размер поля данных в IP-фрагменте 8 байт, следовательно, TCP SYN-запрос, имеющий минимальный размер 20 байт, можно разбить на три фрагмента). Первый фрагмент не содержит флагов, на основании, которых данные пакеты могут быть заблокированы. Тем не менее, если межсетевой экран выполняет дефрагментацию пакетов, то данный метод является неэффективным.</p>
<h3 id="udp-сканирование">UDP сканирование</h3>
<p>Сканирование UDP-сервисов представляет собой достаточно сложную процедуру. Это связано с тем, что протокол UDP является протоколом без установления соединения, а, следовательно, отсутствуют предварительные шаги по созданию виртуального канала.</p>
<p>Для выполнения сканирования UDP-портов можно воспользоваться тем фактом, что большинство хостов в ответ на получение пакет, направленного на закрытый UDP-порт отвечают ICMP пакетом ICMP_PORT_UNREACH. Таким образом, можно обнаружить закрытые порты.</p>
<p>Исключив закрытые порты можно получить список открытых портов. Данный вид сканирования является медленным, так как в соответствии с RFC 1812 хост может значительно ограничить количество ответов содержащих ICMP-сообщения об ошибках.</p>
<h3 id="другие-сканирования">Другие сканирования</h3>
<p>По различному поведению в разных сценариях можно выяснить и ОС системы и версию ПО и тд.</p>
<h2 id="активные-атаки">Активные атаки</h2>
<p>Спуфинг — ситуация, в которой один человек или программа успешно маскируется под другую путём фальсификации данных и позволяет получить незаконные преимущества.</p>
<h3 id="ложный-arp-сервер">Ложный ARP-сервер</h3>
<p>Это называется ARP <strong>спуфинг</strong> — отвечаем на arp запросы, что хост или маршрутизатор это мы, получаем пакеты.</p>
<h3 id="ложный-dns-сервер">Ложный DNS-сервер</h3>
<h4 id="перехват-dns-запроса">Перехват DNS запроса</h4>
<p>Для реализации атаки путем перехвата DNS-запроса злоумышленнику необходимо перехватить запрос, извлечь из него номер UDP-порта хоста отправителя, двухбайтовое значение ID-идентификатора DNS-запроса и искомое имя, а затем послать ложный DNS-ответ на извлеченный из DNS-запроса UDP порт, где в качестве искомого IP-адреса указать настоящий IP-адрес ложного DNS-сервера. Такой вариант атаки в дальнейшем позволит полностью перехватить трафик между атакуемым хостом и сервером и активно воздействовать на него. Необходимым условием осуществления данного варианта атаки является возможность перехвата DNS-запроса, а это возможно только в том случае, если атакующий находится, либо на пути следования запроса к DNS-серверу, либо в одном сегменте с DNS-сервером.</p>
<h4 id="направленный-шторм-ложных-dns-ответов">Направленный шторм ложных DNS-ответов</h4>
<p>Другой вариант осуществления удаленной DNS-атаки - внедрение в сеть Internet ложного сервера путем создания направленного шторма ложных DNS-ответов на атакуемый хост. В этом случае злоумышленник осуществляет постоянную передачу на атакуемый хост заранее подготовленного ложного DNS-ответа от имени настоящего DNS-сервера без предыдущего приема DNS-запроса.</p>
<p>Но IP-адрес отправителя ответа должен совпадать с IP-адресом DNSсервера, а имя в DNS-ответе - с именем в DNS-запросе; кроме того, DNS-ответ следует направить на тот же UDP-порт, с которого было послано сообщение (в данном случае это первая проблема для взломщика), и поле идентификатора запроса (ID) в заголовке DNS-ответа должно содержать то же значение, что и в переданном запросе (а это вторая проблема).</p>
<p>Таким образом, реализация данной удаленной атаки, использующей пробелы в безопасности службы DNS, позволяет из любой точки сети Internet нарушить маршрутизацию между двумя заданными объектами (хостами). Такая атака осуществляется межсегментно по отношению к цели атаки и угрожает безопасности любого хоста Internet, использующего обычную службу DNS.</p>
<h3 id="имперсонация">Имперсонация</h3>
<p>Предположим, что узел А обменивается IP-датаграммами с узлом В, при этом узлы идентифицируют друг друга по IP-адресам, указываемым в датаграммах. Предположим далее, что узел В имеет особые привилегии при взаимодействии с А: то есть А предоставляет В некоторый сервис, недоступный для других хостов Internet. Злоумышленник на узле Х, желающий получить такой сервис, должен имитировать узел В — такие действия называются имперсонацией узла В узлом Х.</p>
<p>Пусть узел находится в сети, не имеющей никакого отношения к узлам А и В и не лежащей между ними (А и В могут находиться как в одной, так и в разных сетях). Легко видеть, что имперсонация UDP-сообщений без обратной связи является тривиальной - злоумышленник должен только сфабриковать датаграмму, адресованную от узла В узлу А, и отправить ее по назначению.</p>
<p>Схема атаки с имперсонацией TCP-соединения без обратной связи</p>
<ol type="1">
<li>Злоумышленник выводит из строя узел В.</li>
<li>Злоумышленник делает несколько пробных попыток установить соединения с узлом А с целью получить от А последовательность значений ISN(A). Сразу после поступления SYN-сегмента от А злоумышленник разрывает наполовину установленное соединение посылкой сегмента с флагом RST. Проанализировав полученные значения ISN(A), злоумышленник определяет закон формирования этих значений.</li>
<li>Злоумышленник отправляет в А SYN сегмент от имени В.</li>
<li>Узел А отвечает узлу В свои SYN сегментом, подтверждающим получение SYN-сегмента от В, и указывает значение ISN(A) для этого соединения. Злоумышленник не видит этого сегмента.</li>
<li>На основе ранее полученных данных злоумышленник предсказывает значение ISN(A) и отправляет в А сегмент от имени В, содержащий подтверждение ISN(A)+1 и данные для прикладного процесса. Получив этот сегмент, узел А считает соединение с В установленным и передает поступившие данные прикладному процессу. Цель атаки достигнута. Данные могут быть, например, командой, которую узел А выполняет, потому что она поступила от доверенного узла В.</li>
</ol>
<h3 id="mitm">MITM</h3>
<p>Про него в слайдах не говорится, но когда мы пропускаем через себя чужой трафик и выступай своего рода проксей (тайно для участников) это и есть MITM. Чтобы всех этих проблем не было используйте TLS современных версий с рекомендациями от Mozilla и не забывайте обновлять ОС, Nginx и openssl). <strong>20. Коммуникационные протоколы. Ошибки, возникающие при передаче сообщений. Задача надежного обмена сообщениями. Симметричные протокол скользящего (раздвижного) окна: устройство протокола и обоснование его корректности. Протокол альтернирующего бита.[1, стр. 83-94]</strong></p>
<h3 id="короткая-версия-см-подробную-версию-ниже"><strong>Короткая версия</strong> (см подробную версию ниже)</h3>
<p>Основное назначение коммуникационного протокола - передача данных, то есть получение информации от одного узла сети и доставка ее по назначению другому узлу сети. При передаче данных возможны ошибки (потеря, дублирование, искажение). Эти ошибки нужно обнаруживать и исправлять. Для этого в протоколе ведется учет состояния информации. Для использования состояния информации применяется управление соединением - инициализация и аннулирование состояния информации. Инициализация называется установлением соединения, а аннулирование - завершением соединения.</p>
<p><strong>Симметричный протокол раздвижного окна</strong> (коммуникационный протокол)</p>
<p>Предназначен для для обмена данными между двумя узлами сети, которые имеют прямое соединение (например, кабель). Асинхронный протокол, относящийся к уровню управления передачей данных (второй уровень модели OSI). Не будет рассматриваться управление соединением для этого протокола. Предполагается, что физическое соединение обычно функционирует непрерывно в течение долгого времени, а не устанавливается и завершается периодически. При физическом соединении сообщения не могут обгонять друг друга и дублироваться, поэтому рассматриваются только ошибки потери сообщения. Содержание сообщения, передаваемого по каналу связи может быть повреждено. Предполагается, что процесс-получатель способен обнаруживать искажения сообщений, например, при помощи счетчиков четности или кодирования с исправлением ошибок.</p>
<p>Постановка задачи:</p>
<p>Процессам <span class="math inline"><em>p</em></span> и <span class="math inline"><em>q</em></span> нужно передать данные <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub></span> и <span class="math inline"><em>i</em><em>n</em><sub><em>q</em></sub></span> друг другу и записать полученные данные в <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub></span> и <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub></span>. В канале связи возможны помехи, приводящие к потери сообщений.</p>
<p>Общая идея алгоритма:</p>
<ul>
<li>Входные данные одного процесса служат для подтверждения получения сообщений от другого процесса.</li>
<li>Сообщение - пакеты - наборы вида <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span>, где <span class="math inline"><em>w</em></span> - информационное слово, <span class="math inline"><em>i</em></span> - порядковый номер пакета</li>
<li>Пакет <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span>, отправленный процессом <span class="math inline"><em>p</em></span>, передает слово <span class="math inline"><em>w</em> = <em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em>]</span> процессу <span class="math inline"><em>q</em></span> и подтверждает успешное получение ряда пакетов, отправленных процессом <span class="math inline"><em>q</em></span>.</li>
<li>Процесс <span class="math inline"><em>p</em></span> может опережать процесс <span class="math inline"><em>q</em></span> на некоторое заданное число пакетов <span class="math inline"><em>l</em><sub><em>p</em></sub></span>, если мы постановим, что отправление пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span> процессом <span class="math inline"><em>p</em></span> подтверждает получение слов с номерами <span class="math inline">0, 1, ..., (<em>i</em> − <em>l</em><sub><em>p</em></sub>)</span> от процесса <span class="math inline"><em>q</em></span>.</li>
<li>Константы опережения <span class="math inline"><em>l</em><sub><em>p</em></sub></span> и <span class="math inline"><em>l</em><sub><em>q</em></sub></span> известны процессам <span class="math inline"><em>p</em></span> и <span class="math inline"><em>q</em></span>.</li>
</ul>
<p>Таким образом в протоколе соблюдаются два принципа:</p>
<ul>
<li>Процесс <span class="math inline"><em>p</em></span> может отправить слово <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em>]</span> только после того, как будут занесены в память все слова, начиная с <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0]</span> и заканчивая <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em> − <em>l</em><sub><em>p</em></sub>]</span> , то есть когда будет выполняться неравенство <span class="math inline"><em>i</em> &lt; <em>s</em><sub><em>p</em></sub> + <em>l</em><sub><em>p</em></sub></span>, где <span class="math inline"><em>s</em><sub><em>p</em></sub> = <em>m</em><em>i</em><em>n</em><em>j</em> : <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>j</em>] = <em>u</em><em>d</em><em>e</em><em>f</em></span></li>
<li>Как только <span class="math inline"><em>p</em></span> получает пакет <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span> отпадает необходимость в повторной передаче слов, начиная с <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub>[0]</span> и оканчивая <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em> − <em>l</em><sub><em>q</em></sub>]</span>.</li>
</ul>
<p>Алгоритм состоит из следующих трех действий:</p>
<ul>
<li><p>Действие <span class="math inline"><em>S</em><sub><em>p</em></sub></span> осуществляет отправление <span class="math inline"><em>i</em></span>-го входного слова процесса <span class="math inline"><em>p</em></span>.</p></li>
<li><p>Действие <span class="math inline"><em>R</em><sub><em>p</em></sub></span> осуществляет прием слова процессом <span class="math inline"><em>p</em></span>.</p></li>
<li><p>Действие <span class="math inline"><em>L</em><sub><em>p</em></sub></span> моделирует потерю пакета, адресатом которого является процесс <span class="math inline"><em>p</em></span>.</p></li>
</ul>
<p><strong>Требования корректности.</strong> Нужно доказать, что протокол работает правильно, т.е. каждое слово из входного массива <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub></span> процесса p будет рано или поздно записано в выходной массив outq процесса <span class="math inline"><em>q</em></span> , и наоборот. Более строго это выражается двумя требованиями.</p>
<ol type="1">
<li>Безопасная доставка сообщений. В каждой достижимой конфигурации протокола выполняются соотношения <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1] = <em>i</em><em>n</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1]</span> и <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1] = <em>i</em><em>n</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1]</span> .</li>
<li>Неизбежная доставка сообщений. Для каждого целого числа <span class="math inline"><em>k</em> ≥ 0</span> , в ходе выполнения протокола будет достигнута конфигурация, в которой <span class="math inline"><em>s</em><sub><em>p</em></sub> ≥ <em>k</em></span>, <span class="math inline"><em>s</em><sub><em>q</em></sub> ≥ <em>k</em></span> .</li>
</ol>
<p>Симметричный протокол удовлетворяет этим требованиям по теоремам.</p>
<p><strong>Теорема</strong>.</p>
<p>Симметричный протокол раздвижного окна удовлетворяет требованию безопасной доставки сообщений, т.е. в каждой достижимой конфигурации протокола выполняются соотношения <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1] = <em>i</em><em>n</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1]</span> и <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1] = <em>i</em><em>n</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1]</span></p>
<p><strong>Теорема</strong></p>
<p>Симметричный протокол раздвижного окна удовлетворяет требованию неизбежной доставки сообщений, т.е. для каждого целого числа k ≥ 0 , в ходе любого выполнения протокола будет достигнуты конфигурация, в которой spk, sqk.</p>
<p><strong>Протокол альтернирующего бита</strong></p>
<p>Особо интересный вариант протокола раздвижного окна возникает в том случае, когда <span class="math inline"><em>l</em><sub><em>p</em></sub> = 1</span> и <span class="math inline"><em>l</em><sub><em>q</em></sub> = 0</span> (или наоборот). В качестве начальных значений переменных <span class="math inline"><em>a</em><sub><em>p</em></sub></span> и <span class="math inline"><em>a</em><sub><em>q</em></sub></span> в этом случае выбирается не 0, а числа <span class="math inline"> − <em>l</em><sub><em>p</em></sub></span> и <span class="math inline"> − <em>l</em><sub><em>q</em></sub></span> . Такой вариант алгоритма раздвижного окна называется протоколом чередующихся (альтернирующих) битов; он предназначен для односторонней передачи данных.</p>
<h3 id="подробная-версия"><strong>Подробная версия</strong></h3>
<p>Основное назначение коммуникационного протокола - передача данных, то есть получение информации от одного узла сети и доставка ее по назначению другому узлу сети. При передаче данных возможны ошибки (потеря, дублирование, искажение). Эти ошибки нужно обнаруживать и исправлять. Для этого в протоколе ведется учет состояния информации. Для использования состояния информации применяется управление соединением - инициализация и аннулирование состояния информации. Инициализация называется установлением соединения, а аннулирование - завершением соединения.</p>
<p><strong>Симметричный протокол раздвижного окна</strong> (коммуникационный протокол)</p>
<p>Предназначен для для обмена данными между двумя узлами сети, которые имеют прямое соединение (например, кабель). Асинхронный протокол, относящийся к уровню управления передачей данных (второй уровень модели OSI). Не будет рассматриваться управление соединением для этого протокола. Предполагается, что физическое соединение обычно функционирует непрерывно в течение долгого времени, а не устанавливается и завершается периодически. При физическом соединении сообщения не могут обгонять друг друга и дублироваться, поэтому рассматриваются только ошибки потери сообщения. Содержание сообщения, передаваемого по каналу связи может быть повреждено. Предполагается, что процесс-получатель способен обнаруживать искажения сообщений, например, при помощи счетчиков четности или кодирования с исправлением ошибок.</p>
<p>Постановка задачи:</p>
<p>Процессам <span class="math inline"><em>p</em></span> и <span class="math inline"><em>q</em></span> нужно передать данные <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub></span> и <span class="math inline"><em>i</em><em>n</em><sub><em>q</em></sub></span> друг другу и записать полученные данные в <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub></span> и <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub></span>. В канале связи возможны помехи, приводящие к потери сообщений.</p>
<p>Общая идея алгоритма:</p>
<ul>
<li>Входные данные одного процесса служат для подтверждения получения сообщений от другого процесса.</li>
<li>Сообщение - пакеты - наборы вида <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span>, где <span class="math inline"><em>w</em></span> - информационное слово, <span class="math inline"><em>i</em></span> - порядковый номер пакета</li>
<li>Пакет <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span>, отправленный процессом <span class="math inline"><em>p</em></span>, передает слово <span class="math inline"><em>w</em> = <em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em>]</span> процессу <span class="math inline"><em>q</em></span> и подтверждает успешное получение ряда пакетов, отправленных процессом <span class="math inline"><em>q</em></span>.</li>
<li>Процесс <span class="math inline"><em>p</em></span> может опережать процесс <span class="math inline"><em>q</em></span> на некоторое заданное число пакетов <span class="math inline"><em>l</em><sub><em>p</em></sub></span>, если мы постановим, что отправление пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span> процессом <span class="math inline"><em>p</em></span> подтверждает получение слов с номерами <span class="math inline">0, 1, ..., (<em>i</em> − <em>l</em><sub><em>p</em></sub>)</span> от процесса <span class="math inline"><em>q</em></span>.</li>
<li>Константы опережения <span class="math inline"><em>l</em><sub><em>p</em></sub></span> и <span class="math inline"><em>l</em><sub><em>q</em></sub></span> известны процессам <span class="math inline"><em>p</em></span> и <span class="math inline"><em>q</em></span>.</li>
</ul>
<p>Таким образом в протоколе соблюдаются два принципа:</p>
<ul>
<li>Процесс <span class="math inline"><em>p</em></span> может отправить слово <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em>]</span> только после того, как будут занесены в память все слова, начиная с <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0]</span> и заканчивая <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em> − <em>l</em><sub><em>p</em></sub>]</span> , то есть когда будет выполняться неравенство <span class="math inline"><em>i</em> &lt; <em>s</em><sub><em>p</em></sub> + <em>l</em><sub><em>p</em></sub></span>, где <span class="math inline"><em>s</em><sub><em>p</em></sub> = <em>m</em><em>i</em><em>n</em><em>j</em> : <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>j</em>] = <em>u</em><em>d</em><em>e</em><em>f</em></span></li>
<li>Как только <span class="math inline"><em>p</em></span> получает пакет <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em>&gt;</span> отпадает необходимость в повторной передаче слов, начиная с <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub>[0]</span> и оканчивая <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em> − <em>l</em><sub><em>q</em></sub>]</span>.</li>
</ul>
<p>Действия алгоритма:</p>
<figure>
<img src="https://lh3.googleusercontent.com/Sjvh8fyvl8_xyqwVXIV4zzlOuyCHODxYHe3D5Wae17qsZ9HBiW9_bzf_2Xu9fZbgohsg1zmw5be9HQf1UtNyCRLT9mHroVjrgkSN5kt0z0f-RvJH5UmcrhdD67VGWnjgCCaFHgRr" alt="" /><figcaption>img</figcaption>
</figure>
<p>Действие <span class="math inline"><em>S</em><sub><em>p</em></sub></span> осуществляет отправление <span class="math inline"><em>i</em></span>-го входного слова процесса <span class="math inline"><em>p</em></span>.</p>
<p>Действие <span class="math inline"><em>R</em><sub><em>p</em></sub></span> осуществляет прием слова процессом <span class="math inline"><em>p</em></span>.</p>
<p>Действие <span class="math inline"><em>L</em><sub><em>p</em></sub></span> моделирует потерю пакета, адресатом которого является процесс <span class="math inline"><em>p</em></span>.</p>
<p><span class="math inline"><em>S</em><sub><em>p</em></sub></span>:</p>
<p>Данные для отправления выбираются из раздвижного окна <span class="math inline"><em>a</em><sub><em>p</em></sub> &lt; <em>i</em> &lt; <em>s</em><sub><em>p</em></sub> + <em>l</em><sub><em>p</em></sub></span>. Предполагается, что <span class="math inline"><em>a</em><sub><em>p</em></sub></span> наименьший номер в массиве <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub></span>, получение которого еще не подтвердил процесс <span class="math inline"><em>q</em></span>, <span class="math inline"><em>s</em><sub><em>p</em></sub></span> - наименьший номер того элемента в массиве <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub></span>, в который еще не записаны полученные данные.</p>
<p><span class="math inline"><em>R</em><sub><em>p</em></sub></span>:</p>
<p>Получив сообщение процесс в начале проверяет не было ли идентичное сообщение получено ранее (возникает повторное получение сообщения). Если это не так, то слово, содержащееся в сообщении, записывается в выходной массив, при этом значения переменных <span class="math inline"><em>a</em><sub><em>p</em></sub></span> и <span class="math inline"><em>s</em><sub><em>p</em></sub></span> изменяются.</p>
<p><span class="math inline"><em>L</em><sub><em>p</em></sub></span>:</p>
<p>Моделирование потери сообщения проводится путем удаления произвольного сообщения из множества сообщений <span class="math inline"><em>Q</em><sub><em>p</em></sub></span> , пребывающих на этапе пересылки от процесса <span class="math inline"><em>q</em></span> к процессу <span class="math inline"><em>p</em></span>.</p>
<p>Что плохого может случиться?</p>
<ol type="1">
<li>Створки окон обоих процессов могут “захлопнуться”, и процессы будут обречены (безуспешно) ожидать сообщений друг от друга (блокировка , deadlock );</li>
<li>Створки окон могут “застыть”, и процессы будут обречены передавать одни и те же сообщения (активный тупик , livelock );</li>
<li>Данные могут быть потеряны при передаче, и процесс не заметит этого;</li>
<li>Процесс может “забыть” передать данные;</li>
<li>Створки окна могут раздвигаться, отдаляясь друг от друга неограниченно широко.</li>
</ol>
<p><strong>Требования корректности.</strong> Нужно доказать, что протокол работает правильно, т.е. каждое слово из входного массива <span class="math inline"><em>i</em><em>n</em><sub><em>p</em></sub></span> процесса p будет рано или поздно записано в выходной массив outq процесса <span class="math inline"><em>q</em></span> , и наоборот. Более строго это выражается двумя требованиями.</p>
<ol type="1">
<li>Безопасная доставка сообщений. В каждой достижимой конфигурации протокола выполняются соотношения <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1] = <em>i</em><em>n</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1]</span> и <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1] = <em>i</em><em>n</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1]</span> .</li>
<li>Неизбежная доставка сообщений. Для каждого целого числа <span class="math inline"><em>k</em> ≥ 0</span> , в ходе выполнения протокола будет достигнута конфигурация, в которой <span class="math inline"><em>s</em><sub><em>p</em></sub> ≥ <em>k</em></span>, <span class="math inline"><em>s</em><sub><em>q</em></sub> ≥ <em>k</em></span> .</li>
</ol>
<p>Многие свойства распределенных алгоритмов, нуждающиеся в проверке, относятся к одному из двух типов: условие безопасности и условие живости.</p>
<p>Условие безопасности требует, чтобы каждая достижимая конфигурация в любом выполнении системы обладала определенным свойством. Условие живости требует, чтобы хотя бы одна достижимая конфигурация в любом выполнении системы обладала определенным свойством.</p>
<p>Ограничения накладываемые, чтобы протокол обладал свойством живости:</p>
<ul>
<li>В качестве <span class="math inline"><em>l</em><sub><em>p</em></sub></span> и <span class="math inline"><em>l</em><sub><em>q</em></sub></span> можно взять любые неотрицательные константы, удовлетворяющие неравенству <span class="math inline"><em>l</em><sub><em>p</em></sub> + <em>l</em><sub><em>q</em></sub> &gt; 0</span> .</li>
<li>Выдвигаются два требования справедливости:
<ol type="1">
<li>F1. Если бесконечно часто возникает возможность отправки пакета, то этот пакет будет отправляться бесконечно часто.</li>
<li>F2. Если один и тот же пакет отправляется бесконечно часто, то и принимается он также бесконечно часто.</li>
</ol></li>
</ul>
<p><strong>Теорема</strong>.</p>
<p>Симметричный протокол раздвижного окна удовлетворяет требованию безопасной доставки сообщений, т.е. в каждой достижимой конфигурации протокола выполняются соотношения <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1] = <em>i</em><em>n</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1]</span> и <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1] = <em>i</em><em>n</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1]</span></p>
<p>Доказательство:</p>
<p>Следует из Теоремы 3.2 (о свойстве инвариантов) и Теоремы 3.4. Из условий</p>
<p>(0p): <span class="math inline">∀<em>i</em> &lt; <em>s</em><sub><em>p</em></sub> : <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em>] ≠ <em>u</em><em>d</em><em>e</em><em>f</em></span> и</p>
<p>(2p): <span class="math inline">∀<em>i</em> : <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em>] ≠ <em>u</em><em>d</em><em>e</em><em>f</em> =  &gt; <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em>] = <em>i</em><em>n</em><sub><em>q</em></sub>[<em>i</em>] ∧ (<em>a</em><sub><em>p</em></sub> &gt; <em>i</em> − <em>l</em><sub><em>q</em></sub>)</span> следует выполнимость равенства <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1] = <em>i</em><em>n</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>p</em></sub> − 1]</span> , а из условий (0q) и (2q) следует выполнимость равенства <span class="math inline"><em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1] = <em>i</em><em>n</em><sub><em>p</em></sub>[0..<em>s</em><sub><em>q</em></sub> − 1]</span> .</p>
<p>Вспомогательные теоремы (без доказательства)</p>
<p>Теорема 3.2. Если <span class="math inline"><em>Q</em></span> является инвариантом системы переходов <span class="math inline"><em>S</em></span> , и для каждой конфигурации <span class="math inline"><em>γ</em> ∈ <em>C</em></span> выполняется <span class="math inline"><em>Q</em>(<em>γ</em>) =  &gt; <em>P</em>(<em>γ</em>)</span>, то для любого выполнения системы <span class="math inline"><em>S</em></span> утверждение <span class="math inline"><em>P</em></span> будет истинно в каждой конфигурации выполнения.</p>
<p>Теорема 3.4. Утверждение P является инвариантом алгоритма раздвижного окна.</p>
<p><br /><span class="math display"><em>P</em> ≡ ∀<em>i</em> &lt; <em>s</em><sub><em>p</em></sub> : <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em>] ≠ <em>u</em><em>d</em><em>e</em><em>f</em></span><br /></p>
<p><br /><span class="math display"> ∧ ∀<em>i</em> &lt; <em>s</em><sub><em>q</em></sub> : <em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[<em>i</em>] ≠ <em>u</em><em>d</em><em>e</em><em>f</em></span><br /></p>
<p><br /><span class="math display"> ∧ ∀<em>i</em> :  &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em> &gt;  ∈ <em>Q</em><sub><em>p</em></sub> =  &gt; <em>w</em> = <em>i</em><em>n</em><sub><em>q</em></sub>[<em>i</em>] ∧ (<em>i</em> &lt; <em>s</em><sub><em>q</em></sub> + <em>l</em><sub><em>q</em></sub>)</span><br /></p>
<p><br /><span class="math display"> ∧ ∀<em>i</em> :  &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>w</em>, <em>i</em> &gt;  ∈ <em>Q</em><sub><em>q</em></sub> =  &gt; <em>w</em> = <em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em>] ∧ (<em>i</em> &lt; <em>s</em><sub><em>p</em></sub> + <em>l</em><sub><em>p</em></sub>)</span><br /></p>
<p><br /><span class="math display"> ∧ ∀<em>i</em> : <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em>] ≠ <em>u</em><em>d</em><em>e</em><em>f</em> =  &gt; <em>o</em><em>u</em><em>t</em><sub><em>p</em></sub>[<em>i</em>] = <em>i</em><em>n</em><sub><em>q</em></sub>[<em>i</em>] ∧ (<em>a</em><sub><em>p</em></sub> &gt; <em>i</em> − <em>l</em><sub><em>q</em></sub>)</span><br /></p>
<p><br /><span class="math display"> ∧ ∀<em>i</em> : <em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[<em>i</em>] ≠ <em>u</em><em>d</em><em>e</em><em>f</em> =  &gt; <em>o</em><em>u</em><em>t</em><sub><em>q</em></sub>[<em>i</em>] = <em>i</em><em>n</em><sub><em>p</em></sub>[<em>i</em>] ∧ (<em>a</em><sub><em>q</em></sub> &gt; <em>i</em> − <em>l</em><sub><em>p</em></sub>)</span><br /></p>
<p><br /><span class="math display"><em>a</em><sub><em>p</em></sub> ≤ <em>s</em><sub><em>q</em></sub></span><br /></p>
<p><br /><span class="math display"><em>a</em><sub><em>q</em></sub> ≤ <em>s</em><sub><em>p</em></sub></span><br /></p>
<p><strong>Теорема</strong></p>
<p>Симметричный протокол раздвижного окна удовлетворяет требованию неизбежной доставки сообщений, т.е. для каждого целого числа k ≥ 0 , в ходе любого выполнения протокола будет достигнуты конфигурация, в которой spk, sqk.</p>
<p>Доказательство:</p>
<p>Предположим, что есть вычисление C , в котором значения хотя бы одной из переменных <span class="math inline"><em>s</em><sub><em>p</em></sub></span> и <span class="math inline"><em>s</em><sub><em>q</em></sub></span> увеличиваются лишь конечное число раз. Тогда, согласно неравенству Леммы 3.1. <span class="math inline"><em>s</em><sub><em>p</em></sub> − <em>l</em><sub><em>q</em></sub> ≤ <em>s</em><sub><em>q</em></sub> ≤ <em>s</em><sub><em>p</em></sub> + <em>l</em><sub><em>p</em></sub></span> , значение другой переменной также не может увеличиваться бесконечно часто. Пусть <span class="math inline"><em>σ</em><sub><em>p</em></sub></span> и <span class="math inline"><em>σ</em><sub><em>q</em></sub></span> - наибольшие значения переменных <span class="math inline"><em>s</em><sub><em>p</em></sub></span> и <span class="math inline"><em>s</em><sub><em>q</em></sub></span> . Тогда, cогласно Лемме 3.2., либо отправление пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>i</em><em>n</em><sub><em>p</em></sub>[<em>σ</em><sub><em>q</em></sub>], <em>σ</em><sub><em>q</em></sub>&gt;</span> процессом <span class="math inline"><em>p</em></span> , либо отправление пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>i</em><em>n</em><sub><em>q</em></sub>[<em>σ</em><sub><em>p</em></sub>], <em>σ</em><sub><em>p</em></sub>&gt;</span> процессом <span class="math inline"><em>q</em></span> допустимо бесконечно долго после того, как переменные <span class="math inline"><em>s</em><sub><em>p</em></sub></span> , <span class="math inline"><em>s</em><sub><em>q</em></sub></span> , <span class="math inline"><em>a</em><sub><em>p</em></sub></span> и <span class="math inline"><em>a</em><sub><em>q</em></sub></span> примут свои окончательные значения. Тогда, cогласно допущению F1, один из этих пакетов (например, <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>i</em><em>n</em><sub><em>q</em></sub>[<em>σ</em><sub><em>p</em></sub>], <em>σ</em><sub><em>p</em></sub>&gt;</span> отправляется бесконечно часто, и, согласно допущению F2, он должен приниматься также бесконечно часто. Получение процессом <span class="math inline"><em>p</em></span> пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>i</em><em>n</em><sub><em>q</em></sub>[<em>σ</em><sub><em>p</em></sub>], <em>σ</em><sub><em>p</em></sub>&gt;</span> приводит к тому, что значение <span class="math inline"><em>s</em><sub><em>p</em></sub></span> (равное <span class="math inline"><em>σ</em><sub><em>p</em></sub></span> ) увеличивается. Это противоречит выбору значения <span class="math inline"><em>σ</em><sub><em>p</em></sub></span> .</p>
<p>Леммы будут приведены без доказательств</p>
<p>Лемма 3.1. В любой достижимой конфигурации выполняются неравенства <span class="math inline"><em>s</em><sub><em>p</em></sub> − <em>l</em><sub><em>q</em></sub> ≤ <em>a</em><sub><em>p</em></sub> ≤ <em>s</em><sub><em>q</em></sub> ≤ <em>a</em><sub><em>q</em></sub> + <em>l</em><sub><em>p</em></sub> ≤ <em>s</em><sub><em>p</em></sub> + <em>l</em><sub><em>p</em></sub></span>.(Створки окон процессов <span class="math inline"><em>p</em></span> и <span class="math inline"><em>q</em></span> “разъезжаются” не слишком далеко друг от друга.)</p>
<p>Лемма 3.2. В любой достижимой конфигурации допустимо хотя бы одно из двух действий: отправление пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>i</em><em>n</em><sub><em>p</em></sub>[<em>s</em><sub><em>q</em></sub>], <em>s</em><sub><em>q</em></sub>&gt;</span> процессом <span class="math inline"><em>p</em></span> или отправление пакета <span class="math inline"> &lt; <em>p</em><em>a</em><em>c</em><em>k</em>, <em>i</em><em>n</em><sub><em>q</em></sub>[<em>s</em><sub><em>p</em></sub>], <em>s</em><sub><em>p</em></sub>&gt;</span> процессом <span class="math inline"><em>q</em></span> .</p>
<p><strong>Протокол альтернирующего бита</strong></p>
<p>Особо интересный вариант протокола раздвижного окна возникает в том случае, когда <span class="math inline"><em>l</em><sub><em>p</em></sub> = 1</span> и <span class="math inline"><em>l</em><sub><em>q</em></sub> = 0</span> (или наоборот). В качестве начальных значений переменных <span class="math inline"><em>a</em><sub><em>p</em></sub></span> и <span class="math inline"><em>a</em><sub><em>q</em></sub></span> в этом случае выбирается не 0, а числа <span class="math inline"> − <em>l</em><sub><em>p</em></sub></span> и <span class="math inline"> − <em>l</em><sub><em>q</em></sub></span> . Такой вариант алгоритма раздвижного окна называется протоколом чередующихся (альтернирующих) битов; он предназначен для односторонней передачи данных.</p>
<h2 id="общие-принципы-дедуктивной-верификации-программ.-операционная-семантика-императивных-программ.-формальная-постановка-задачи-верификации-программ.-логика-хоара-правила-вывода-и-свойства.-автоматизация-проверки-правильности-программ.">22. Общие принципы дедуктивной верификации программ. Операционная семантика императивных программ. Формальная постановка задачи верификации программ. Логика Хоара: правила вывода и свойства. Автоматизация проверки правильности программ.</h2>
<p>Общие принципы дедуктивной верификации:</p>
<ol type="1">
<li>Программа $$ вычисляет отношение <span class="math inline"><em>R</em><sub><em>π</em></sub></span> между данными, подаваемыми на вход и получаемыми на выходе</li>
<li>Текст программы <span class="math inline"><em>π</em></span> — это формальное описание отношения $R_{} $</li>
<li>Спецификация программы <span class="math inline"><em>Φ</em></span> — это формальное описание отношения <span class="math inline"><em>R</em><sub><em>Φ</em></sub></span> между данными программы
<ul>
<li>Отношение, описываемое спецификацией, — это требования, которым должно удовлетворять отношение, вычисляемое программой</li>
</ul></li>
<li>Формальная верификация программы <span class="math inline"><em>π</em></span> относительно спецификации <span class="math inline"><em>Φ</em></span> — это строгое доказательство того, что программа $$ удовлетворяет требованиям <span class="math inline"><em>Φ</em></span>, то есть доказательство включения <span class="math inline">$R_{\pi} \sube R_Ф$</span></li>
</ol>
<p>Чтобы уметь формально верифицировать программы, нужно:</p>
<ol type="1">
<li><p>Строго описать, какие записи мы считаем программами (синтаксис программ) и как программы преобразуют входные данные в выходные (семантику программ)</p></li>
<li><p>Выбрать формальный язык описания требований к программам</p></li>
<li><p>Предложить метод проверки того, удовлетворяет ли заданная программа предъявленным к ней требованиям</p></li>
</ol>
<p>Синтаксис императивных программ (сигнатуры <span class="math inline"><em>σ</em></span>) задаётся следующей формой Бэкуса-Наура:</p>
<p>$$ ::= instr | instr; <span class="math inline"><em>π</em></span></p>
<p>instr ::= <span class="math inline">$\empty$</span> | x:=t | <strong>if</strong> <span class="math inline"><em>C</em></span> <strong>then $$</strong> <strong>else <span class="math inline"><em>π</em></span></strong> <strong>fi</strong> | <strong>while <span class="math inline"><em>C</em></span></strong> <strong>do <span class="math inline"><em>π</em></span></strong> <strong>od</strong></p>
<p>Где</p>
<ul>
<li><p>$$ — программа</p></li>
<li><p>instr — инструкция (пустая инструкция, присваивание, ветвление, цикл)</p></li>
<li><p>x — переменная</p></li>
<li><p>t—терм</p></li>
<li><p><span class="math inline"><em>C</em></span> — условие: формула, не содержащая кванторов</p></li>
</ul>
<p><strong>Операционная семантика</strong>:</p>
<ul>
<li><p>Вычисление программы — это последовательное изменение состояния вычисления</p></li>
<li><p>Программой задаётся отношение переходов, описывающее, какое состояние вычисления будет получено следующим из произвольного текущего состояния</p></li>
<li><p>Значение программы — это функция преобразования входных данных в выходные, определяемая на основе транзитивного замыкания отношения переходов</p></li>
<li><p>Хорошо подходит для описания значения императивных программ</p></li>
</ul>
<p><strong>Операционная семантика для императивных программ</strong>:</p>
<p><strong>Состояние управления</strong> — это произвольная программа</p>
<p><strong>Состояние данных (оценка переменных)</strong> — это подстановка, отображающая каждую переменную программы в терм, не содержащий переменных</p>
<p><strong>Состояние вычисления</strong> — это пара <span class="math inline">⟨<em>π</em>, <em>θ</em>⟩</span>, где <span class="math inline"><em>π</em></span> — состояние управления, а <span class="math inline"><em>θ</em></span> — состояние данных</p>
<p><strong>Отношение переходов</strong> <span class="math inline">→</span> на множестве состояний вычисления для программы <span class="math inline"><em>π</em></span> в интерпретации <span class="math inline"><em>I</em></span> определяется так:</p>
<ul>
<li><p>если <span class="math inline">⟨</span>x:= t, <span class="math inline"><em>θ</em>⟩</span> <span class="math inline">→</span> <span class="math inline">$\langle \empty, \{x/t\}\theta \rangle$</span></p></li>
<li><p>если <span class="math inline"><em>I</em> ⊨ <em>C</em><em>θ</em></span> , то: <span class="math inline">⟨</span><strong>if</strong> <span class="math inline"><em>C</em></span> <strong>then</strong> <span class="math inline"><em>π</em><sub>1</sub></span> <strong>else</strong> <span class="math inline"><em>π</em><sub>2</sub></span>, <span class="math inline"><em>θ</em>⟩</span> <span class="math inline">→</span> <span class="math inline">⟨<em>π</em><sub>1</sub>, <em>θ</em>⟩</span></p></li>
<li><p>если <span class="math inline"><em>I</em> ⊭ <em>C</em><em>θ</em></span> , то: <span class="math inline">⟨</span><strong>if</strong> <span class="math inline"><em>C</em></span> <strong>then</strong> <span class="math inline"><em>π</em><sub>1</sub></span> <strong>else</strong> <span class="math inline"><em>π</em><sub>2</sub></span>, <span class="math inline"><em>θ</em>⟩</span> <span class="math inline">→</span> <span class="math inline">⟨<em>π</em><sub>2</sub>, <em>θ</em>⟩</span></p></li>
<li><p>если <span class="math inline"><em>I</em> ⊨ <em>C</em><em>θ</em></span> , то: <span class="math inline">⟨</span><strong>while</strong> <span class="math inline"><em>C</em></span> <strong>do</strong> <span class="math inline"><em>π</em></span> <strong>od</strong>, <span class="math inline"><em>θ</em>⟩</span> <span class="math inline">→</span> <span class="math inline">⟨<em>π</em></span>; <strong>while</strong> <span class="math inline"><em>C</em></span> <strong>do</strong> <span class="math inline"><em>π</em></span> <strong>od</strong>, <span class="math inline"><em>θ</em>⟩</span></p></li>
<li><p>если <span class="math inline"><em>I</em> ⊭ <em>C</em><em>θ</em></span> , то: <span class="math inline">⟨</span><strong>while</strong> <span class="math inline"><em>C</em></span> <strong>do</strong> <span class="math inline"><em>π</em></span> <strong>od</strong>, <span class="math inline"><em>θ</em>⟩</span> <span class="math inline">→</span> <span class="math inline">$\langle \empty, \theta \rangle$</span></p></li>
<li><p>если⟨<span class="math inline"><em>π</em><sub>1</sub></span>, <span class="math inline"><em>θ</em></span>⟩→⟨<span class="math inline"><em>π</em><sub>1</sub><sup>′</sup></span>, <span class="math inline"><em>η</em></span>⟩ , то ⟨ <span class="math inline"><em>π</em><sub>1</sub></span> ; <span class="math inline"><em>π</em><sub>2</sub></span> , <span class="math inline"><em>θ</em></span> ⟩ → ⟨ <span class="math inline"><em>π</em><sub>1</sub><sup>′</sup></span> ;<span class="math inline"><em>π</em><sub>2</sub></span> ,<span class="math inline"><em>η</em></span> ⟩<br />
</p></li>
<li><p>$; , $ <span class="math inline">→</span> <span class="math inline">⟨<em>π</em>, <em>θ</em>⟩</span></p></li>
</ul>
<p><strong>Трасса</strong> программы <span class="math inline"><em>π</em></span> на оценке <span class="math inline"><em>θ</em></span> в интерпретации <span class="math inline"><em>I</em></span> — это последовательность состояний вычисления вида <span class="math inline">⟨<em>π</em>, <em>θ</em>⟩ → ⟨<em>π</em><sub>1</sub>, <em>θ</em><sub>1</sub>⟩ → ⟨<em>π</em><sub>2</sub>, <em>θ</em><sub>2</sub>⟩ → …</span></p>
<p><strong>Вычисление программы</strong> <span class="math inline"><em>π</em></span> на оценке <span class="math inline"><em>θ</em></span> в интерпретации <span class="math inline"><em>I</em></span> — это максимальная по длине трасса <span class="math inline"><em>π</em></span> на <span class="math inline"><em>θ</em></span> в <span class="math inline"><em>I</em></span></p>
<p><strong>Результат конечного вычисления</strong> программы <span class="math inline"><em>π</em></span> на оценке <span class="math inline"><em>θ</em></span> в интерпретации <span class="math inline"><em>I</em></span> — это оценка данных последнего состояния вычисления <span class="math inline"><em>π</em></span> на <span class="math inline"><em>θ</em></span> в <span class="math inline"><em>I</em></span> , иными словами, если <span class="math inline">$\langle \pi, \theta \rangle \to^* \langle \empty, \eta \rangle$</span>, то <span class="math inline"><em>η</em></span> — результат вычисления <span class="math inline"><em>π</em></span> на <span class="math inline"><em>θ</em></span> в <span class="math inline"><em>I</em></span></p>
<p>(<span class="math inline">→<sup>*</sup></span> — транзитивное замыкание отношения <span class="math inline">→</span>)</p>
<p><strong>Формальная постановка задачи верификации</strong></p>
<p>Предусловие <span class="math inline"><em>ϕ</em></span> и постусловие <span class="math inline"><em>ψ</em></span> — это формулы логики предикатов, а <span class="math inline"><em>π</em></span> — императивная программа</p>
<p>Требование корректности <span class="math inline"><em>π</em></span> относительно <span class="math inline"><em>ϕ</em></span>, <span class="math inline"><em>ψ</em></span> записывается в видетриплета Хоара (или тройки Хоара): <span class="math inline">{<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span></p>
<p>Триплет Хоара <span class="math inline">{<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span> истинен в интерпретации <span class="math inline"><em>I</em></span> (<span class="math inline"><em>I</em> ⊨ {<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span>), если для любых оценок <span class="math inline"><em>θ</em></span>, <span class="math inline"><em>η</em></span> верно: если <span class="math inline"><em>I</em> ⊨ <em>ϕ</em><em>θ</em></span> и <span class="math inline">$\langle \pi, \theta \rangle \to^* \langle \empty, \eta \rangle$</span>, то <span class="math inline"><em>I</em> ⊨ <em>ψ</em><em>η</em></span></p>
<p>Программа <span class="math inline"><em>π</em></span> частично корректна в интерпретации <span class="math inline"><em>I</em></span> относительно предусловия <span class="math inline"><em>ϕ</em></span> и постусловия <span class="math inline"><em>ψ</em></span>, если <span class="math inline"><em>I</em> ⊨ {<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span></p>
<p><strong>Правила вывода</strong></p>
<figure>
<img src=".\img\22_1.jpg" alt="" /><figcaption>image</figcaption>
</figure>
<p><strong>Теорема корректности правил вывода Хоара</strong></p>
<p>Для любой интерпретации <span class="math inline"><em>I</em></span> и любого правила вывода логики Хоара (SKIP, AS, INF, COMP, IF, WHILE)</p>
<figure>
<img src=".\img\22_2.jpg" alt="" /><figcaption>image</figcaption>
</figure>
<p>если <span class="math inline"><em>I</em>| = <em>Ψ</em><sub>1</sub></span>, <span class="math inline"><em>I</em> ⊨ <em>Ψ</em><sub>2</sub></span>, <span class="math inline"><em>I</em> ⊨ <em>ϕ</em></span> и <span class="math inline"><em>I</em> ⊨ <em>ψ</em></span>, то <span class="math inline"><em>I</em> ⊨ <em>Φ</em></span></p>
<p><strong>Аннотация</strong> — это запись вида <span class="math inline">{<em>ϕ</em>}</span>, где <span class="math inline"><em>ϕ</em></span> — произвольная формула</p>
<p><strong>Аннотированная программа</strong> — это программа, в которой до и после каждой инструкции могут располагаться последовательности аннотаций</p>
<p>Аннотация может расцениваться как</p>
<ul>
<li><p>предусловие инструкции, следующей за аннотацией</p></li>
<li><p>постусловие инструкции, предшествующей аннотации</p></li>
<li><p>составная часть триплета, располагающегося в выводе (некоторого исходного триплета)</p></li>
</ul>
<p><strong>Теорема</strong>. Если существует аннотированная программа <span class="math inline">$\overline{\pi}$</span>, обосновывающая истинность триплета <span class="math inline">{<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span> в интерпретации <span class="math inline"><em>I</em></span>, то <span class="math inline"><em>I</em> ⊨ {<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span></p>
<p>Проблема корректности программ в общем случае неразрешима</p>
<p><strong>Слабейшее предусловие</strong> для программы <span class="math inline"><em>π</em></span> и постусловия <span class="math inline"><em>ψ</em></span> в интерпретации <span class="math inline"><em>I</em></span> — это формула wpr(<span class="math inline"><em>π</em>, <em>ψ</em>, <em>I</em></span>), для которой выполнены следующие условия:</p>
<ol type="1">
<li>$I $ {wpr(<span class="math inline"><em>π</em>, <em>ψ</em>, <em>I</em></span>)} <span class="math inline"><em>π</em></span> <span class="math inline">{<em>ψ</em>}</span></li>
<li>Для любой формулы <span class="math inline"><em>χ</em></span>, такой что <span class="math inline"><em>I</em> ⊨ {<em>χ</em>}<em>π</em>{<em>ψ</em>}</span>, верно <span class="math inline"><em>I</em> ⊨ <em>χ</em>→</span> wpr(<span class="math inline"><em>π</em>, <em>ψ</em>, <em>I</em></span>)</li>
</ol>
<p><strong>Теорема</strong>. <span class="math inline"><em>I</em> ⊨ {<em>ϕ</em>}<em>π</em>{<em>ψ</em>}</span> <span class="math inline">⇔</span> <span class="math inline"><em>I</em> ⊨ <em>ϕ</em>→</span> wpr(<span class="math inline"><em>π</em>, <em>ψ</em>, <em>I</em></span>)</p>
<p>Для полной автоматизации проверки корректности программ достаточно иметь два алгоритма:</p>
<ol type="1">
<li><p>Алгоритм проверки истинности формул логики предикатов</p></li>
<li><p>Алгоритм вычисления слабейшего предусловия для произвольных программ и постусловий</p></li>
</ol>
<p>Первый алгоритм зависит от выбора интерпретации программ, и в общем случае может не существовать.</p>
<p>Со вторым алгоритмом всё немного лучше:</p>
<p><strong>Теорема</strong>.</p>
<ul>
<li>wpr(x:=t, <span class="math inline"><em>ψ</em></span>) = <span class="math inline"><em>ψ</em></span>{x/t}<br />
</li>
<li>wpr(<span class="math inline"><em>π</em><sub>1</sub>; <em>π</em><sub>2</sub>, <em>ψ</em></span>) = wpr(<span class="math inline"><em>π</em><sub>1</sub></span>,wpr(<span class="math inline"><em>π</em><sub>2</sub>, <em>ψ</em></span>))</li>
<li>wpr(<strong>if</strong> <span class="math inline"><em>C</em></span> <strong>then</strong> <span class="math inline"><em>π</em><sub>1</sub></span> <strong>else</strong> <span class="math inline"><em>π</em><sub>2</sub></span> <strong>fi</strong>, <span class="math inline"><em>ψ</em></span>) = <span class="math inline"><em>C</em></span> &amp; wpr(<span class="math inline"><em>π</em><sub>1</sub>, <em>ψ</em></span>) ∨ <span class="math inline">¬<em>C</em></span> &amp; wpr(<span class="math inline"><em>π</em><sub>2</sub>, <em>ψ</em></span>)</li>
</ul>
<p>Для применения правила WHILE (а также для аннотации цикла, и для вычисления слабейшего предусловия цикла) необходимо предварительно найти подходящую формулу ϕ - инвариант цикла # 23. Темпоральная логика деревьев вычислений CTL. Синтаксис и семантика CTL. Примеры спецификаций моделей в терминах формул CTL. Темпоральная логика линейного времени PLTL. Синтаксис и семантика PLTL. Свойства живости и безопасности. Ограничения справедливости. Задача верификации моделей (model-checking).</p>
<p>Модель Крипке <span class="math inline"><em>M</em></span> над множеством атомарных высказываний <span class="math inline"><em>A</em><em>P</em></span> это четверка <span class="math inline"><em>M</em> = (<em>S</em>, <em>S</em><sub>0</sub>, <em>R</em>, <em>L</em>)</span>:</p>
<ul>
<li><span class="math inline"><em>S</em></span> - конечное множество состояний</li>
<li><span class="math inline">$S_0 \sube S$</span> - множество начальных состояний</li>
<li><span class="math inline">$R \sube S \times S$</span> - отношение переходов, которое должно быть тотальным ( для каждого состояния <span class="math inline"><em>s</em> ∈ <em>S</em></span> должно существовать такое состояние <span class="math inline"><em>s</em>′ ∈ <em>S</em></span>, что имеет место <span class="math inline"><em>R</em>(<em>s</em>, <em>s</em>′)</span>)</li>
<li><span class="math inline"><em>L</em> : <em>S</em> → 2<sup><em>A</em><em>P</em></sup></span> - функция разметки, которая помечает каждое состояние множеством атомарных высказываний, истинных в этом состоянии.</li>
</ul>
<p><strong>Трасса</strong> - последовательность событий (вычисление системы)</p>
<p><strong>Свойство системы</strong> - множество трасс</p>
<p>Свойство вычислений P называется <strong>свойством безопасности</strong> ,если оно удовлетворяет следующему требованию: какова бы ни была трасса <span class="math inline"><em>α</em></span>, $(2<sup>{AP})</sup>P $, существует такой ее конечный префикс <span class="math inline"><em>β</em></span>, что для любой трассы <span class="math inline"><em>α</em>′</span> выполняется соотношение <span class="math inline"><em>β</em><em>α</em>′ ∉ <em>P</em></span>.</p>
<p>Содержательный смысл: “отсутствие безопасности - это когда если что-то плохое случилось, то этого уже не исправить”</p>
<p>Свойство вычислений P называется <strong>свойством живости</strong> ,если оно удовлетворяет следующему требованию: для любого конечного слова <span class="math inline"><em>β</em></span>, <span class="math inline"><em>β</em> ∈ (2<sup><em>A</em><em>P</em></sup>)<sup>*</sup></span>, существует такая трасса <span class="math inline"><em>α</em></span>, <span class="math inline"><em>α</em> ∈ (2<sup><em>A</em><em>P</em></sup>)<sup><em>ω</em></sup></span> , для которой выполняется соотношение <span class="math inline"><em>β</em><em>α</em> ∈ <em>P</em></span>.</p>
<p>Содержательный смысл: “что бы ни случилось в начале, потом всегда можно достичь своей цели”</p>
<p>Различают два типа <strong>ограничений справедливости</strong> ( условий, которым должны удовлетворять пути в моделях Крипке, чтобы эти пути соответствовали вычислениям, построенным по принципу чередования - важно для асинхронно работающих систем, чтобы только один процесс не выполнялся бесконечно часто).</p>
<ul>
<li>Слабая справедливость : если путь почти всегда проходит через состояния, в которых может быть выполнено действие act , то действие act должно быть выполнено бесконечно часто.</li>
<li>Сильная справедливость : если путь бесконечно часто проходит через состояния, в которых может быть выполнено действие act , то действие act должно быть выполнено бесконечно часто.</li>
</ul>
<p>Темпоральные логики предназначены для описания свойств вычислений реагирующих систем, т.е. множеств трасс в размеченных системах переходов (моделях Крипке).</p>
<p><strong>CTL</strong>*</p>
<p><strong>Синтаксис</strong></p>
<p>В CTL* имеются формулы двух типов: <strong>формулы состояния</strong> (способные обращаться в истину в некотором состоянии) и <strong>формулы пути</strong> (способные быть истинными на протяжении некоторого пути). Формулами CTL* называются все формулы состояний, полученные по следующим правилам.</p>
<p>Формулы состояния:</p>
<ul>
<li><span class="math inline"><em>p</em> ∈ <em>A</em><em>P</em></span>, <span class="math inline"><em>p</em></span> - формула состояния</li>
<li><span class="math inline"><em>f</em><sub>1</sub>, <em>f</em><sub>2</sub></span> - формулы состояния, то $f_1, f_1 f_2, f_1 f_2 $ - формулы состояния</li>
<li><span class="math inline"><em>f</em></span> - формула пути, то <strong>E</strong><span class="math inline"><em>f</em></span> и <strong>A</strong><span class="math inline"><em>f</em></span> - формулы состояния</li>
</ul>
<p>Формулы пути:</p>
<ul>
<li><span class="math inline"><em>f</em></span> - формула состояния, то <span class="math inline"><em>f</em></span> - формула пути</li>
<li><span class="math inline"><em>g</em><sub>1</sub>, <em>g</em><sub>2</sub></span> - формулы пути, то <span class="math inline">¬<em>g</em><sub>1</sub>, <em>g</em><sub>1</sub> ∧ <em>g</em><sub>2</sub>, <em>g</em><sub>1</sub> ∨ <em>g</em><sub>2</sub></span>, <strong>X</strong><span class="math inline"><em>g</em><sub>1</sub></span>, <strong>F</strong><span class="math inline"><em>g</em><sub>1</sub></span>, <span class="math inline"><em>g</em><sub>1</sub></span><strong>U</strong><span class="math inline"><em>g</em><sub>2</sub></span>, <span class="math inline"><em>g</em><sub>1</sub></span><strong>R</strong><span class="math inline"><em>g</em><sub>2</sub></span> - формулы пути</li>
</ul>
<p><strong>Семантика</strong></p>
<p>Формул состояния:</p>
<ul>
<li><span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>p</em></span> <span class="math inline">⇔</span> <span class="math inline"><em>p</em> ∈ <em>L</em>(<em>s</em>)</span></li>
<li><span class="math inline"><em>M</em>, <em>s</em> ⊨ ¬<em>f</em><sub>1</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>s</em> ⊭ <em>f</em><sub>1</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>f</em><sub>1</sub> ∨ <em>f</em><sub>2</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>f</em><sub>1</sub></span> или <span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>f</em><sub>2</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>f</em><sub>1</sub> ∧ <em>f</em><sub>2</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>f</em><sub>1</sub></span> и <span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>f</em><sub>2</sub></span></li>
<li>$M,s <span class="math inline"> *  * <em>E</em> * *</span>f$ <span class="math inline">⇔</span> в <span class="math inline"><em>M</em></span> есть такой путь <span class="math inline"><em>π</em></span> из состояния <span class="math inline"><em>s</em></span>, что <span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>f</em></span> (формула выполняется на протяжении пути)</li>
<li>$M,s <span class="math inline"> *  * <em>А</em> * *</span>f$ <span class="math inline">⇔</span> в <span class="math inline"><em>M</em></span> для любого пути <span class="math inline"><em>π</em></span> из состояния <span class="math inline"><em>s</em></span>, что <span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>f</em></span></li>
</ul>
<p>Формул пути:</p>
<ul>
<li><span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub></span> <span class="math inline">⇔</span> для первого состояния <span class="math inline"><em>s</em></span> на пути <span class="math inline"><em>π</em></span> в <span class="math inline"><em>M</em></span> верно <span class="math inline"><em>M</em>, <em>s</em> ⊨ <em>g</em><sub>1</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em> ⊨ ¬<em>g</em><sub>1</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>π</em> ⊭ <em>g</em><sub>1</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub> ∨ <em>g</em><sub>2</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub></span> или <span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>2</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub> ∧ <em>g</em><sub>2</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub></span> и <span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>2</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em>⊨</span><strong>X</strong><span class="math inline"><em>g</em><sub>1</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>M</em>, <em>π</em><sup>1</sup> ⊨ <em>g</em><sub>1</sub></span> (<span class="math inline"><em>π</em><sup><em>i</em></sup></span> - это суффикc пути <span class="math inline"><em>π</em></span> начинающийся из состояния <span class="math inline"><em>s</em><sub><em>i</em></sub></span>)</li>
<li><span class="math inline"><em>M</em>, <em>π</em>⊨</span><strong>F</strong><span class="math inline"><em>g</em><sub>1</sub></span> <span class="math inline">⇔</span> существует такое <span class="math inline"><em>k</em> ≥ 0</span>, что <span class="math inline"><em>M</em>, <em>π</em><sup><em>k</em></sup> ⊨ <em>g</em><sub>1</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em>⊨</span><strong>G</strong><span class="math inline"><em>g</em><sub>1</sub></span> <span class="math inline">⇔</span> для любого <span class="math inline"><em>k</em> ≥ 0</span> верно <span class="math inline"><em>M</em>, <em>π</em><sup><em>k</em></sup> ⊨ <em>g</em><sub>1</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub></span><strong>U</strong><span class="math inline"><em>g</em><sub>2</sub></span> <span class="math inline">⇔</span> существует такое <span class="math inline"><em>k</em> ≥ 0</span> , что верно <span class="math inline"><em>M</em>, <em>π</em><sup><em>k</em></sup> ⊨ <em>g</em><sub>2</sub></span> и для каждого <span class="math inline">0 ≤ <em>j</em> &lt; <em>k</em></span> верно <span class="math inline"><em>M</em>, <em>π</em><sup><em>j</em></sup> ⊨ <em>g</em><sub>1</sub></span></li>
<li><span class="math inline"><em>M</em>, <em>π</em> ⊨ <em>g</em><sub>1</sub></span><strong>R</strong><span class="math inline"><em>g</em><sub>2</sub></span> <span class="math inline">⇔</span> каково бы ни было <span class="math inline"><em>j</em> ≥ 0</span> , если для каждого <span class="math inline"><em>i</em> &lt; <em>j</em></span> верно <span class="math inline"><em>M</em>, <em>π</em><sup><em>i</em></sup> ⊭ <em>g</em><sub>1</sub></span>, то <span class="math inline"><em>M</em>, <em>π</em><sup><em>j</em></sup> ⊨ <em>g</em><sub>2</sub></span></li>
</ul>
<p>CTL и LTL являются подмножествами CTL*.</p>
<p><strong>CTL</strong></p>
<p>В логике ветвящегося времени темпоральные операторы находятся непосредственно под действием кванторов по тем путям, которые исходят из заданного состояния. То есть каждый темпоральный оператор <strong>X, F, G, U, R</strong> должен следовать непосредственно за квантором пути <strong>A, E</strong>.</p>
<p><strong>Примеры спецификаций CTL</strong>:</p>
<ul>
<li><strong>EF</strong> (Start $ ~ $ Ready): можно достичь такого состояния, в котором условие Start выполняется, а Ready - нет;</li>
<li><strong>AG</strong> (Req <span class="math inline">→</span> <strong>AF</strong> Ack): когда бы ни был получен запрос, он рано или поздно будет подтвержден;</li>
<li><strong>AG</strong> (<strong>AF</strong> DeviceEnabled): условие DeviceEnabled выполняется бесконечно часто на каждом пути вычисления;</li>
<li><strong>AG</strong> (<strong>EF</strong> Restart): из любого достижимого состояния достижимо состояние Restart.</li>
</ul>
<p><strong>LTL</strong></p>
<p>В логике линейного времени операторы предназначены для описания событий на протяжении единственного пути вычисления. Состоит из всех формул вида <strong>A</strong><span class="math inline"><em>f</em></span>, где <span class="math inline"><em>f</em></span> - формула пути, в которой все формулы состояния - это атомарные высказывания.</p>
<p><strong>Примеры спецификаций LTL</strong>:</p>
<ul>
<li><strong>A</strong> (<strong>FG</strong> enabled <span class="math inline">→</span> <strong>GF</strong> fired)</li>
</ul>
<p><strong>Задача model-cheking</strong></p>
<p>Пусть задана модель Крипке <span class="math inline"><em>M</em> = (<em>S</em>, <em>S</em><sub>0</sub>, <em>R</em>, <em>L</em>)</span>, и формула темпоральной логики <span class="math inline"><em>ϕ</em></span>, которая выражает некоторую желаемую спецификацию. Требуется найти в множестве <span class="math inline"><em>S</em></span> подмножество <span class="math inline"><em>S</em><sub><em>ϕ</em></sub></span> всех состояний <span class="math inline"><em>s</em></span> , в которых выполняется <span class="math inline"><em>ϕ</em></span>, т.е. множество <span class="math inline"><em>S</em><sub><em>ϕ</em></sub> = {<em>s</em> ∈ <em>S</em>|<em>M</em>, <em>s</em> ⊨ <em>ϕ</em>}</span> , и проверить выполнимость включения <span class="math inline">$S_0 \sube S _{\phi}$</span> . ## 24. Временные автоматы как формальные модели распределенных систем реального времени. Вычисления временных автоматов. Примеры использования временных автоматов для моделирования встроенных систем. Зеноновские вычисления. Синтаксис и семантика TimedCTL. Задача верификации моделей программ реального времени. Программно-инструментальное средство верификации моделей программ реального времени UPPAAL.</p>
<p><strong>Система реального времени</strong> (СРВ) — это система, поведение которой существенно зависит не только от того, в каком порядке изменяются состояния компонентов системы, но и от того, за какое время происходит изменение состояний.</p>
<p><strong>Элементарными временными ограничениями</strong> над множеством часов <span class="math inline"><em>C</em></span> называются выражения вида: true, <span class="math inline"><em>x</em> &lt; <em>k</em></span>, <span class="math inline"><em>x</em> ≤ <em>k</em></span>, <span class="math inline"><em>x</em> − <em>y</em> &lt; <em>k</em></span>, <span class="math inline"><em>x</em> − <em>y</em> ≤ <em>k</em></span>, где <span class="math inline"><em>x</em>, <em>y</em> ∈ <em>C</em></span>, <span class="math inline"><em>k</em> ∈ <em>N</em><sub>0</sub></span></p>
<p><span class="math inline"><em>E</em><em>T</em><em>C</em>(<em>C</em>)</span> — множество всех элементарных временных ограничений над <span class="math inline"><em>C</em></span></p>
<p>Синтаксис <strong>временных ограничений</strong> над <span class="math inline"><em>C</em></span> задаётся формой Бэкуса-Наура <span class="math inline"><em>g</em> : := (<em>e</em><em>t</em><em>c</em>) | (<em>g</em>&amp;<em>g</em>) | (¬<em>g</em>)</span>, где <span class="math inline"><em>g</em></span> — временное ограничение и <span class="math inline"><em>e</em><em>t</em><em>c</em> ∈ <em>E</em><em>T</em><em>C</em>(<em>C</em>)</span></p>
<p><span class="math inline"><em>T</em><em>C</em>(<em>C</em>)</span> — множество всех временных ограничений над <span class="math inline"><em>C</em></span></p>
<p>Временное ограничение <strong>инвариантно</strong>, если в нём не содержатся подвыражения <span class="math inline"><em>x</em> − <em>y</em> &lt; <em>k</em></span>, <span class="math inline"><em>x</em> − <em>y</em> ≤ <em>k</em></span> и связка <span class="math inline">¬</span></p>
<p><span class="math inline"><em>I</em><em>C</em>(<em>C</em>)</span> — множество всех инвариантных временныx ограничений над <span class="math inline"><em>C</em></span></p>
<p><strong>Оценкой часов</strong> множества <span class="math inline"><em>C</em></span> называется отображение вида <span class="math inline"><em>v</em> : <em>C</em> → <em>R</em><sub> ≥ 0</sub></span></p>
<p><strong>Выполнимость временного ограничения</strong> <span class="math inline"><em>t</em><em>c</em></span> на оценке часов <span class="math inline"><em>v</em></span> (<span class="math inline"><em>v</em> ⊨ <em>t</em><em>c</em></span>) определяется следующим образом (<span class="math inline"> ⋈  − &lt;,≤</span>):</p>
<ul>
<li><span class="math inline"><em>v</em> ⊨ <em>t</em><em>r</em><em>u</em><em>e</em></span></li>
<li><span class="math inline"><em>v</em> ⊨ <em>x</em> ⋈ <em>k</em></span> <span class="math inline">⇔</span> $v(x) $ k</li>
<li><span class="math inline"><em>v</em> ⊨ <em>x</em> − <em>y</em> ⋈ <em>k</em></span> <span class="math inline">⇔</span> <span class="math inline"><em>v</em>(<em>x</em>) − <em>v</em>(<em>y</em>) ⋈ <em>k</em></span></li>
<li><span class="math inline"><em>v</em> ⊨ <em>t</em><em>c</em><sub>1</sub>&amp;<em>t</em><em>c</em><sub>2</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>v</em> ⊨ <em>t</em><em>c</em><sub>1</sub></span> и <span class="math inline"><em>v</em> ⊨ <em>t</em><em>c</em><sub>2</sub></span></li>
<li><span class="math inline"><em>v</em> ⊨ ¬<em>t</em><em>c</em><sub>1</sub></span> <span class="math inline">⇔</span> <span class="math inline"><em>v</em> ⊭ <em>t</em><em>c</em><sub>1</sub></span></li>
</ul>
<p><strong>Временной автомат</strong> над множеством атомарных высказываний AP — это система <span class="math inline">(<em>L</em>, <em>l</em><sub>0</sub>, <em>ξ</em>, <em>C</em>, <em>I</em>, <em>T</em>)</span>, где <span class="math inline"><em>L</em></span>— конечное множество состояний <span class="math inline"><em>l</em><sub>0</sub></span> — начальное состояние <span class="math inline"><em>l</em><sub>0</sub> ∈ <em>L</em></span>, <span class="math inline"><em>ξ</em> : <em>L</em> → 2<sup><em>A</em><em>P</em></sup></span> — разметка состояний событиями <span class="math inline"><em>C</em></span> — конечное множество часов <span class="math inline"><em>I</em> : <em>L</em> → <em>I</em><em>C</em>(<em>C</em>)</span> — разметка состояний инвариантами <span class="math inline">$T \sube L \times TC(C) \times 2^{C} \times L$</span> отношение переходов — <span class="math inline">(<em>l</em><sub><em>i</em></sub>, <em>g</em>, <em>X</em>, <em>l</em><sub>2</sub>)</span> — переход из состояния <span class="math inline"><em>l</em><sub>1</sub></span> в состояние <span class="math inline"><em>l</em><sub>2</sub></span> с предусловием <span class="math inline"><em>g</em></span> и множеством сбрасываемых часов <span class="math inline"><em>X</em></span> [<span class="math inline"><em>l</em><sub>1</sub>→<sup><em>g</em>, <em>X</em></sup><em>l</em><sub>2</sub></span>]</p>
<p><strong>Вычислительная конфигурация</strong> временного автомата <span class="math inline"><em>A</em> = (<em>L</em>, <em>l</em><sub>0</sub>, <em>ξ</em>, <em>C</em>, <em>I</em>, <em>T</em>)</span> имеет вид <span class="math inline"><em>σ</em> = (<em>l</em>, <em>v</em>)</span> , где <span class="math inline"><em>l</em> ∈ <em>L</em></span> и <span class="math inline"><em>v</em> : <em>C</em> → <em>R</em><sub> ≥ 0</sub></span> (<span class="math inline"><em>v</em></span> - это оценка часов)</p>
<p>Конфигурации (дискретно) преобразуются автоматом <span class="math inline"><em>A</em></span> в процессе вычисления двумя способами:</p>
<ol type="1">
<li><p>Продвижение времени (<span class="math inline"><em>σ</em> ↦ <em>σ</em>′</span> ) [<span class="math inline"><em>d</em> ∈ <em>R</em><sub> ≥ 0</sub></span>]</p>
<ol type="1">
<li>$’ = + d $<br />
</li>
<li><span class="math inline"><em>v</em> + <em>d</em> ⊨ <em>I</em>(<em>l</em>)</span> - новая оценка часов удовлетворяет ограничениям состояния <span class="math inline"><em>l</em></span> при изменении времени</li>
</ol></li>
<li><p>Выполнение перехода (<span class="math inline"><em>σ</em> ↪ <em>σ</em>′</span> ) [<span class="math inline"><em>l</em>→<sup><em>g</em>, <em>X</em></sup><em>l</em>′ ∈ <em>T</em></span>]</p>
<ol type="1">
<li><span class="math inline"><em>σ</em>′ = <em>σ</em>[<em>X</em>][<em>l</em>/<em>l</em>′]</span> сброс часов</li>
<li><span class="math inline"><em>v</em> ⊨ <em>g</em></span> оценка часов удовлетворяет ограничению перехода</li>
<li><span class="math inline"><em>v</em>[<em>X</em>] ⊨ <em>I</em>(<em>l</em>′)</span> в новом состоянии выполняются оценки часов</li>
</ol></li>
</ol>
<p><strong>Трассой</strong> автомата, исходящей из конфигурации <span class="math inline"><em>σ</em></span> (или, коротко, <span class="math inline"><em>σ</em></span>-трассой), называется последовательность конфигураций вида <span class="math inline"><em>σ</em> → <em>σ</em><sub>1</sub> → <em>σ</em><sub>2</sub> → ...</span></p>
<p><strong>Частичным вычислением автомата</strong> называется трасса, исходящая из начальной конфигурации.</p>
<p>Конфигурация <span class="math inline"><em>σ</em></span> называется <strong>тупиковой</strong>, если не существует конфигурации <span class="math inline"><em>σ</em>′</span>, такой что <span class="math inline"><em>σ</em> → <em>σ</em>′</span> .</p>
<p>Трасса называется <strong>полной</strong>, если она бесконечна или оканчивается тупиковой конфигурацией.</p>
<p><strong>Вычислением</strong> автомата называется полная трасса, исходящая из начальной конфигурации.</p>
<p><strong>Примеры использования</strong>:</p>
<ul>
<li>Оценка времени реакции встроенной системы на определенное событие (Например после возникновения ошибки в системе должна загореться сигнальная лампочка в течение 3 секунд, и переключится в режим обработки ошибки в течение 10 секунд)</li>
<li>Проверка свойств взаимодействия (Например, что в системе управления транспортом невозможна такая ситуация, что светофоры горят зеленым для пересекающихся дорог)</li>
</ul>
<p>Полная трасса конвергентна, если её длительность конечна, и дивергентна, если её длительность бесконечна. Вычислением Зенона (или <strong>зеноновским вычислением</strong>) называется конвергентное вычисление, в котором выполнение перехода ($$) встречается бесконечно часто.</p>
<p>Логика ветвящегося реального времени (Timed CTL; TCTL) — аналог CTL, адаптированный к особенностям поведения СРВ.</p>
<p>Минимальный синтаксис TCTL-формул над множеством атомарных высказываний AP и множеством часов C задаётся формой Бэкуса-Наура</p>
<p><span class="math inline"><em>ϕ</em> :  := <em>a</em> | (<em>e</em><em>t</em><em>c</em>) | (<em>ϕ</em>&amp;<em>ϕ</em>) | (¬<em>ϕ</em>) | (</span><strong>E</strong><span class="math inline">(<em>ϕ</em></span> <strong>U</strong> <span class="math inline"><em>ϕ</em>)) | (</span><strong>A</strong><span class="math inline">(<em>ϕ</em></span><strong>U</strong><span class="math inline"><em>ϕ</em>))</span>, где <span class="math inline"><em>ϕ</em></span> — TCTL-формула, <span class="math inline"><em>a</em> ∈ <em>A</em><em>P</em></span> и <span class="math inline"><em>e</em><em>t</em><em>c</em> ∈ <em>E</em><em>T</em><em>C</em>(<em>C</em>)</span></p>
<p>Содержательная трактовка кванторов <strong>E</strong>, <strong>A</strong> и оператора <strong>U</strong> схожа с их трактовкой в CTL но адаптирована к особенностям выполнения СРВ:</p>
<ul>
<li><strong>E</strong>Φ: существует дивергентное выполнение СРВ, для которого верно Φ</li>
<li><strong>A</strong>Φ: для любого дивергентного выполнения СРВ верно Φ</li>
<li><span class="math inline"><em>ϕ</em></span><strong>U</strong><span class="math inline"><em>ψ</em></span>: в реальном будущем станет верным <span class="math inline"><em>ψ</em></span>, а до тех пор будет верно <span class="math inline"><em>ϕ</em></span></li>
</ul>
<p>Рассмотрим временной автомат <span class="math inline"><em>A</em> = (<em>L</em>, <em>l</em><sub>0</sub>, <em>ξ</em>, <em>C</em>, <em>I</em>, <em>T</em>)</span> над <span class="math inline"><em>A</em><em>P</em></span>, его конфигурацию <span class="math inline"><em>σ</em> = (<em>l</em>, <em>ν</em>)</span> и TCTL-формулу <span class="math inline"><em>ϕ</em></span> над <span class="math inline"><em>C</em></span> и <span class="math inline"><em>A</em><em>P</em></span></p>
<p>Формула <span class="math inline"><em>ϕ</em></span> выполняется в конфигурации <span class="math inline"><em>σ</em></span> автомата <span class="math inline"><em>A</em></span> (<span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>ϕ</em></span>) в следующих случаях:</p>
<ul>
<li><p><span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>a</em></span> , где <span class="math inline"><em>a</em> ∈ <em>A</em><em>P</em></span> <span class="math inline">⇔</span> <span class="math inline"><em>a</em> ∈ <em>ξ</em>(<em>l</em>)</span></p></li>
<li><p><span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>e</em><em>t</em><em>c</em></span>, где <span class="math inline"><em>e</em><em>t</em><em>c</em> ∈ <em>E</em><em>T</em><em>C</em>(<em>C</em>)</span> <span class="math inline">⇔</span> <span class="math inline"><em>ν</em> ⊨ <em>e</em><em>t</em><em>c</em></span></p></li>
<li><p><span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>ψ</em>&amp;<em>χ</em></span> <span class="math inline">⇔</span> <span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>ψ</em></span> и <span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>χ</em></span></p></li>
<li><p><span class="math inline"><em>A</em>, <em>σ</em> ⊨ ¬<em>ψ</em></span> <span class="math inline">⇔</span> <span class="math inline"><em>A</em>, <em>σ</em> ⊭ <em>ψ</em></span></p></li>
<li><p>$A, $ <strong>E</strong>Φ <span class="math inline">⇔</span> существует дивергентная <span class="math inline"><em>σ</em></span>-трасса <span class="math inline"><em>τ</em></span> автомата <span class="math inline"><em>A</em></span>, такая что <span class="math inline"><em>A</em>, <em>τ</em>⊨</span> Φ</p></li>
<li><p><span class="math inline"><em>A</em>, <em>σ</em>⊨</span> <strong>A</strong>Φ <span class="math inline">⇔</span> для любой дивергентной <span class="math inline"><em>σ</em></span>-трассы <span class="math inline"><em>τ</em></span> автомата <span class="math inline"><em>A</em></span> верно <span class="math inline"><em>A</em>, <em>τ</em>⊨</span> Φ</p></li>
<li><p><span class="math inline"><em>A</em>, <em>τ</em> ⊨ <em>ψ</em></span><strong>U</strong><span class="math inline"><em>χ</em></span>, где <span class="math inline"><em>τ</em> = (<em>σ</em><sub>0</sub> → <em>σ</em><sub>1</sub> → <em>σ</em><sub>2</sub> → ...)</span> — дивергентная трасса <span class="math inline">⇔</span> <span class="math inline"><em>A</em>, <em>σ</em><sub>0</sub> ⊨ <em>χ</em></span> или существуют номер <span class="math inline"><em>k</em>, <em>k</em> ≥ 1</span>, и конфигурация <span class="math inline"><em>σ</em></span>, порождаемая на <span class="math inline"><em>k</em></span>-м шаге трассы <span class="math inline"><em>τ</em></span>, такие что</p>
<ul>
<li><span class="math inline"><em>A</em>, <em>σ</em> ⊨ <em>χ</em></span> и</li>
<li>для всех конфигураций <span class="math inline"><em>δ</em></span>, порождаемых трассой $ _0 _1 … _k $, верно <span class="math inline"><em>A</em>, <em>δ</em> ⊨ <em>ψ</em> ∨ <em>χ</em></span></li>
</ul></li>
</ul>
<p>TCTL-формула <span class="math inline"><em>ϕ</em></span> <strong>выполняется</strong> на автомате <span class="math inline"><em>A</em></span> (<span class="math inline"><em>A</em> ⊨ <em>ϕ</em></span>), если она выполняется в начальной конфигурации этого автомата</p>
<p><strong>Задача model checking для TCTL</strong> Для заданного корректного временного автомата <span class="math inline"><em>A</em></span> и заданной TCTL-формулы <span class="math inline"><em>ϕ</em></span> проверить справедливость соотношения <span class="math inline"><em>A</em> ⊨ <em>ϕ</em></span></p>
<p><strong>UPPAAL</strong> – это средство верификации систем реального времени.</p>
<p>Структура:</p>
<ul>
<li><p>Модуль описания - входная модель (расширенная модель сети временных автоматов), возможность описания параметризованных шаблонов, наличие данных различной степени локальности</p></li>
<li><p>Модуль симуляции - генерация и визуализация трассы временного автомата</p></li>
<li><p>Модуль верификации - проверка темпоральных свойств, предоставление трассы-контрпримера</p></li>
</ul>
<blockquote>
<p>Там, где $$ про зеноновские вычисления - это переходы без продвижения по времени</p>
<p>Примеры придуманы из воздуха (в курсе только примеры с птичками, голодными и не очень) ## 25. Дискретные цепи Маркова. Метод вложенных цепей Маркова при исследовании систем массового обслуживания.</p>
</blockquote>
<p>Пусть <span class="math inline"><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ..., <em>X</em><sub><em>n</em></sub>, ..</span> - последовательность случайных величин, принимающих значения <span class="math inline">1, .., <em>k</em>, ..</span> (счетное множество). Процесc <span class="math inline"><em>X</em><sub><em>t</em></sub></span> будет марковской цепью при условии того, что следующее значение в цепи зависит только от предыдущего: <span class="math inline"><em>P</em>(<em>X</em><sub><em>n</em> + 1</sub> = <em>i</em><sub><em>n</em> + 1</sub>|<em>X</em><sub><em>n</em></sub> = <em>i</em><sub><em>n</em></sub>, ..., <em>X</em><sub>1</sub> = <em>i</em><sub>1</sub>) = <em>P</em>(<em>X</em><sub><em>n</em> + 1</sub> = <em>i</em><sub><em>n</em> + 1</sub>|<em>X</em><sub><em>n</em></sub> = <em>i</em><sub><em>n</em></sub>)</span></p>
<p>Важным параметром характеристики цепи Маркова является вероятность перехода за один шаг <span class="math inline"><em>P</em><sub><em>i</em><sub><em>n</em></sub><em>j</em><sub><em>n</em> + 1</sub>, <em>n</em></sub></span>, и если она не зависит от <span class="math inline"><em>n</em></span>, то <strong>цепь Маркова называется однородной</strong> . Далее рассматриваются только такие цепи.</p>
<p>Пусть вероятность перехода из состояния <span class="math inline"><em>i</em></span> в состояние <span class="math inline"><em>j</em></span> : <span class="math inline"><em>P</em>(<em>X</em><sub><em>n</em> + 1</sub> = <em>j</em>|<em>X</em><sub><em>n</em></sub> = <em>i</em>) = <em>P</em><sub><em>i</em><em>j</em></sub></span>. Тогда матрица вероятностей перехода за один шаг обозначается <span class="math inline">(<em>P</em><sub><em>i</em><em>j</em></sub>)</span> - матрица вероятностей перехода за один шаг.</p>
<p>Вероятность перехода за из состояние <span class="math inline"><em>i</em></span> в состояние <span class="math inline"><em>j</em></span> за <span class="math inline"><em>n</em></span> шагов обозначается следующим образом<span class="math inline"><em>P</em>(<em>X</em><sub><em>k</em> + <em>n</em></sub> = <em>j</em>|<em>X</em><sub><em>k</em></sub> = <em>i</em>) = <em>P</em><sub><em>i</em><em>j</em></sub><sup>(<em>n</em>)</sup></span> .</p>
<p><span class="math inline"><em>P</em><sub><em>i</em></sub><sup>0</sup> = <em>P</em>(<em>X</em><sub>1</sub> = <em>i</em>)</span> - задает начальное распределение вероятностей.</p>
<p>Для определения вероятности перехода за любое число шагов используется уравнение <strong>Колмогорова-Чепмена</strong>: <span class="math inline">$P_{ij}^{n+m} = \sum\limits_{k=1}^{\infin} P_{ik}^{(n)} P_{k,j}^{(m)}$</span> .</p>
<p><strong>Некоторые свойства цепей Маркова</strong>:</p>
<p><strong>Достижимость состояния</strong> - состояние <span class="math inline"><em>j</em></span> достижимо из <span class="math inline"><em>i</em></span> <span class="math inline">⇔</span> <span class="math inline">∃<em>n</em> : <em>P</em><sub><em>i</em><em>j</em></sub><sup>(<em>n</em>)</sup> &gt; 0</span></p>
<p><strong>Несущественность состояния</strong> - состояние <span class="math inline"><em>i</em></span> называется несущественным, если <span class="math inline">∃<em>j</em>:</span> <span class="math inline"><em>j</em></span> из <span class="math inline"><em>i</em></span> достижимо, но <span class="math inline"><em>i</em></span> из <span class="math inline"><em>j</em></span> недостижимо</p>
<p><strong>Поглощающее состояние</strong> - состояние <span class="math inline"><em>i</em></span> называется поглощающим, если <span class="math inline"><em>P</em><sub><em>i</em><em>i</em></sub> = 1</span></p>
<p>Далее будем рассматривать цепи Маркова без несущественных состояний и без поглощающих состояний</p>
<p><strong>Сообщающиеся состояния</strong> - <span class="math inline"><em>i</em></span> и <span class="math inline"><em>j</em></span>, сообщающиеся <span class="math inline"><em>i</em> ↔︎ <em>j</em></span>, если <span class="math inline"><em>i</em></span> достижимо из <span class="math inline"><em>j</em></span> и наоборот</p>
<p><strong>Неразложимость цепи</strong> - цепь Маркова неразложима, если все состояния образуют один класс сообщающихся состояний</p>
<p><strong>Период состояния <span class="math inline"><em>i</em></span></strong> : $d(i) = НОД(n : P_{ii}^{(n)} , n ) $</p>
<p><strong>Непериодическое состояние</strong> - <span class="math inline"><em>d</em>(<em>i</em>) = 1</span></p>
<p><strong>Утверждение</strong>: если <span class="math inline"><em>i</em> ↔︎ <em>j</em></span>, то <span class="math inline"><em>d</em>(<em>i</em>) = <em>d</em>(<em>j</em>)</span>. Таким образом для неразложимой цепи можно говорить о периоде цепи Маркова</p>
<p><strong>Вероятность первого возвращения за <span class="math inline"><em>n</em></span> шагов</strong> <span class="math inline"><em>f</em><sub><em>i</em><em>i</em></sub><sup>(<em>n</em>)</sup> = <em>P</em>(<em>X</em><sub><em>n</em></sub> = <em>i</em>, <em>X</em><sub><em>n</em> − 1</sub> ≠ <em>i</em>, …, <em>X</em><sub>1</sub> ≠ <em>i</em>|<em>X</em><sub>0</sub> = <em>i</em>)</span></p>
<p><strong>Вероятность возвращения за конечное число шагов</strong> <span class="math inline">$f_{ii} = \sum\limits_{n=1}^{\infin}f_{ii}^{(n)}$</span></p>
<p><strong>Возвратность состояния</strong> - состояние <span class="math inline"><em>i</em></span> возвратна, если <span class="math inline"><em>f</em><sub><em>i</em><em>i</em></sub> = 1</span></p>
<p><strong>Утверждение</strong>: если $i $ возвратно и <span class="math inline"><em>i</em> ↔︎ <em>j</em></span>, то <span class="math inline"><em>j</em></span> возвратно. Таким образом для неразложимой цепи можно говорить о возвратности цепи</p>
<p>Цепь Маркова называется эргодической, если <span class="math inline">$\pi_j = \lim\limits_{n \to \infin}P_{ij}^{(n)}$</span>.</p>
<p><strong>Теорема</strong>. Рассмотрим неразложимую, непериодическую возвратную цепь Маркова. Тогда <span class="math inline">$\exists \lim\limits_{n \to \infin} P_{ii}^{(n)} = {1 \over \sum\limits_{n=1}^{\infin}nf_{ii}^{(n)}}$</span> , и <span class="math inline">$\lim\limits_{n \to \infin} P_{ji}^{(n)} = \lim\limits_{n \to \infin} P_{ii}^{(n)}$</span></p>
<p>Важным понятием является <strong>стационарное распределение</strong> цепи Маркова <span class="math inline">$\pi = (\pi_0, \pi_2, \dots), \pi_k \ge 0, k \ge 0, \sum\limits_{k \ge 0} \pi_k = 1$</span>, которое удовлетворяет соотношениям <span class="math inline">$\pi_j = \sum\limits_{k}\pi_kP_{kj}$</span></p>
<p><strong>Теорема</strong>. Существует и единственно стационарное распределение при условии неразложимости, непериодичности и возвратности цепи Маркова.</p>
<p><strong>Система массового обслуживания</strong></p>
<p>В случайные моменты времени в системе появляются запросы на обслуживание. Система массового обслуживания имеет приборы для обслуживания заявок и дисциплины обслуживания принятых заявок.</p>
<p><strong>Входящий поток</strong> это <span class="math inline">{<em>z</em><sub><em>i</em></sub>}, <em>i</em> ≥ 1</span> - последовательность неотрицательных случайных величин, задающая последовательность интервалов между поступлениями заявок на обслуживание</p>
<p>Если <span class="math inline"><em>z</em><sub>1</sub>, <em>z</em><sub>2</sub>, ...</span> - независимые одинаково распределенные случайные величины, то такой поток называется <strong>реккурентным</strong> и <span class="math inline"><em>P</em>(<em>z</em><sub>1</sub>, ..., <em>z</em><sub><em>n</em></sub>) = <em>P</em>(<em>z</em><sub>1</sub>)...<em>p</em>(<em>z</em><sub><em>n</em></sub>) = <em>P</em>(<em>z</em>)<sup><em>n</em></sup> = <em>A</em>(<em>x</em>)</span>.</p>
<p><strong>Пуассоновский поток</strong> - поток, где <span class="math inline"><em>A</em>(<em>x</em>) = 1 − <em>e</em><sup> − <em>a</em><em>x</em></sup></span></p>
<p><strong>Интенсивность потока</strong> <span class="math inline"><em>a</em></span> - среднее число заявок в единицу времени</p>
<p><strong>Метод вложенных цепей</strong></p>
<p><span class="math inline"><em>L</em>(<em>t</em>)</span> - число заявок в системе в момент времени <span class="math inline"><em>t</em></span>. Если не все потоки поступления и обработки заявок имеют показательное распределение (а значит процесс не марковский в общем), то стоит рассматривать систему только в те моменты времени, когда процесс будет марковским. Например d моменты завершения обработки заявки (если время обработки не показательное) и рассматривать <span class="math inline"><em>L</em><sub><em>n</em></sub> = <em>L</em>(<em>t</em><sub><em>n</em></sub> + 0)</span> - в момент завершения <span class="math inline"><em>n</em></span>-го кванта времени.</p>
<p>Далее методами теории цепей Маркова исследуют стационарное распределение вложенной цепи и затем по этому распределению восстанавливают стационарное распределение исходного процесса.</p>
<h1 id="процессы-гибели-и-рождения.-исследование-марковских-систем-обслуживания-с-помощью-теории-процессов-гибели-и-рождения.">26. Процессы гибели и рождения. Исследование марковских систем обслуживания с помощью теории процессов гибели и рождения.</h1>
<p>Случайный процесс <span class="math inline"><em>X</em><sub><em>t</em></sub></span> называется процессом гибели и рождения. Если:</p>
<ol type="1">
<li>Множество его значений содержится в множестве целых неотрицательных чисел</li>
<li>Время пербывания в состоянии <span class="math inline"><em>i</em></span> подчинено показательному распределению с параметром $_i + _i &gt; 0 $</li>
<li>При этом процесс переходит в состояние <span class="math inline"><em>i</em> + 1</span> c вероятностью <span class="math inline">$\lambda_i \over \lambda_i + \mu_i$</span>, а в <span class="math inline"><em>i</em> − 1</span> c вероятностью <span class="math inline">$\mu_i \over \lambda_i + \mu_i$</span></li>
</ol>
<p>Процесс, где <span class="math inline"><em>L</em>(<em>t</em>)</span> - число требований в системе в момент времени <span class="math inline"><em>t</em></span>, во многих марковских системах массового обслуживания является частным случаем процесса гибели и рождения. В систему могут поступать и уходить заявки в течение случайных промежутков времени.</p>
<p>В случае непрерывной марковской цепи <span class="math inline">$X_t, t \in [0,+\infin)$</span> для нее необходимо выполнения условия: <span class="math inline">∀<em>n</em>, ∀<em>t</em><sub>1</sub> &lt; <em>t</em><sub>2</sub> &lt; … &lt; <em>t</em><sub><em>n</em></sub></span> <span class="math inline"><em>P</em>(<em>X</em><sub><em>t</em><sub><em>n</em></sub></sub> = <em>i</em><sub><em>n</em></sub>|<em>X</em><sub><em>t</em><sub><em>n</em> − 1</sub></sub> = <em>i</em><sub><em>n</em> − 1</sub>, …, <em>X</em><sub><em>t</em><sub>1</sub></sub> = <em>i</em><sub>1</sub>) = <em>P</em>(<em>X</em><sub><em>t</em><sub><em>n</em></sub></sub> = <em>i</em><sub><em>n</em></sub>|<em>X</em><sub><em>t</em><sub><em>n</em> − 1</sub></sub> = <em>i</em><sub><em>n</em> − 1</sub>)</span>. То есть вероятность перехода зависит только от предыдущего состояния, в котором находился процесс. Введем матрицу вероятностей перехода за фиксированное время <span class="math inline"><em>t</em></span> (переходная функция) <span class="math inline"><em>P</em><sub><em>i</em><em>j</em></sub>(<em>t</em>) = <em>P</em>(<em>X</em><sub><em>t</em> + <em>s</em></sub> = <em>j</em>|<em>X</em><sub><em>s</em></sub> = <em>i</em>)</span> - вероятность перехода из состояния <span class="math inline"><em>i</em></span> в состояние <span class="math inline"><em>j</em></span> за время <span class="math inline"><em>t</em></span>.</p>
<p>Прямые уравнения Колмогорова для вероятностей перехода в случае процесса гибели и рождения имеют вид (слева производная):</p>
<p><span class="math inline"><em>P</em>′<sub><em>i</em>0</sub>(<em>t</em>) =  − <em>λ</em><sub>0</sub><em>P</em><sub><em>i</em>0</sub>(<em>t</em>) + <em>μ</em><sub>1</sub><em>P</em><sub><em>i</em>1</sub>(<em>t</em>)</span></p>
<p><span class="math inline"><em>P</em>′<sub><em>i</em><em>j</em></sub>(<em>t</em>) =  − (<em>λ</em><sub><em>j</em></sub> + <em>μ</em><sub><em>j</em></sub>)<em>P</em><sub><em>i</em><em>j</em></sub>(<em>t</em>) + <em>λ</em><sub><em>j</em> − 1</sub><em>P</em><sub><em>i</em><em>j</em> − 1</sub>(<em>t</em>) + <em>μ</em><sub><em>j</em> + 1</sub><em>P</em><sub><em>i</em><em>j</em> + 1</sub>(<em>t</em>)</span>, <span class="math inline"><em>j</em> ≥ 1</span></p>
<p><span class="math inline">$P_{ij}(0) = \left\{ \begin{matrix} 1 ,i =j \\ 0, i\neq j \end{matrix} \right.$</span></p>
<p>Решение этой бесконечной системы дифференциальных уравнений в явном виде существует только при стационарном распределении вероятностей процесса <span class="math inline">$\lim\limits_{t \to \infin}P_{ij}(t) = \pi_{j}$</span>. В таком случае система преобразуется в следующий вид (производная константы равна нулю):</p>
<p><span class="math inline"> − <em>λ</em><sub>0</sub><em>π</em><sub>0</sub> + <em>μ</em><sub>1</sub><em>π</em><sub>1</sub> = 0</span></p>
<p><span class="math inline"> − (<em>λ</em><sub><em>j</em></sub> + <em>μ</em><sub><em>j</em></sub>)<em>π</em><sub><em>j</em></sub> + <em>λ</em><sub><em>j</em> − 1</sub><em>π</em><sub><em>j</em> − 1</sub> + <em>μ</em><sub><em>j</em> + 1</sub><em>π</em><sub><em>j</em> + 1</sub> = 0</span> <span class="math inline">⇔</span> <span class="math inline"> − <em>λ</em><sub><em>j</em></sub><em>π</em><sub><em>j</em></sub> + <em>μ</em><sub><em>j</em> + 1</sub><em>π</em><sub><em>j</em> + 1</sub> =  − <em>λ</em><sub><em>j</em> − 1</sub><em>π</em><sub><em>j</em> − 1</sub> + <em>μ</em><sub><em>j</em></sub><em>π</em><sub><em>j</em></sub></span></p>
<p>Далее возможно выделить реккурентное соотношение</p>
<p><span class="math inline"><em>λ</em><sub><em>j</em> − 1</sub><em>π</em><sub><em>j</em> − 1</sub> = <em>μ</em><sub><em>j</em></sub><em>π</em><sub><em>j</em></sub></span></p>
<p><span class="math inline">$\pi_j = -{\lambda_{j-1} \over \mu_j}\pi_{j-1}$</span></p>
<p>Обозначим $<em>j = {</em>{j-1} <em>j} $ , <span class="math inline"><em>ρ</em><sub>0</sub> = 1</span>, тогда при $</em>{j=1}^{}_{i=1}^j_i + $ - существует общее решение системы:</p>
<p><span class="math inline">$\pi_0 = {1 \over \sum\limits_{j=1}^{\infin}\prod\limits_{i=1}^j\rho_i}$</span> , <span class="math inline">$\pi_j = (\prod\limits_{i=1}^j\rho_i)\pi_0$</span></p>
<p>Таким образом найдены вероятности нахождения системы во всех состояниях при длительной работе системы (<span class="math inline">$t \to \infin$</span>). # 27. Понятие антагонистической игры. Верхнее и нижнее значения конечных и бесконечных антагонистических игр. Седловая точка. Необходимые и достаточные условия существования седловой точки. Теорема Фон Неймана о существовании седловой точки у вогнуто-выпуклых функций.</p>
<p>В антагонистической игре принимают участие два игрока: первый (1) и второй (2). Игрок 1 выбирает стратегию <span class="math inline"><em>x</em></span> из множества стратегий <span class="math inline"><em>X</em></span>. Игрок 2 выбирает стратегию <span class="math inline"><em>y</em></span> из множества <span class="math inline"><em>Y</em></span>. Задана функция выигрыша <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span> первого игрока, определенная на <span class="math inline"><em>X</em> × <em>Y</em></span>. Выигрыш первого игрока является проигрышем для второго. Цель первого игрока состоит в увеличении выигрыша <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span>, а цель второго - в уменьшении <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span>.</p>
<p>Антагонистическая игра задается набором $Г = X, Y, F(x,y) $</p>
<p>Антагонистическая игра <span class="math inline"><em>Г</em></span> называется матричной, если множества стратегий игроков конечны: <span class="math inline"><em>X</em> = {1, …, <em>m</em>}</span>, <span class="math inline"><em>Y</em> = {1, …, <em>n</em>}</span>. Стратегия первого игрока обозначается <span class="math inline"><em>i</em></span>, стратегия второго игрока обозначается <span class="math inline"><em>j</em></span>, выигрыш первого игрока <span class="math inline"><em>F</em>(<em>i</em>, <em>j</em>) = <em>a</em><sub><em>i</em><em>j</em></sub></span>. Матрица <span class="math inline"><em>A</em> = (<em>a</em><sub><em>i</em><em>j</em></sub>)<sub><em>m</em> × <em>n</em></sub></span> называется матрицей игры. Первый игрок выбирает номер строки <span class="math inline"><em>i</em></span>, второй - номер столбца <span class="math inline"><em>j</em></span>.</p>
<p><strong>Нижнее значение игры</strong></p>
<p><span class="math inline">$\underline{I} = \max\limits_{i=\overline{1,n}} \min\limits_{j=\overline{1,m}} F(i,j)$</span> - конечная игра, наилучший гарантированный результат для первого игрока в отсутствии знания о выборе стратегии вторым игроком</p>
<p><span class="math inline">$\underline{I} = \sup\limits_{x \in X} \inf\limits_{y \in Y} F(x,y) = \inf\limits_{y \in Y} F(x_0,y)$</span> - бесконечная игра, <span class="math inline"><em>x</em><sub>0</sub></span> - оптимальная стратегия первого игрока</p>
<p><strong>Верхнее значение игры</strong></p>
<p><span class="math inline">$\overline{I} = \min\limits_{j=\overline{1,m}} \max\limits_{i=\overline{1,n}} F(i,j)$</span> - конечномерный случай, наилучший гарантированный результат для второго игрока в отсутствии знания о выборе стратегии первым игроком</p>
<p><span class="math inline">$\overline{I} = \inf\limits_{y \in Y} \sup\limits_{x \in X} F(x,y) = \sup\limits_{x \in X} F(x,y_0)$</span> - бесконечная игра, <span class="math inline"><em>y</em><sub>0</sub></span> - оптимальная стратегия второго игрока</p>
<p><strong>Седловая точка</strong></p>
<p><span class="math inline">(<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>)</span> - седловая точка, если</p>
<p><span class="math inline"><em>F</em>(<em>x</em>, <em>y</em><sub>0</sub>) ≤ <em>F</em>(<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>) ≤ <em>F</em>(<em>x</em><sub>0</sub>, <em>y</em>)</span> для <span class="math inline">∀<em>x</em> ∈ <em>X</em>, <em>y</em> ∈ <em>Y</em></span> - бесконечная игра</p>
<p><span class="math inline"><em>F</em>(<em>i</em>, <em>j</em><sub>0</sub>) ≤ <em>F</em>(<em>i</em><sub>0</sub>, <em>j</em><sub>0</sub>) ≤ <em>F</em>(<em>i</em><sub>0</sub>, <em>j</em>)</span> для <span class="math inline">$\forall i = \overline{1,m}, j = \overline{1,n}$</span> - конечная игра</p>
<p><strong>Теорема 1</strong>: Седловая точка существует тогда и только тогда, когда <span class="math inline">$\underline{I} = \overline{I}$</span></p>
<p><strong>Теорема 2</strong>: Если <span class="math inline">∃<em>i</em><sub>0</sub>, <em>j</em><sub><em>o</em></sub>, <em>v</em> = <em>c</em><em>o</em><em>n</em><em>s</em><em>t</em></span> : <span class="math inline"><em>F</em>(<em>i</em>, <em>j</em><sub>0</sub>) ≤ <em>v</em> ≤ <em>F</em>(<em>i</em><sub>0</sub>, <em>j</em>), ∀<em>i</em>, <em>j</em></span> , то <span class="math inline"><em>v</em> = <em>F</em>(<em>i</em><sub>0</sub>, <em>j</em><sub>0</sub>)</span> и <span class="math inline">(<em>i</em><sub>0</sub>, <em>j</em><sub>0</sub>)</span> - седловая точка</p>
<p><strong>Теорема 3</strong>: Существует седловая точка, тогда и только тогда, когда существуют и равны <span class="math inline">$\max\limits_{x \in X}\inf\limits_{y \in Y}F(x,y) = \min\limits_{y \in Y}\sup\limits_{x \in X}F(x,y) = V$</span> ( <span class="math inline"><em>V</em></span> равно значению <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span> в седловой точке)</p>
<p><strong>Теорема Фон-Неймана</strong></p>
<p>Пусть <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span> - определена и непрерывна на множестве <span class="math inline"><em>X</em> × <em>Y</em></span>, <span class="math inline"><em>X</em> ⊂ <em>E</em><sup><em>m</em></sup></span>, <span class="math inline"><em>Y</em> ⊂ <em>E</em><sup><em>n</em></sup></span> - выпуклые компактные множества в евклидовых пространствах и <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span> - выпукла по <span class="math inline"><em>y</em></span>, вогнута по <span class="math inline"><em>x</em></span>, тогда <span class="math inline"><em>F</em>(<em>x</em>, <em>y</em>)</span> имеет на <span class="math inline"><em>X</em> × <em>Y</em></span> седловую точку.</p>
<h1 id="понятие-потока-в-сети.-задача-о-максимальном-потоке.-алгоритмы-форда-фалкерсона-и-карзанова.-теорема-о-максимальном-потоке-и-минимальном-разрезе.-сведение-задачи-составления-допустимого-расписания-с-прерываниями-для-многопроцессорной-системы-при-заданных-директивных-интервалах-к-задаче-о-максимальном-потоке-в-сети.">28. Понятие потока в сети. Задача о максимальном потоке. Алгоритмы Форда-Фалкерсона и Карзанова. Теорема о максимальном потоке и минимальном разрезе. Сведение задачи составления допустимого расписания с прерываниями для многопроцессорной системы при заданных директивных интервалах к задаче о максимальном потоке в сети.</h1>
<p>Сеть состоит из ориентированного графа <span class="math inline"><em>G</em> = (<em>V</em> = {1, …, <em>n</em>}, <em>A</em> = {(<em>i</em>, <em>j</em>)}, <em>i</em>, <em>j</em> ∈ <em>V</em>)</span> с двумя выделенными вершинами <span class="math inline"><em>s</em></span> - источник и <span class="math inline"><em>t</em></span> - сток. Каждая дуга обладает пропускной способностью <span class="math inline"><em>u</em><sub><em>i</em><em>j</em></sub></span>. <span class="math inline">(<em>i</em>, <em>j</em>) ∈ <em>A</em> : <em>u</em><sub><em>i</em><em>j</em></sub> &gt; 0</span></p>
<p><strong>Поток</strong>: <span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub>, (<em>i</em>, <em>j</em>) ∈ <em>A</em></span> и его свойства:</p>
<ol type="1">
<li><span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub> ≥ 0</span></li>
<li><span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub> ≤ <em>u</em><sub><em>i</em><em>j</em></sub> ∀(<em>i</em>, <em>j</em>) ∈ <em>A</em></span></li>
<li><span class="math inline">$\sum\limits_{j:(j,i_0) \in A}f_{ji_0} - \sum\limits_{j:(i_0,j) \in A}f_{i_0j} = 0, ~\forall i_0 \in V, i_0\neq s,t$</span> - сохранение потока</li>
</ol>
<p><span class="math inline">$\sum\limits_{(s,j) \in A}f_{sj} - \sum\limits_{(j,s) \in A}f_{js} = M(f)$</span> - величина потока (Суммарный поток выходящий из истока минус суммарный поток входящий в исток)</p>
<p><strong>Задача о максимальном потоке</strong></p>
<p>Необходимо найти поток <span class="math inline"><em>f</em><sub><em>i</em>, <em>j</em></sub>′</span>, такой что $ M(f’) = <em>{f</em>{ij}}M(f)$, то есть величина потока максимальна.</p>
<p><strong>Пример сети с построенным максимальным потоком</strong></p>
<figure>
<img src="./img/28_1.png" alt="" /><figcaption>img</figcaption>
</figure>
<p><strong>Алгоритм Форда-Фалкерсона</strong></p>
<p>Пусть <span class="math inline"><em>π</em></span> - это путь</p>
<p>по прямой дуге: <span class="math inline"><em>δ</em><sub><em>i</em><em>j</em></sub> = <em>u</em><sub><em>i</em><em>j</em></sub> − <em>f</em><sub><em>i</em><em>j</em></sub> &gt; 0</span> <span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub> = <em>f</em><sub><em>i</em><em>j</em></sub> + <em>δ</em>(<em>π</em>)</span></p>
<p>По обратной дуге: $<em>{kj} = f</em>{kj}  $ <span class="math inline"><em>f</em><sub><em>k</em><em>j</em></sub> = <em>f</em><sub><em>k</em><em>j</em></sub> − <em>δ</em>(<em>π</em>)</span></p>
<p><span class="math inline">$\delta(\pi) = \min\limits_{(i,j) \in \pi}\delta_{i,j}$</span></p>
<p><strong>Увеличивающий путь</strong> - это путь <span class="math inline"><em>π</em></span> (последовательность дуг из истока в сток), для которого величина <span class="math inline"><em>δ</em>(<em>π</em>) &gt; 0</span>, которая определяется следующим образом: для каждой дуги <span class="math inline">(<em>i</em>, <em>j</em>)</span> входящей в путь <span class="math inline"><em>π</em></span> вычисляется величина <span class="math inline">$\delta_{ij} = \left\{ \begin{matrix} u_{ij} - f_{ij} &gt; 0 &amp; ,прямая ~ дуга\\ f_{ji} &gt; 0 &amp; ,обратная ~ дуга \end{matrix} \right.$</span> и <span class="math inline">$\delta(\pi) = \min\limits_{(i,j) \in \pi} \delta_{ij}$</span>.</p>
<blockquote>
<p>неформально это путь из истока в сток, вдоль которого можно увеличить поток на некоторую величину.</p>
<p>Про обратную дугу - можно забирать поток назад</p>
</blockquote>
<p><strong>Алгоритм</strong></p>
<ol type="1">
<li><span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub></span> - начальный поток (<span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub> = 0</span>)</li>
<li>Увеличить путь <span class="math inline"><em>π</em></span> на <span class="math inline"><em>δ</em>(<em>π</em>)</span> [итеративно]</li>
<li>Если нет увеличивающего пути - остановка. [нашли максимальный поток]</li>
</ol>
<p>Пусть <span class="math inline">$u_{ij} \in \N$</span> - закончится, так как как минимум на 1 каждый раз увеличивается, поэтому алгоритм не зациклится.</p>
<p><strong>Алгоритм Карзанова</strong></p>
<p><span class="math inline"><em>G</em>(<em>f</em>) = (<em>V</em>, <em>A</em>(<em>f</em>))</span> - <strong>остаточная сеть</strong></p>
<p><span class="math inline"><em>A</em>(<em>f</em>)</span>:</p>
<ol type="1">
<li><span class="math inline">(<em>i</em>, <em>j</em>) ∈ <em>A</em>, <em>f</em><sub><em>i</em><em>j</em></sub> &lt; <em>u</em><sub><em>i</em><em>j</em></sub></span> <span class="math inline">(<em>i</em>, <em>j</em>) → <em>A</em>(<em>f</em>)</span> <span class="math inline"><em>v</em><sub><em>i</em><em>j</em></sub> = <em>u</em><sub><em>i</em><em>j</em></sub> − <em>f</em><sub><em>i</em><em>j</em></sub></span></li>
<li><span class="math inline">(<em>i</em>, <em>j</em>) ∈ <em>A</em>, <em>f</em><sub><em>i</em><em>j</em></sub> &gt; 0</span> <span class="math inline">(<em>j</em>, <em>i</em>) → <em>A</em>(<em>f</em>)</span> <span class="math inline"><em>v</em><sub><em>j</em><em>i</em></sub> = <em>f</em><sub><em>i</em><em>j</em></sub></span></li>
</ol>
<p><strong>Слоистая сеть</strong> $G^<em>(f)= (V^</em>, A^*(f)) $ включает в себя множество всех кратчайших путей (по числу дуг) из источника в сток по слоям:</p>
<p>Нулевой слой <span class="math inline"><em>V</em><sub>0</sub> = {<em>s</em>}</span></p>
<p>Первый слой <span class="math inline"><em>V</em><sub>1</sub> = {<em>i</em> : (<em>s</em>, <em>i</em>) ∈ <em>A</em>(<em>f</em>)}</span></p>
<p>Второй слой <span class="math inline"><em>V</em><sub>2</sub> = {<em>j</em> : (<em>j</em>, <em>i</em>) ∈ <em>A</em>(<em>f</em>), <em>i</em> ∈ <em>V</em><sub>1</sub>, <em>j</em> ∉ <em>V</em><sub>1</sub> ∪ <em>V</em><sub>0</sub></span> и так далее, на последнем слое может быть не только сток, в промежуточных может быть тупиковые, поэтому надо убирать висячие узлы как только дошли до стока и инцидентные им дуги.</p>
<p><strong>Тупиковый поток</strong> - поток, относительно которого нет прямого увеличивающего пути (содержит только прямые дуги) из источника в сток.</p>
<p><strong>Алгоритм</strong></p>
<ol type="1">
<li>Начальный нулевой поток в G</li>
<li>Построить G(f) - остаточную сеть</li>
<li>Если нет прямого пути из s в t, то стоп <span class="math inline"><em>f</em></span> - максимальный поток</li>
<li>Построить <span class="math inline"><em>G</em><sup>*</sup>(<em>f</em>)</span> - слоистую сеть</li>
<li>Построить тупиковый поток в <span class="math inline"><em>G</em><sup>*</sup>(<em>f</em>)</span> - <span class="math inline"><em>g</em><sub><em>i</em><em>j</em></sub></span></li>
<li>Изменить потоки: $(i,j) A^<em>(f) $- прямая <span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub> = <em>f</em><sub><em>i</em><em>j</em></sub> + <em>g</em><sub><em>i</em><em>j</em></sub></span> , для обратных дуг $(i,j) A^</em>(f) $ <span class="math inline"><em>f</em><sub><em>i</em><em>j</em></sub> = <em>f</em><sub><em>i</em><em>j</em></sub> − <em>g</em><sub><em>i</em><em>j</em></sub></span></li>
<li>Перейти на 2 шаг</li>
</ol>
<p><strong>Разрез</strong>: , <span class="math inline">$V = V_c \cup \overline{V}_c$</span>, <span class="math inline">$V_c \cap \overline{V}_c = \empty$</span>, <span class="math inline"><em>s</em> ∈ <em>V</em><sub><em>c</em></sub></span>, <span class="math inline">$t \in \overline{V}_c$</span></p>
<p><span class="math inline">$u(V_c, \overline{V}_c) = \sum\limits_{i \in V_c, j \in \overline{V}_c} u_{ij}$</span> - пропускная способность разреза</p>
<p>Разрез с минимальной пропускной способностью называется <strong>минимальным разрезом</strong>.</p>
<p><strong>Теорема о максимальном потоке и минимальном разрезе</strong>. Величина максимального потока в сети равна величине минимального разреза в сети.</p>
<p><strong>Задача составления допустимого расписания с прерываниями для многопроцессорной системы:</strong></p>
<p>Пусть имеется <span class="math inline"><em>m</em></span> - процессоров. Задано <span class="math inline"><em>N</em> = {1, …, <em>n</em>}</span> - число работ и для каждой работы заданы <span class="math inline"><em>t</em><sub><em>i</em></sub></span> - длительность , <span class="math inline">(<em>b</em><sub><em>i</em></sub>, <em>f</em><sub><em>i</em></sub>]</span> - директивный интервал <span class="math inline"><em>i</em></span>-ой работы (<span class="math inline"><em>b</em><sub><em>i</em></sub> &lt; <em>f</em><sub><em>i</em></sub></span> и <span class="math inline"><em>t</em><sub><em>i</em></sub> ≤ <em>f</em><sub><em>i</em></sub> − <em>b</em><sub><em>i</em></sub></span>). Во время выполнения работ допускаются прерывания и переключения. Требуется ответить на вопрос существует ли допустимое расписание и как его построить.</p>
<p><strong>Сведение задачи к задачи поиска максимального потока в сети</strong>:</p>
<p>Обозначим <span class="math inline"><em>y</em><sub>0</sub> &lt; <em>y</em><sub>1</sub> &lt; <em>y</em><sub>2</sub> &lt; …<em>y</em><sub><em>p</em></sub></span> - все упорядоченные значения <span class="math inline"><em>b</em><sub><em>i</em></sub>, <em>f</em><sub><em>i</em></sub></span></p>
<p>Составим отрезки <span class="math inline">$I_j=(y_{j-1}, y_j], j=\overline{1,p}$</span></p>
<p>Сеть будет состоять из узлов <span class="math inline"><em>s</em></span>, <span class="math inline"><em>t</em></span> , <span class="math inline"><em>I</em><sub><em>j</em></sub></span>, <span class="math inline"><em>w</em><sub><em>i</em></sub></span></p>
<p><span class="math inline"><em>Δ</em><sub><em>j</em></sub> = <em>y</em><sub><em>j</em></sub> − <em>y</em><sub><em>j</em> − 1</sub></span> - длительность интервала <span class="math inline"><em>I</em><sub><em>j</em></sub></span></p>
<p>Добавляем дуги <span class="math inline">(<em>s</em>, <em>I</em><sub><em>j</em></sub>)</span> с пропускной способностью <span class="math inline"><em>m</em><em>Δ</em><sub><em>j</em></sub></span></p>
<p>Добавляем дуги <span class="math inline">(<em>I</em><sub><em>j</em></sub>, <em>w</em><sub><em>i</em></sub>)</span>, если <span class="math inline">$I_j \sub (b_i, f_i]$</span> пропускной способностью <span class="math inline"><em>Δ</em><sub><em>j</em></sub></span></p>
<p>Добавляем дуги <span class="math inline">(<em>w</em><sub><em>i</em></sub>, <em>s</em>)</span> пропускной способностью <span class="math inline"><em>t</em><sub><em>i</em></sub></span></p>
<p>Пример сети для задачи при <span class="math inline"><em>m</em> = 2</span></p>
<p><span class="math inline">$\begin{matrix}Раб. &amp; b_i &amp; f_i &amp; t_i \\ 1 &amp; 1 &amp; 6 &amp;3 \\ 2 &amp; 1 &amp; 5 &amp;3 \\ 3 &amp; 0 &amp; 6 &amp; 3\\ 4 &amp; 0 &amp; 4 &amp; 3\\ \end{matrix}$</span></p>
<p><span class="math inline"><em>I</em><sub>1</sub> = [0, 1], <em>I</em><sub>2</sub> = [1, 4], <em>I</em><sub>3</sub> = [4, 5], <em>I</em><sub>4</sub> = [5, 6]</span></p>
<figure>
<img src=".\img\28_2.png" alt="" /><figcaption>img</figcaption>
</figure>
<p><strong>Теорема</strong>. Допустимое расписание существует, тогда и только тогда, когда Максимальный поток в G насыщает все выходные дуги.</p>
<blockquote>
<p><strong>Как можно искать увеличивающий путь</strong></p>
<p>Есть состояния у каждого узла : <span class="math inline"><em>Н</em>, <em>П</em><em>Н</em>, <em>П</em><em>П</em></span> - непомеченный, помеченный непросмотренный, помеченный просмотренный</p>
<blockquote>
<p>Метим следующие для рассмотрения вершины по которым теоретически можно получить увеличивающий путь</p>
</blockquote>
<ol type="1">
<li>S [-], S - <span class="math inline"><em>П</em><em>Н</em></span></li>
<li>Если нет <span class="math inline"><em>П</em><em>Н</em></span>, то останавливаемся (нет увеличивающих путей)</li>
<li><span class="math inline"><em>i</em> − <em>П</em><em>Н</em></span>, $j - Н, (i,j) A, f_{ij} u_{ij} $ - метим <span class="math inline">[<em>i</em>]</span>, <span class="math inline"><em>j</em> − <em>П</em><em>Н</em></span></li>
</ol>
<p>​ <span class="math inline"><em>i</em> − <em>П</em><em>Н</em></span>, <span class="math inline">∀<em>j</em> − <em>Н</em>, (<em>i</em>, <em>j</em>) ∈ <em>A</em>, <em>f</em><sub><em>i</em><em>j</em></sub> &gt; 0</span> - метим <span class="math inline">[<em>i</em>]</span>, <span class="math inline"><em>j</em> − <em>П</em><em>Н</em></span></p>
<p>​ далее <span class="math inline"><em>i</em> − <em>П</em><em>П</em></span></p>
<ol start="4" type="1">
<li>Если <span class="math inline"><em>t</em> − <em>Н</em></span>, то переходим на шаг 2</li>
</ol>
<p>​ Если <span class="math inline"><em>t</em> − <em>П</em></span> - построить увеличивающий путь от истока к стоку</p>
<p><strong>Как строить тупиковый поток</strong></p>
<p><span class="math inline"><em>i</em> ∈ <em>V</em><sup>*</sup>(<em>f</em>), <em>i</em> ≠ <em>s</em>, <em>t</em></span></p>
<p>$a(i)= { _{(j,i) A^*(f)}v_{ji}, _{(j,i) A^*(f)}v_{ij}} $ - <strong>пропускная способность узла</strong></p>
<p><span class="math inline">$a(s) = \sum\limits_{(s,j) \in A^*(f)}v_{sj}$</span></p>
<p><span class="math inline">$a(s) = \sum\limits_{(j,s) \in A^*(f)}v_{jt}$</span></p>
<p><span class="math inline"><em>i</em><sub>0</sub></span> - самый слабый узел <span class="math inline">$a(i_0) = \min\limits_{i \in V^*(f)}a(i)$</span></p>
<p>Выбираем его</p>
<p><span class="math inline"><em>a</em><sub><em>i</em><sub>0</sub></sub></span> - будем проталкивать поток от <span class="math inline"><em>i</em><sub>0</sub></span> до стока и до истока (можно по разным дугам, но разрешена только одна недонасыщенная)</p>
<p>После этого вершина <span class="math inline"><em>i</em><sub>0</sub></span> исключается из сети и все полностью насыщенные дуги (если дуги были не полностью насыщены и остались в сети то им изменяем пропускную способность)</p>
<p>и так сначала, пока не останется тупиковый поток</p>
</blockquote>
<h1 id="псевдополиномиальные-алгоритмы-решения-задач-разбиение-рюкзак-расписание-для-многопроцессорной-системы-число-процессоров-фиксировано.">29. Псевдополиномиальные алгоритмы решения задач: разбиение, рюкзак, расписание для многопроцессорной системы (число процессоров фиксировано).</h1>
<p>Пусть есть задача распознавания свойств <span class="math inline"><em>П</em></span>. <span class="math inline"><em>D</em><sub><em>П</em></sub></span> - множество индивидуальных задач.</p>
<p>Алгоритм <span class="math inline"><em>A</em></span> решения задачи <span class="math inline"><em>П</em></span> называется псевдополиномиальным, если его вычислительная сложность ограничена сверху полиномом от функции длины и функции максимума (максимальное число в данной индивидуальной задаче) : <span class="math inline"><em>T</em><sub><em>A</em></sub>(<em>I</em>) ≤ <em>p</em>(<em>l</em>(<em>I</em>), <em>M</em>(<em>I</em>))</span> (<span class="math inline"><em>I</em> ∈ <em>D</em><sub><em>П</em></sub></span>)</p>
<p><strong>Разбиение</strong></p>
<p>Пусть даны <span class="math inline"><em>n</em></span> чисел : <span class="math inline"><em>N</em> = {<em>a</em><sub>1</sub>, …, <em>a</em><sub><em>n</em></sub>}</span>. Такие, что <span class="math inline">$B = \sum\limits_{i \in N} a_i$</span> - четное число и <span class="math inline">$0 &lt; a_i &lt; {B\over 2}|~ i=\overline{1,n}$</span>. Необходимо проверить, возможно ли разбиение множества <span class="math inline"><em>N</em></span> на два непересекающихся подмножества <span class="math inline">$\overline N$</span> и <span class="math inline">$N \setminus \overline N$</span>, таких, что <span class="math inline">$\sum\limits_{i \in \overline N} a_i = \sum\limits_{j \in N \setminus \overline N} a_j = {B \over 2}$</span></p>
<p>Алгоритм:</p>
<p>Необходимо составить таблицу <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em>)</span> размера <span class="math inline">$n \times {B \over 2}$</span>.</p>
<p>Значение ячейки <span class="math inline">$t(i,j) = \left\{ \begin{matrix} 1 &amp; \exist\tilde N \sube N' : \sum\limits_{k \in \tilde N} a_k = j~ ,~ при~ этом ~ N' = \{a_1, \dots, a_i\} \\ 0 &amp; иначе \end{matrix} \right.$</span></p>
<p>Построение таблицы производится по строкам, начиная с первой:</p>
<ul>
<li>В первой строке <span class="math inline"><em>i</em> = 1</span> единица ставится столбцу <span class="math inline"><em>j</em> = <em>a</em><sub>1</sub></span> : <span class="math inline"><em>t</em>(1, <em>a</em><sub>1</sub>) = 1</span></li>
<li>Для следующих строк <span class="math inline"><em>i</em> &gt; 1</span>:
<ol type="1">
<li>Переносим все единицы с предыдущей строки: <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em>) = 1</span>, если <span class="math inline"><em>t</em>(<em>i</em> − 1, <em>j</em>) = 1</span></li>
<li>Добавляем единицы, полученные сдвигом существующих на <span class="math inline"><em>a</em><sub><em>i</em></sub></span>: если <span class="math inline"><em>t</em>(<em>i</em> − 1, <em>j</em>) = 1</span> и $ j + a_i $, то <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em> + <em>a</em><sub><em>i</em></sub>) = 1</span></li>
<li>Добавляем единицу в столбец с номером <span class="math inline"><em>a</em><sub><em>i</em></sub></span>: <span class="math inline"><em>t</em>(<em>i</em>, <em>a</em><sub><em>i</em></sub>) = 1</span></li>
</ol></li>
</ul>
<p>Останавливаемся, когда получаем первую единицу в столбце с номером <span class="math inline">$B \over 2$</span> - значит можно построить разбиение. Если нет, то и нельзя построить разбиение.</p>
<p>Сложность алгоритма равна <span class="math inline"><em>O</em>(<em>n</em><em>B</em>)</span> - по размеру таблицы, которую надо заполнить.</p>
<p><strong>Рюкзак</strong></p>
<p>Дано <span class="math inline"><em>n</em></span> предметов с весами <span class="math inline"><em>w</em><sub>1</sub>, …, <em>w</em><sub><em>n</em></sub></span> и стоимостями <span class="math inline"><em>p</em><sub>1</sub>, …, <em>p</em><sub><em>n</em></sub></span>. <span class="math inline"><em>N</em> = {1, …, <em>n</em>}</span>. Задан вес <span class="math inline"><em>W</em></span> и стоимость <span class="math inline"><em>P</em></span>. Необходимо проверить, возможно ли найти такое множество предметов <span class="math inline">$\overline{N}$</span> , что сумма их весов не превышает заданный вес <span class="math inline">$\sum\limits_{i \in \overline N} w_i \le W$</span> и суммарная стоимость не меньше заданной стоимости <span class="math inline">$\sum\limits_{i \in \overline N} p_i \ge P$</span> .</p>
<p>Алгоритм:</p>
<p>Необходимо составить таблицу <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em>)</span> размера <span class="math inline"><em>n</em> × <em>W</em></span>.</p>
<p>Построение таблицы производится по строкам, начиная с первой:</p>
<ul>
<li>В первой строке <span class="math inline"><em>i</em> = 1</span> ячейка со столбцом <span class="math inline"><em>j</em> = <em>w</em><sub>1</sub></span> заполняется стоимостью <span class="math inline"><em>p</em><sub>1</sub></span> : <span class="math inline"><em>t</em>(1, <em>w</em><sub>1</sub>) = <em>p</em><sub>1</sub></span></li>
<li>Для следующих строк <span class="math inline"><em>i</em> &gt; 1</span>:
<ol type="1">
<li>Переносим все значения c предыдущей строки: <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em>) = <em>t</em>(<em>i</em> − 1, <em>j</em>)</span> <span class="math inline">$j = \overline{1, W}$</span></li>
<li>Выбираем максимальную стоимость между 2 вариантам: добавить <span class="math inline"><em>i</em></span> -ую вещь в наборы или не добавлять (уже есть набор с таким же весом и большей стоимостью) : если <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em>) ≠ 0</span>, то <span class="math inline"><em>t</em>(<em>i</em>, <em>j</em> + <em>w</em><sub><em>i</em></sub>) = max {<em>t</em>(<em>i</em> − 1, <em>j</em>) + <em>p</em><sub><em>i</em></sub>,  <em>t</em>(<em>i</em> − 1, <em>j</em> + <em>w</em><sub><em>i</em></sub>) }</span></li>
<li>Добавляем максимальную стоимость для множества с весом <span class="math inline"><em>w</em><sub><em>i</em></sub></span>: <span class="math inline"><em>t</em>(<em>i</em>, <em>w</em><sub><em>i</em></sub>) = max {<em>p</em><sub><em>i</em></sub>,  <em>t</em>(<em>i</em> − 1, <em>w</em><sub><em>i</em></sub>)}</span></li>
</ol></li>
</ul>
<p>Останавливаемся, когда получаем значение стоимости в ячейке, больше, чем <span class="math inline"><em>P</em></span>, - значит можно найти необходимое множество предметов. Если не получили, то и нельзя найти необходимое множество предметов.</p>
<p>Теперь перейдем к поиску самого набора предметов, в случае, если необходимое множество предметов найти можно:</p>
<ol type="1">
<li>Изначально множество <span class="math inline"><em>N</em>′</span> пусто</li>
<li>Выбираем минимальную строку <span class="math inline"><em>i</em><sub>1</sub></span>, такую, что <span class="math inline">$\exist j_1 : t(i_1,j_1) \ge P$</span>. Добавляем <span class="math inline"><em>i</em><sub>1</sub></span> к <span class="math inline"><em>N</em>′</span>. Запоминаем <span class="math inline"><em>j</em><sub>1</sub></span></li>
<li>Уменьшаем <span class="math inline"><em>j</em><sub>1</sub></span> на величину веса предмета <span class="math inline"><em>i</em><sub>1</sub></span>: <span class="math inline"><em>j</em><sub>1</sub> := <em>j</em><sub>1</sub> − <em>w</em><sub><em>i</em><sub>1</sub></sub></span></li>
<li>Если <span class="math inline"><em>j</em><sub>1</sub> = 0</span>, то закончили. Иначе ищем минимальную строку <span class="math inline"><em>i</em><sub>2</sub></span>, такую, что <span class="math inline"><em>t</em>(<em>i</em><sub>2</sub>, <em>j</em><sub>1</sub>) = <em>t</em>(<em>i</em><sub>1</sub>, <em>j</em><sub>1</sub>)</span>. Добавляем <span class="math inline"><em>i</em><sub>2</sub></span> в множество <span class="math inline"><em>N</em>′</span>. <span class="math inline"><em>i</em><sub>1</sub> := <em>i</em><sub>2</sub></span> и переход к шагу 3.</li>
</ol>
<p>Сложность алгоритма равна <span class="math inline"><em>O</em>(<em>n</em><em>W</em>)</span> - по размеру таблицы, которую надо заполнить.</p>
<p><strong>Расписание для многопроцессорной системы</strong></p>
<p>Пусть задано <span class="math inline"><em>N</em> = {1, …, <em>n</em>}</span> работ с заданными длительностями выполнения <span class="math inline"><em>t</em><sub><em>i</em></sub> ≤ <em>T</em></span>. <span class="math inline"><em>T</em></span> - единый директивный срок для всех работ. Имеется <span class="math inline"><em>m</em></span> процессоров на которых запрещены прерывания. Необходимо проверить - возможно ли построение расписания выполнения работ, которое уложится в директивный интервал.</p>
<p>Алгоритм:</p>
<p>Алгоритм заключается в построении точек в <span class="math inline"><em>m</em></span>-мерной решетке и проверки принадлежности точек <span class="math inline"><em>m</em></span>-мерному кубу со стороной <span class="math inline"><em>T</em></span>.</p>
<ol type="1">
<li>$l=1 $ - cтроим первые <span class="math inline"><em>m</em></span> точек <span class="math inline"><em>m</em></span>-мерной решетки: <span class="math inline">(<em>t</em><sub>1</sub>, 0, …, 0), (0, <em>t</em><sub>1</sub>, …, 0), …, (0, 0, …, <em>t</em><sub>1</sub>)</span> . Изначально все эти точки активны.</li>
<li>Исключаем из списка активных точек те, которые не принадлежат определенному выше кубу. Если <span class="math inline"><em>l</em> = <em>n</em></span>, то решение найдено - из числа активных точек берем решение. Если активных не осталось, то расписание не может построить, удовлетворяющее директивному интервалу <span class="math inline"><em>T</em></span>.</li>
<li>На шаге <span class="math inline"><em>l</em> := <em>l</em> + 1</span> для каждой активной точки <span class="math inline"><em>a</em> = (<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, …, <em>a</em><sub><em>m</em></sub>)</span> строим множество новых активных точек вида <span class="math inline">(<em>a</em><sub>1</sub> + <em>t</em><sub><em>l</em></sub>, <em>a</em><sub>2</sub>, …, <em>a</em><sub><em>m</em></sub>), (<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub> + <em>t</em><sub><em>l</em></sub>, …, <em>a</em><sub><em>m</em></sub>), …, (<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, …, <em>a</em><sub><em>m</em></sub> + <em>t</em><sub><em>l</em></sub>)</span> , при этом <span class="math inline"><em>a</em></span> исключаем из списка активных. Переходим к шагу 2.</li>
</ol>
<p>Сложность <span class="math inline"><em>O</em>(<em>T</em><sup><em>m</em></sup>)</span> - псевдополиномиальный только при фиксированном числе процессоров <span class="math inline"><em>m</em></span>.</p>
<blockquote>
<p>T^m - число точек рассматриваемого куба, которые проверяем</p>
</blockquote>
<h1 id="метод-ветвей-и-границ-на-примере-минимаксной-задачи-теории-расписаний.-приближенные-алгоритмы-решения-np-трудных-задач-упаковка-в-контейнеры-рюкзак-коммивояжер-расписание-для-многопроцессорной-системы-вершинное-покрытие.-оценки-их-сложности-и-погрешности.">30. Метод ветвей и границ на примере минимаксной задачи теории расписаний. Приближенные алгоритмы решения NP-трудных задач: упаковка в контейнеры, рюкзак, коммивояжер, расписание для многопроцессорной системы, вершинное покрытие. Оценки их сложности и погрешности.</h1>
<p>Метод ветвей и границ относится к точным алгоритмам. Для метода ветвей и границ необходимы две процедуры: ветвление и нахождение оценок (границ). Пусть есть оптимальная задача <span class="math inline">$\min\limits_{x \in X}f(x)$</span>. Ветвление разделяет множество <span class="math inline"><em>X</em> = <em>X</em><sub>1</sub> ∪ <em>X</em><sub>2</sub></span> . Вычисляются оценки на этих множествах (нижние и верхние) <span class="math inline">$F_{1l} \le \min\limits_{x \in X_1}f(x) \le F_{1h}$</span> и <span class="math inline">$F_{2l} \le \min\limits_{x \in X_2}f(x) \le F_{2h}$</span>. Если <span class="math inline"><em>F</em><sub>1<em>h</em></sub> ≤ <em>F</em><sub>2<em>l</em></sub></span> , то можно не рассматривать <span class="math inline"><em>X</em><sub>2</sub></span> и осуществлять ветвление дальше только на <span class="math inline"><em>X</em><sub>1</sub></span>.</p>
<p><strong>Минимаксная задача построения расписания для многопроцессорной системы</strong>: имеется вычислительная система $P = P_1, , P_m $ , состоящая из <span class="math inline"><em>m</em></span> процессоров. Дано <span class="math inline"><em>n</em></span> работ <span class="math inline"><em>T</em> = <em>T</em><sub>1</sub>, …, <em>T</em><sub><em>n</em></sub></span>, для каждой из которых известна длительность <span class="math inline"><em>t</em><sub><em>i</em><em>j</em></sub></span> на процессоре <span class="math inline"><em>P</em><sub><em>j</em></sub></span>. Требуется распределить задания по процессорам так, чтобы общее время выполнения всего множества работ было минимальным.</p>
<p>Ветвление: на первом уровне определяется размещение 1 работы — <span class="math inline"><em>m</em></span> вариантов, далее рекурсивно на уровне <span class="math inline"><em>k</em></span> определяется процессор для работы <span class="math inline"><em>k</em></span>.</p>
<p>Оценки:</p>
<ul>
<li><p>Нижняя (на уровне <span class="math inline"><em>k</em></span>, то есть известно размещение первых <span class="math inline"><em>k</em></span> работ ):</p>
<ul>
<li><span class="math inline">$L_1 = \max\limits_{j= \overline{1,m}} T_j$</span>, где <span class="math inline"><em>T</em><sub><em>j</em></sub></span> - текущее время выполнения размещенных работ на процессоре <span class="math inline"><em>j</em></span>. Общая длительность расписания будет не меньше уже существующей.</li>
<li><span class="math inline">$L_2 = \max\limits_{i=\overline{k+1,n}} \min\limits_{j=\overline{1,m}} (T_j + t_{ij})$</span> - длительность расписания увеличится еще на одну размещенную работу (самым быстрым способом)</li>
<li><span class="math inline">$L_3 = (\sum\limits_{j=1}^mT_j + \sum\limits_{i=k+1}^n \min\limits_{j=\overline{1,m}}t_{ij}){1 \over m}$</span> - учет размещение всех работ, не размещенных к данному ветвлению</li>
</ul>
<p>Итоговая нижняя оценка <span class="math inline"><em>L</em> = max (<em>L</em><sub>1</sub>, <em>L</em><sub>2</sub>, <em>L</em><sub>3</sub>)</span></p></li>
<li><p>Верхняя (на уровне <span class="math inline"><em>k</em></span>, то есть известно размещение первых <span class="math inline"><em>k</em></span> работ ): неназначенные работы распределяются жадным алгоритмом и <span class="math inline">$H = \max\limits_{j=\overline{1,m}}T^*_j$</span>, где <span class="math inline"><em>T</em><sub><em>j</em></sub><sup>*</sup></span> - длительность работ на процессорах с учетом распределения остальных работ жадным алгоритмом.</p></li>
</ul>
<p>Приближенным алгоритмом для задачи <span class="math inline"><em>П</em></span> называется полиномиальный по времени алгоритм, возвращающий для каждого входа <span class="math inline"><em>I</em> ∈ <em>D</em><sub><em>П</em></sub></span> какое-то решение <span class="math inline"><em>x</em>(<em>I</em>) ∈ <em>s</em><em>o</em><em>l</em>(<em>I</em>)</span>. Обозначим через <span class="math inline"><em>f</em>(<em>x</em><sub><em>A</em></sub>(<em>I</em>))</span> стоимость решения, найденного алгоритмом А на входе <span class="math inline"><em>I</em></span>. Пусть <span class="math inline">$f(x^*(I)) = \min\limits_{x(i) \in sol(I)}f(x(I))$</span> - оптимальная стоимость решения.</p>
<p>Часто рассматриваются следующие <strong>виды погрешностей</strong> для индивидуальных задач <span class="math inline"><em>I</em></span>:</p>
<p><span class="math inline">$r^1_A(I) = {f(x_A(I)) \over f(x^*(I))}$</span> - во сколько раз больше решение</p>
<p><span class="math inline"><em>r</em><sub><em>A</em></sub><sup>2</sup>(<em>I</em>) = <em>f</em>(<em>x</em><sub><em>A</em></sub>(<em>I</em>)) − <em>f</em>(<em>x</em><sup>*</sup>(<em>I</em>))</span> - разность</p>
<p><span class="math inline">$r^3_A(I) = { {f(x_A(I)) - f(x^*(I))} \over f(x^*(I))}$</span> - относительная погрешность</p>
<p><span class="math inline"><em>r</em><sub><em>A</em></sub><sup>3</sup>(<em>I</em>) = <em>r</em><sub><em>A</em></sub><sup>1</sup>(<em>I</em>) − 1</span></p>
<p><strong>Погрешности</strong> для алгоритма определяются следующим образом:</p>
<p><span class="math inline">$r^1_A = \sup\limits_{I \in D_П} r_A^1(I)$</span> - погрешность алгоритма в целом</p>
<p><span class="math inline">$r^2_A = \sup\limits_{I \in D_П} r_A^2(I)$</span> - - погрешность алгоритма в целом</p>
<p><strong>Упаковка</strong></p>
<p>Упаковка <span class="math inline"><em>N</em></span> объектов (каждый своего объёма <span class="math inline"><em>v</em><sub><em>i</em></sub></span>) в конечное число контейнеров (объём контейнеров фиксирован <span class="math inline"><em>V</em></span>) таким способом, чтобы число использованных контейнеров было наименьшим.</p>
<p>Алгоритм:</p>
<p>Первый походящий: объекты помещаются в первый подходящий контейнер, если не помещаются, то создается новый.</p>
<p>Погрешность: <span class="math inline"><em>r</em><sub><em>A</em></sub><sup>1</sup> ≤ 2</span> , так как все контейнеры, максимум кроме одного будут заполнены на половину, значит <span class="math inline">$\sum\limits_{i \in N}v_i \ge {V \over 2}f(x_A(I))$</span>, следовательно <span class="math inline">$f(x_A(I)) &lt;2 \cdot {\sum\limits_{i \in N}v_i \over V}$</span>, но <span class="math inline">${\sum\limits_{i \in N}v_i \over V} \le f(x^*(I))$</span></p>
<p>Сложность <span class="math inline"><em>O</em>(<em>n</em><sup>2</sup>)</span></p>
<blockquote>
<p>Если объемы упорядочить по невозрастанию, то <span class="math inline">$r_A^1 \le {11 \over 9}$</span></p>
</blockquote>
<p><strong>Рюкзак</strong></p>
<p>Из заданного множества предметов со свойствами стоимость и вес, требуется отобрать некое число предметов таким образом, чтобы получить максимальную суммарную стоимость при одновременном соблюдении ограничения на суммарный вес.</p>
<p>Алгоритм:</p>
<p>Жадный алгоритм: необходимо отсортировать вещи по их удельной ценности (то есть отношению ценности предмета к его весу), и поместить в рюкзак предметы с наибольшей удельной ценностью.</p>
<p>Итоговая сложность <span class="math inline"><em>O</em>(<em>N</em>log (<em>N</em>))</span></p>
<p>Погрешность: <span class="math inline"><em>r</em><sub><em>A</em></sub><sup>1</sup> ≤ 2</span></p>
<p><strong>Коммивояжер</strong></p>
<p>Пройти все вершины неориентированного графа <span class="math inline"><em>G</em> = <em>V</em>, <em>A</em></span> с весами <span class="math inline"><em>d</em><sub><em>i</em><em>j</em></sub>, (<em>i</em>, <em>j</em>) ∈ <em>A</em></span> ровно по одному разу и вернуться в исходную вершину. Необходимо найти такой обход графа с минимальной суммой весов пройденных рёбер.</p>
<p>Алгоритм:</p>
<ol type="1">
<li>Ищем минимальное остовное дерево (МОД) <span class="math inline"><em>f</em>(<em>x</em><sub><em>М</em><em>О</em><em>Д</em></sub>(<em>I</em>)) &lt; <em>f</em>(<em>x</em><sup>*</sup>(<em>I</em>))</span>
<ol type="1">
<li><span class="math inline">$V' = \empty , A' = \empty$</span></li>
<li>Добавляем вершину <span class="math inline"><em>i</em> = 1</span> в <span class="math inline"><em>V</em>′</span></li>
<li>Ищем ребро <span class="math inline">(<em>i</em><sub>0</sub>, <em>j</em><sub>0</sub>)</span> , такое что <span class="math inline">$d_{i_0j_0} = \min\limits_{i \in V', ~ j \in V \setminus V', ~ (i,j) \in A} d_{ij}$</span> . Вершина <span class="math inline"><em>j</em><sub>0</sub></span> добавляется в <span class="math inline"><em>V</em>′</span>, а ребро <span class="math inline">(<em>i</em><sub>0</sub>, <em>j</em><sub>0</sub>)</span> в <span class="math inline"><em>A</em>′</span></li>
</ol></li>
<li>Используем двойной обход по МОД (<span class="math inline"><em>f</em>(<em>x</em><sub>2</sub>(<em>I</em>)) &lt; 2<em>f</em>(<em>x</em><sup>*</sup>(<em>I</em>))</span>)</li>
<li>Строим маршрут коммивояжера (<span class="math inline"><em>f</em>(<em>x</em><sub><em>A</em></sub>(<em>I</em>)) &lt; 2<em>f</em>(<em>x</em><sup>*</sup>(<em>I</em>))</span>)</li>
</ol>
<p>Погрешность: <span class="math inline"><em>r</em><sub><em>A</em></sub><sup>1</sup> ≤ 2</span></p>
<p>Сложность: <span class="math inline"><em>O</em>(<em>n</em><sup>3</sup>)</span></p>
<p><strong>Вершинное покрытие</strong></p>
<p>Выбрать в неориентированном графе G = (V, E) минимальное (по количеству вершин) множество вершин S так, чтобы оно покрывало все рёбра графа. То есть так, чтобы у каждого из рёбер графа хотя бы один из концов принадлежал S.</p>
<p>Алгоритм:</p>
<ol type="1">
<li><span class="math inline">$V' = \empty$</span></li>
<li>Выбираем ребро <span class="math inline">(<em>i</em>, <em>j</em>) ∈ <em>E</em></span>, добавляем вершины <span class="math inline"><em>i</em>, <em>j</em></span> в множество <span class="math inline"><em>V</em>′</span></li>
<li>Удаляем все инцидентные этим вершинам ребра <span class="math inline"><em>A</em></span> , $ E := E A $. Если еще есть ребра, то перейти к шагу 2.</li>
</ol>
<p>Погрешность <span class="math inline"><em>r</em><sub><em>A</em></sub><sup>1</sup> ≤ 2</span>, так как, если <span class="math inline">|<em>V</em>′| = <em>f</em>(<em>x</em><sub><em>A</em></sub>(<em>I</em>)) = 2<em>K</em></span>, то <span class="math inline"><em>f</em>(<em>x</em><sup>*</sup>(<em>I</em>)) ≥ <em>K</em></span></p>
<p>Сложность <span class="math inline"><em>O</em>(<em>n</em><sup>2</sup>)</span></p>
